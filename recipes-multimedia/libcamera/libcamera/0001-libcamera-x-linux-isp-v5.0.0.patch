From 7b85a9f903c4e2986de097703eb4c76b835cbfe9 Mon Sep 17 00:00:00 2001
From: Vincent ABRIOU <vincent.abriou@st.com>
Date: Thu, 10 Oct 2024 15:58:01 +0200
Subject: [PATCH 1/1] libcamera: x-linux-isp-v5.0.0

libcamera development to support X-LINUX-ISP v5.0.0

Signed-off-by: Vincent ABRIOU <vincent.abriou@st.com>
---
 .../guides/application-developer.rst          |    2 +-
 Documentation/guides/pipeline-handler.rst     |    2 +-
 README.rst                                    |   23 +-
 include/libcamera/base/object.h               |    2 +
 include/libcamera/base/signal.h               |    3 +-
 include/libcamera/internal/v4l2_subdevice.h   |    2 +-
 include/libcamera/ipa/dcmipp.mojom            |   35 +
 include/libcamera/ipa/meson.build             |    1 +
 include/linux/README                          |    2 +-
 include/linux/dma-buf.h                       |   84 ++
 include/linux/drm_fourcc.h                    |  128 +-
 include/linux/intel-ipu3.h                    |    7 +-
 include/linux/media-bus-format.h              |   13 +-
 include/linux/media.h                         |   29 +-
 include/linux/stm32-dcmipp-config.h           |  196 +++
 include/linux/v4l2-common.h                   |   39 -
 include/linux/v4l2-controls.h                 | 1291 ++++++++++++++++-
 include/linux/v4l2-mediabus.h                 |    4 -
 include/linux/v4l2-subdev.h                   |   56 +-
 include/linux/videodev2.h                     |   74 +-
 meson.build                                   |    1 +
 meson_options.txt                             |   10 +-
 src/apps/cam/camera_session.cpp               |   11 +-
 src/apps/cam/capture_script.cpp               |    5 +-
 src/apps/common/dng_writer.cpp                |    1 +
 src/gstreamer/gstlibcamera-utils.cpp          |   64 +
 src/gstreamer/gstlibcamerapad.cpp             |    4 +
 src/gstreamer/gstlibcamerasrc.cpp             | 1022 ++++++++++++-
 src/gstreamer/meson.build                     |   12 +
 src/ipa/dcmipp/algorithms/aec.cpp             |  511 +++++++
 src/ipa/dcmipp/algorithms/aec.h               |   52 +
 src/ipa/dcmipp/algorithms/algorithm.h         |   34 +
 src/ipa/dcmipp/algorithms/awb.cpp             |  945 ++++++++++++
 src/ipa/dcmipp/algorithms/awb.h               |   65 +
 src/ipa/dcmipp/algorithms/badpixel.cpp        |  185 +++
 src/ipa/dcmipp/algorithms/badpixel.h          |   50 +
 src/ipa/dcmipp/algorithms/blc.cpp             |  145 ++
 src/ipa/dcmipp/algorithms/blc.h               |   44 +
 src/ipa/dcmipp/algorithms/contrast.cpp        |  141 ++
 src/ipa/dcmipp/algorithms/contrast.h          |   44 +
 src/ipa/dcmipp/algorithms/demosaicing.cpp     |  146 ++
 src/ipa/dcmipp/algorithms/demosaicing.h       |   44 +
 src/ipa/dcmipp/algorithms/meson.build         |   11 +
 src/ipa/dcmipp/algorithms/statistic.cpp       |  212 +++
 src/ipa/dcmipp/algorithms/statistic.h         |   44 +
 src/ipa/dcmipp/data/imx335.yaml               |   54 +
 src/ipa/dcmipp/data/meson.build               |    9 +
 src/ipa/dcmipp/dcmipp.cpp                     |  537 +++++++
 src/ipa/dcmipp/ipa_context.h                  |  127 ++
 src/ipa/dcmipp/meson.build                    |   39 +
 src/ipa/dcmipp/module.h                       |   27 +
 src/ipa/libipa/camera_sensor_helper.cpp       |   11 +
 src/ipa/libipa/camera_sensor_helper.h         |    2 +-
 src/libcamera/base/bound_method.cpp           |    1 +
 src/libcamera/base/event_notifier.cpp         |    6 +
 src/libcamera/base/object.cpp                 |   55 +-
 src/libcamera/base/signal.cpp                 |    3 +-
 src/libcamera/base/thread.cpp                 |    7 +
 src/libcamera/base/timer.cpp                  |   10 +-
 src/libcamera/bayer_format.cpp                |    5 +
 src/libcamera/camera_sensor_properties.cpp    |    4 +
 src/libcamera/control_ids_draft.yaml          |  217 +++
 src/libcamera/formats.c                       |    0
 src/libcamera/formats.cpp                     |   26 +-
 src/libcamera/formats.yaml                    |    2 +
 src/libcamera/pipeline/dcmipp/dcmipp.cpp      | 1277 ++++++++++++++++
 src/libcamera/pipeline/dcmipp/dcmipp.h        |  131 ++
 src/libcamera/pipeline/dcmipp/dcmipp_path.cpp |  513 +++++++
 src/libcamera/pipeline/dcmipp/meson.build     |    5 +
 src/libcamera/pipeline/rpi/vc4/vc4.cpp        |    1 +
 src/libcamera/v4l2_device.cpp                 |   20 +-
 src/libcamera/v4l2_pixelformat.cpp            |    2 +
 src/libcamera/v4l2_subdevice.cpp              |   17 +
 test/event-thread.cpp                         |   38 +-
 test/gstreamer/gstreamer_test.cpp             |   17 -
 test/gstreamer/meson.build                    |    2 +-
 test/ipa/ipa_interface_test.cpp               |    1 +
 test/meson.build                              |    9 +-
 test/message.cpp                              |   54 +-
 test/object-delete.cpp                        |   30 +-
 test/signal-threads.cpp                       |   24 +-
 test/timer-fail.cpp                           |  109 ++
 test/timer-thread.cpp                         |   37 +-
 utils/ipc/extract-docs.py                     |    6 +-
 .../module_ipa_proxy.h.tmpl                   |    1 +
 85 files changed, 8930 insertions(+), 302 deletions(-)
 create mode 100644 include/libcamera/ipa/dcmipp.mojom
 create mode 100644 include/linux/stm32-dcmipp-config.h
 create mode 100644 src/ipa/dcmipp/algorithms/aec.cpp
 create mode 100644 src/ipa/dcmipp/algorithms/aec.h
 create mode 100644 src/ipa/dcmipp/algorithms/algorithm.h
 create mode 100644 src/ipa/dcmipp/algorithms/awb.cpp
 create mode 100644 src/ipa/dcmipp/algorithms/awb.h
 create mode 100644 src/ipa/dcmipp/algorithms/badpixel.cpp
 create mode 100644 src/ipa/dcmipp/algorithms/badpixel.h
 create mode 100644 src/ipa/dcmipp/algorithms/blc.cpp
 create mode 100644 src/ipa/dcmipp/algorithms/blc.h
 create mode 100644 src/ipa/dcmipp/algorithms/contrast.cpp
 create mode 100644 src/ipa/dcmipp/algorithms/contrast.h
 create mode 100644 src/ipa/dcmipp/algorithms/demosaicing.cpp
 create mode 100644 src/ipa/dcmipp/algorithms/demosaicing.h
 create mode 100644 src/ipa/dcmipp/algorithms/meson.build
 create mode 100644 src/ipa/dcmipp/algorithms/statistic.cpp
 create mode 100644 src/ipa/dcmipp/algorithms/statistic.h
 create mode 100644 src/ipa/dcmipp/data/imx335.yaml
 create mode 100644 src/ipa/dcmipp/data/meson.build
 create mode 100644 src/ipa/dcmipp/dcmipp.cpp
 create mode 100644 src/ipa/dcmipp/ipa_context.h
 create mode 100644 src/ipa/dcmipp/meson.build
 create mode 100644 src/ipa/dcmipp/module.h
 delete mode 100644 src/libcamera/formats.c
 create mode 100644 src/libcamera/pipeline/dcmipp/dcmipp.cpp
 create mode 100644 src/libcamera/pipeline/dcmipp/dcmipp.h
 create mode 100644 src/libcamera/pipeline/dcmipp/dcmipp_path.cpp
 create mode 100644 src/libcamera/pipeline/dcmipp/meson.build
 create mode 100644 test/timer-fail.cpp

diff --git a/Documentation/guides/application-developer.rst b/Documentation/guides/application-developer.rst
index c46d3362..9a9905b1 100644
--- a/Documentation/guides/application-developer.rst
+++ b/Documentation/guides/application-developer.rst
@@ -348,7 +348,7 @@ The libcamera library uses the concept of `signals and slots` (similar to `Qt
 Signals and Slots`_) to connect events with callbacks to handle them.
 
 .. _signals and slots: https://libcamera.org/api-html/classlibcamera_1_1Signal.html#details
-.. _Qt Signals and Slots: https://doc.qt.io/qt-5/signalsandslots.html
+.. _Qt Signals and Slots: https://doc.qt.io/qt-6/signalsandslots.html
 
 The ``Camera`` device emits two signals that applications can connect to in
 order to execute callbacks on frame completion events.
diff --git a/Documentation/guides/pipeline-handler.rst b/Documentation/guides/pipeline-handler.rst
index 26dc9358..2046a2e7 100644
--- a/Documentation/guides/pipeline-handler.rst
+++ b/Documentation/guides/pipeline-handler.rst
@@ -1422,7 +1422,7 @@ emitted triggers the execution of the connected slots.  A detailed description
 of the libcamera implementation is available in the `libcamera Signal and Slot`_
 classes documentation.
 
-.. _Qt Signals and Slots: https://doc.qt.io/qt-5/signalsandslots.html
+.. _Qt Signals and Slots: https://doc.qt.io/qt-6/signalsandslots.html
 .. _libcamera Signal and Slot: https://libcamera.org/api-html/classlibcamera_1_1Signal.html#details
 
 In order to notify applications about the availability of new frames and data,
diff --git a/README.rst b/README.rst
index 315738ee..e3b22850 100644
--- a/README.rst
+++ b/README.rst
@@ -120,12 +120,13 @@ setting the ``LIBCAMERA_LOG_LEVELS`` environment variable:
 Using GStreamer plugin
 ~~~~~~~~~~~~~~~~~~~~~~
 
-To use GStreamer plugin from source tree, set the following environment so that
-GStreamer can find it. This isn't necessary when libcamera is installed.
+To use the GStreamer plugin from the source tree, use the meson ``devenv``
+command.  This will create a new shell instance with the ``GST_PLUGIN_PATH``
+environment set accordingly.
 
 .. code::
 
-  export GST_PLUGIN_PATH=$(pwd)/build/src/gstreamer
+  meson devenv -C build
 
 The debugging tool ``gst-launch-1.0`` can be used to construct a pipeline and
 test it. The following pipeline will stream from the camera named "Camera 1"
@@ -174,6 +175,22 @@ Which can be received on another device over the network with:
    gst-launch-1.0 tcpclientsrc host=$DEVICE_IP port=5000 ! \
         multipartdemux ! jpegdec ! autovideosink
 
+The GStreamer element also supports multiple streams. This is achieved by
+requesting additionnal source pads. Downstream caps filteris can be used
+to choose specific parameters like resolution and pixel format. The pad
+property ``stream-role`` can be used to select a role.
+
+The following example displayis a 640x480 view finder while streamiing JPEG
+encoded 800x600 video. You can use the receiver pipleine above to view the
+remote stream from another device.
+
+.. code::
+
+   gst-launch-1.0 libcamerasrc name=cs src::stream-role=view-finder src_0::stream-role=video-recording \
+       cs.src ! queue ! video/x-raw,width=640,height=480 ! videoconvert ! autovideosink \
+       cs.src_0 ! queue ! video/x-raw,width=800,height=600 ! videoconvert ! \
+       jpegenc ! multipartmux ! tcpserversink host=0.0.0.0 port=5000
+
 .. section-end-getting-started
 
 Troubleshooting
diff --git a/include/libcamera/base/object.h b/include/libcamera/base/object.h
index 93333636..cb7e0a13 100644
--- a/include/libcamera/base/object.h
+++ b/include/libcamera/base/object.h
@@ -49,6 +49,8 @@ public:
 protected:
 	virtual void message(Message *msg);
 
+	bool assertThreadBound(const char *message);
+
 private:
 	friend class SignalBase;
 	friend class Thread;
diff --git a/include/libcamera/base/signal.h b/include/libcamera/base/signal.h
index 841e4b4c..444997b4 100644
--- a/include/libcamera/base/signal.h
+++ b/include/libcamera/base/signal.h
@@ -13,10 +13,11 @@
 #include <vector>
 
 #include <libcamera/base/bound_method.h>
-#include <libcamera/base/object.h>
 
 namespace libcamera {
 
+class Object;
+
 class SignalBase
 {
 public:
diff --git a/include/libcamera/internal/v4l2_subdevice.h b/include/libcamera/internal/v4l2_subdevice.h
index 69862de0..17db311b 100644
--- a/include/libcamera/internal/v4l2_subdevice.h
+++ b/include/libcamera/internal/v4l2_subdevice.h
@@ -36,7 +36,7 @@ struct V4L2SubdeviceCapability final : v4l2_subdev_capability {
 	}
 	bool hasStreams() const
 	{
-		return capabilities & V4L2_SUBDEV_CAP_MPLEXED;
+		return capabilities & V4L2_SUBDEV_CAP_STREAMS;
 	}
 };
 
diff --git a/include/libcamera/ipa/dcmipp.mojom b/include/libcamera/ipa/dcmipp.mojom
new file mode 100644
index 00000000..b784543c
--- /dev/null
+++ b/include/libcamera/ipa/dcmipp.mojom
@@ -0,0 +1,35 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+
+module ipa.dcmipp;
+
+import "include/libcamera/ipa/core.mojom";
+
+interface IPADcmippInterface {
+	init(libcamera.IPASettings settings,
+	     uint32 hwRevision,
+	     libcamera.IPACameraSensorInfo sensorInfo,
+	     libcamera.ControlInfoMap sensorControls)
+		=> (int32 ret, libcamera.ControlInfoMap ipaControls);
+	configure(libcamera.IPACameraSensorInfo sensorInfo,
+		  libcamera.ControlInfoMap sensorControls,
+		  uint32 ispDecimationRatio)
+		=> (int32 ret, libcamera.ControlInfoMap ipaControls);
+
+	start() => (int32 ret);
+	stop();
+
+	mapBuffers(array<libcamera.IPABuffer> buffers);
+	unmapBuffers(array<uint32> ids);
+
+	[async] processStatsBuffer(uint32 frame, uint32 bufferId);
+	[async] fillParamsBuffer(uint32 frame, uint32 bufferId);
+	[async] queueRequest(uint32 frame, libcamera.ControlList controls);
+};
+
+interface IPADcmippEventInterface {
+	statsBufferProcessed(uint32 bufferId);
+	paramsBufferReady(uint32 bufferId);
+	metadataReady(uint32 frame, libcamera.ControlList sensorControls);
+	setSensorControls(uint32 frame, libcamera.ControlList sensorControls);
+	setIspControls(uint32 frame, libcamera.ControlList ispControls);
+};
diff --git a/include/libcamera/ipa/meson.build b/include/libcamera/ipa/meson.build
index f3b4881c..b0471d63 100644
--- a/include/libcamera/ipa/meson.build
+++ b/include/libcamera/ipa/meson.build
@@ -62,6 +62,7 @@ libcamera_generated_ipa_headers += custom_target('core_ipa_serializer_h',
 
 # Mapping from pipeline handler name to mojom file
 pipeline_ipa_mojom_mapping = {
+    'dcmipp': 'dcmipp.mojom',
     'ipu3': 'ipu3.mojom',
     'rkisp1': 'rkisp1.mojom',
     'rpi/vc4': 'raspberrypi.mojom',
diff --git a/include/linux/README b/include/linux/README
index 9f61517a..101e4997 100644
--- a/include/linux/README
+++ b/include/linux/README
@@ -1,4 +1,4 @@
 # SPDX-License-Identifier: CC0-1.0
 
-Files in this directory are imported from v5.19 of the Linux kernel. Do not
+Files in this directory are imported from v6.7 of the Linux kernel. Do not
 modify them manually.
diff --git a/include/linux/dma-buf.h b/include/linux/dma-buf.h
index b1523cb8..5a6fda66 100644
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@ -85,6 +85,88 @@ struct dma_buf_sync {
 
 #define DMA_BUF_NAME_LEN	32
 
+/**
+ * struct dma_buf_export_sync_file - Get a sync_file from a dma-buf
+ *
+ * Userspace can perform a DMA_BUF_IOCTL_EXPORT_SYNC_FILE to retrieve the
+ * current set of fences on a dma-buf file descriptor as a sync_file.  CPU
+ * waits via poll() or other driver-specific mechanisms typically wait on
+ * whatever fences are on the dma-buf at the time the wait begins.  This
+ * is similar except that it takes a snapshot of the current fences on the
+ * dma-buf for waiting later instead of waiting immediately.  This is
+ * useful for modern graphics APIs such as Vulkan which assume an explicit
+ * synchronization model but still need to inter-operate with dma-buf.
+ *
+ * The intended usage pattern is the following:
+ *
+ *  1. Export a sync_file with flags corresponding to the expected GPU usage
+ *     via DMA_BUF_IOCTL_EXPORT_SYNC_FILE.
+ *
+ *  2. Submit rendering work which uses the dma-buf.  The work should wait on
+ *     the exported sync file before rendering and produce another sync_file
+ *     when complete.
+ *
+ *  3. Import the rendering-complete sync_file into the dma-buf with flags
+ *     corresponding to the GPU usage via DMA_BUF_IOCTL_IMPORT_SYNC_FILE.
+ *
+ * Unlike doing implicit synchronization via a GPU kernel driver's exec ioctl,
+ * the above is not a single atomic operation.  If userspace wants to ensure
+ * ordering via these fences, it is the respnosibility of userspace to use
+ * locks or other mechanisms to ensure that no other context adds fences or
+ * submits work between steps 1 and 3 above.
+ */
+struct dma_buf_export_sync_file {
+	/**
+	 * @flags: Read/write flags
+	 *
+	 * Must be DMA_BUF_SYNC_READ, DMA_BUF_SYNC_WRITE, or both.
+	 *
+	 * If DMA_BUF_SYNC_READ is set and DMA_BUF_SYNC_WRITE is not set,
+	 * the returned sync file waits on any writers of the dma-buf to
+	 * complete.  Waiting on the returned sync file is equivalent to
+	 * poll() with POLLIN.
+	 *
+	 * If DMA_BUF_SYNC_WRITE is set, the returned sync file waits on
+	 * any users of the dma-buf (read or write) to complete.  Waiting
+	 * on the returned sync file is equivalent to poll() with POLLOUT.
+	 * If both DMA_BUF_SYNC_WRITE and DMA_BUF_SYNC_READ are set, this
+	 * is equivalent to just DMA_BUF_SYNC_WRITE.
+	 */
+	__u32 flags;
+	/** @fd: Returned sync file descriptor */
+	__s32 fd;
+};
+
+/**
+ * struct dma_buf_import_sync_file - Insert a sync_file into a dma-buf
+ *
+ * Userspace can perform a DMA_BUF_IOCTL_IMPORT_SYNC_FILE to insert a
+ * sync_file into a dma-buf for the purposes of implicit synchronization
+ * with other dma-buf consumers.  This allows clients using explicitly
+ * synchronized APIs such as Vulkan to inter-op with dma-buf consumers
+ * which expect implicit synchronization such as OpenGL or most media
+ * drivers/video.
+ */
+struct dma_buf_import_sync_file {
+	/**
+	 * @flags: Read/write flags
+	 *
+	 * Must be DMA_BUF_SYNC_READ, DMA_BUF_SYNC_WRITE, or both.
+	 *
+	 * If DMA_BUF_SYNC_READ is set and DMA_BUF_SYNC_WRITE is not set,
+	 * this inserts the sync_file as a read-only fence.  Any subsequent
+	 * implicitly synchronized writes to this dma-buf will wait on this
+	 * fence but reads will not.
+	 *
+	 * If DMA_BUF_SYNC_WRITE is set, this inserts the sync_file as a
+	 * write fence.  All subsequent implicitly synchronized access to
+	 * this dma-buf will wait on this fence.
+	 */
+	__u32 flags;
+	/** @fd: Sync file descriptor */
+	__s32 fd;
+};
+
 #define DMA_BUF_BASE		'b'
 #define DMA_BUF_IOCTL_SYNC	_IOW(DMA_BUF_BASE, 0, struct dma_buf_sync)
 
@@ -94,5 +176,7 @@ struct dma_buf_sync {
 #define DMA_BUF_SET_NAME	_IOW(DMA_BUF_BASE, 1, const char *)
 #define DMA_BUF_SET_NAME_A	_IOW(DMA_BUF_BASE, 1, __u32)
 #define DMA_BUF_SET_NAME_B	_IOW(DMA_BUF_BASE, 1, __u64)
+#define DMA_BUF_IOCTL_EXPORT_SYNC_FILE	_IOWR(DMA_BUF_BASE, 2, struct dma_buf_export_sync_file)
+#define DMA_BUF_IOCTL_IMPORT_SYNC_FILE	_IOW(DMA_BUF_BASE, 3, struct dma_buf_import_sync_file)
 
 #endif
diff --git a/include/linux/drm_fourcc.h b/include/linux/drm_fourcc.h
index 1496e097..d6c83d9c 100644
--- a/include/linux/drm_fourcc.h
+++ b/include/linux/drm_fourcc.h
@@ -88,6 +88,18 @@ extern "C" {
  *
  * The authoritative list of format modifier codes is found in
  * `include/uapi/drm/drm_fourcc.h`
+ *
+ * Open Source User Waiver
+ * -----------------------
+ *
+ * Because this is the authoritative source for pixel formats and modifiers
+ * referenced by GL, Vulkan extensions and other standards and hence used both
+ * by open source and closed source driver stacks, the usual requirement for an
+ * upstream in-kernel or open source userspace user does not apply.
+ *
+ * To ensure, as much as feasible, compatibility across stacks and avoid
+ * confusion with incompatible enumerations stakeholders for all relevant driver
+ * stacks should approve additions.
  */
 
 #define fourcc_code(a, b, c, d) ((__u32)(a) | ((__u32)(b) << 8) | \
@@ -99,18 +111,42 @@ extern "C" {
 #define DRM_FORMAT_INVALID	0
 
 /* color index */
+#define DRM_FORMAT_C1		fourcc_code('C', '1', ' ', ' ') /* [7:0] C0:C1:C2:C3:C4:C5:C6:C7 1:1:1:1:1:1:1:1 eight pixels/byte */
+#define DRM_FORMAT_C2		fourcc_code('C', '2', ' ', ' ') /* [7:0] C0:C1:C2:C3 2:2:2:2 four pixels/byte */
+#define DRM_FORMAT_C4		fourcc_code('C', '4', ' ', ' ') /* [7:0] C0:C1 4:4 two pixels/byte */
 #define DRM_FORMAT_C8		fourcc_code('C', '8', ' ', ' ') /* [7:0] C */
 
-/* 8 bpp Red */
+/* 1 bpp Darkness (inverse relationship between channel value and brightness) */
+#define DRM_FORMAT_D1		fourcc_code('D', '1', ' ', ' ') /* [7:0] D0:D1:D2:D3:D4:D5:D6:D7 1:1:1:1:1:1:1:1 eight pixels/byte */
+
+/* 2 bpp Darkness (inverse relationship between channel value and brightness) */
+#define DRM_FORMAT_D2		fourcc_code('D', '2', ' ', ' ') /* [7:0] D0:D1:D2:D3 2:2:2:2 four pixels/byte */
+
+/* 4 bpp Darkness (inverse relationship between channel value and brightness) */
+#define DRM_FORMAT_D4		fourcc_code('D', '4', ' ', ' ') /* [7:0] D0:D1 4:4 two pixels/byte */
+
+/* 8 bpp Darkness (inverse relationship between channel value and brightness) */
+#define DRM_FORMAT_D8		fourcc_code('D', '8', ' ', ' ') /* [7:0] D */
+
+/* 1 bpp Red (direct relationship between channel value and brightness) */
+#define DRM_FORMAT_R1		fourcc_code('R', '1', ' ', ' ') /* [7:0] R0:R1:R2:R3:R4:R5:R6:R7 1:1:1:1:1:1:1:1 eight pixels/byte */
+
+/* 2 bpp Red (direct relationship between channel value and brightness) */
+#define DRM_FORMAT_R2		fourcc_code('R', '2', ' ', ' ') /* [7:0] R0:R1:R2:R3 2:2:2:2 four pixels/byte */
+
+/* 4 bpp Red (direct relationship between channel value and brightness) */
+#define DRM_FORMAT_R4		fourcc_code('R', '4', ' ', ' ') /* [7:0] R0:R1 4:4 two pixels/byte */
+
+/* 8 bpp Red (direct relationship between channel value and brightness) */
 #define DRM_FORMAT_R8		fourcc_code('R', '8', ' ', ' ') /* [7:0] R */
 
-/* 10 bpp Red */
+/* 10 bpp Red (direct relationship between channel value and brightness) */
 #define DRM_FORMAT_R10		fourcc_code('R', '1', '0', ' ') /* [15:0] x:R 6:10 little endian */
 
-/* 12 bpp Red */
+/* 12 bpp Red (direct relationship between channel value and brightness) */
 #define DRM_FORMAT_R12		fourcc_code('R', '1', '2', ' ') /* [15:0] x:R 4:12 little endian */
 
-/* 16 bpp Red */
+/* 16 bpp Red (direct relationship between channel value and brightness) */
 #define DRM_FORMAT_R16		fourcc_code('R', '1', '6', ' ') /* [15:0] R little endian */
 
 /* 16 bpp RG */
@@ -287,6 +323,8 @@ extern "C" {
  * index 1 = Cr:Cb plane, [39:0] Cr1:Cb1:Cr0:Cb0 little endian
  */
 #define DRM_FORMAT_NV15		fourcc_code('N', 'V', '1', '5') /* 2x2 subsampled Cr:Cb plane */
+#define DRM_FORMAT_NV20		fourcc_code('N', 'V', '2', '0') /* 2x1 subsampled Cr:Cb plane */
+#define DRM_FORMAT_NV30		fourcc_code('N', 'V', '3', '0') /* non-subsampled Cr:Cb plane */
 
 /*
  * 2 plane YCbCr MSB aligned
@@ -626,7 +664,7 @@ extern "C" {
  *
  * The main surface is Y-tiled and is at plane index 0 whereas CCS is linear
  * and at index 1. The clear color is stored at index 2, and the pitch should
- * be ignored. The clear color structure is 256 bits. The first 128 bits
+ * be 64 bytes aligned. The clear color structure is 256 bits. The first 128 bits
  * represents Raw Clear Color Red, Green, Blue and Alpha color each represented
  * by 32 bits. The raw clear color is consumed by the 3d engine and generates
  * the converted clear color of size 64 bits. The first 32 bits store the Lower
@@ -679,13 +717,56 @@ extern "C" {
  * outside of the GEM object in a reserved memory area dedicated for the
  * storage of the CCS data for all RC/RC_CC/MC compressible GEM objects. The
  * main surface pitch is required to be a multiple of four Tile 4 widths. The
- * clear color is stored at plane index 1 and the pitch should be ignored. The
- * format of the 256 bits of clear color data matches the one used for the
- * I915_FORMAT_MOD_Y_TILED_GEN12_RC_CCS_CC modifier, see its description
+ * clear color is stored at plane index 1 and the pitch should be 64 bytes
+ * aligned. The format of the 256 bits of clear color data matches the one used
+ * for the I915_FORMAT_MOD_Y_TILED_GEN12_RC_CCS_CC modifier, see its description
  * for details.
  */
 #define I915_FORMAT_MOD_4_TILED_DG2_RC_CCS_CC fourcc_mod_code(INTEL, 12)
 
+/*
+ * Intel Color Control Surfaces (CCS) for display ver. 14 render compression.
+ *
+ * The main surface is tile4 and at plane index 0, the CCS is linear and
+ * at index 1. A 64B CCS cache line corresponds to an area of 4x1 tiles in
+ * main surface. In other words, 4 bits in CCS map to a main surface cache
+ * line pair. The main surface pitch is required to be a multiple of four
+ * tile4 widths.
+ */
+#define I915_FORMAT_MOD_4_TILED_MTL_RC_CCS fourcc_mod_code(INTEL, 13)
+
+/*
+ * Intel Color Control Surfaces (CCS) for display ver. 14 media compression
+ *
+ * The main surface is tile4 and at plane index 0, the CCS is linear and
+ * at index 1. A 64B CCS cache line corresponds to an area of 4x1 tiles in
+ * main surface. In other words, 4 bits in CCS map to a main surface cache
+ * line pair. The main surface pitch is required to be a multiple of four
+ * tile4 widths. For semi-planar formats like NV12, CCS planes follow the
+ * Y and UV planes i.e., planes 0 and 1 are used for Y and UV surfaces,
+ * planes 2 and 3 for the respective CCS.
+ */
+#define I915_FORMAT_MOD_4_TILED_MTL_MC_CCS fourcc_mod_code(INTEL, 14)
+
+/*
+ * Intel Color Control Surface with Clear Color (CCS) for display ver. 14 render
+ * compression.
+ *
+ * The main surface is tile4 and is at plane index 0 whereas CCS is linear
+ * and at index 1. The clear color is stored at index 2, and the pitch should
+ * be ignored. The clear color structure is 256 bits. The first 128 bits
+ * represents Raw Clear Color Red, Green, Blue and Alpha color each represented
+ * by 32 bits. The raw clear color is consumed by the 3d engine and generates
+ * the converted clear color of size 64 bits. The first 32 bits store the Lower
+ * Converted Clear Color value and the next 32 bits store the Higher Converted
+ * Clear Color value when applicable. The Converted Clear Color values are
+ * consumed by the DE. The last 64 bits are used to store Color Discard Enable
+ * and Depth Clear Value Valid which are ignored by the DE. A CCS cache line
+ * corresponds to an area of 4x1 tiles in the main surface. The main surface
+ * pitch is required to be a multiple of 4 tile widths.
+ */
+#define I915_FORMAT_MOD_4_TILED_MTL_RC_CCS_CC fourcc_mod_code(INTEL, 15)
+
 /*
  * IPU3 Bayer packing layout
  *
@@ -795,6 +876,35 @@ extern "C" {
  */
 #define DRM_FORMAT_MOD_VIVANTE_SPLIT_SUPER_TILED fourcc_mod_code(VIVANTE, 4)
 
+/*
+ * Vivante TS (tile-status) buffer modifiers. They can be combined with all of
+ * the color buffer tiling modifiers defined above. When TS is present it's a
+ * separate buffer containing the clear/compression status of each tile. The
+ * modifiers are defined as VIVANTE_MOD_TS_c_s, where c is the color buffer
+ * tile size in bytes covered by one entry in the status buffer and s is the
+ * number of status bits per entry.
+ * We reserve the top 8 bits of the Vivante modifier space for tile status
+ * clear/compression modifiers, as future cores might add some more TS layout
+ * variations.
+ */
+#define VIVANTE_MOD_TS_64_4               (1ULL << 48)
+#define VIVANTE_MOD_TS_64_2               (2ULL << 48)
+#define VIVANTE_MOD_TS_128_4              (3ULL << 48)
+#define VIVANTE_MOD_TS_256_4              (4ULL << 48)
+#define VIVANTE_MOD_TS_MASK               (0xfULL << 48)
+
+/*
+ * Vivante compression modifiers. Those depend on a TS modifier being present
+ * as the TS bits get reinterpreted as compression tags instead of simple
+ * clear markers when compression is enabled.
+ */
+#define VIVANTE_MOD_COMP_DEC400           (1ULL << 52)
+#define VIVANTE_MOD_COMP_MASK             (0xfULL << 52)
+
+/* Masking out the extension bits will yield the base modifier. */
+#define VIVANTE_MOD_EXT_MASK              (VIVANTE_MOD_TS_MASK | \
+                                           VIVANTE_MOD_COMP_MASK)
+
 /* NVIDIA frame buffer modifiers */
 
 /*
@@ -1440,6 +1550,7 @@ drm_fourcc_canonicalize_nvidia_format_mod(__u64 modifier)
 #define AMD_FMT_MOD_TILE_VER_GFX9 1
 #define AMD_FMT_MOD_TILE_VER_GFX10 2
 #define AMD_FMT_MOD_TILE_VER_GFX10_RBPLUS 3
+#define AMD_FMT_MOD_TILE_VER_GFX11 4
 
 /*
  * 64K_S is the same for GFX9/GFX10/GFX10_RBPLUS and hence has GFX9 as canonical
@@ -1455,6 +1566,7 @@ drm_fourcc_canonicalize_nvidia_format_mod(__u64 modifier)
 #define AMD_FMT_MOD_TILE_GFX9_64K_S_X 25
 #define AMD_FMT_MOD_TILE_GFX9_64K_D_X 26
 #define AMD_FMT_MOD_TILE_GFX9_64K_R_X 27
+#define AMD_FMT_MOD_TILE_GFX11_256K_R_X 31
 
 #define AMD_FMT_MOD_DCC_BLOCK_64B 0
 #define AMD_FMT_MOD_DCC_BLOCK_128B 1
diff --git a/include/linux/intel-ipu3.h b/include/linux/intel-ipu3.h
index 5c298ec5..bd771f1b 100644
--- a/include/linux/intel-ipu3.h
+++ b/include/linux/intel-ipu3.h
@@ -626,8 +626,11 @@ struct ipu3_uapi_stats_3a {
  * @b:	white balance gain for B channel.
  * @gb:	white balance gain for Gb channel.
  *
- * Precision u3.13, range [0, 8). White balance correction is done by applying
- * a multiplicative gain to each color channels prior to BNR.
+ * For BNR parameters WB gain factor for the three channels [Ggr, Ggb, Gb, Gr].
+ * Their precision is U3.13 and the range is (0, 8) and the actual gain is
+ * Gx + 1, it is typically Gx = 1.
+ *
+ * Pout = {Pin * (1 + Gx)}.
  */
 struct ipu3_uapi_bnr_static_config_wb_gains_config {
 	__u16 gr;
diff --git a/include/linux/media-bus-format.h b/include/linux/media-bus-format.h
index 0dfc11ee..f05f747e 100644
--- a/include/linux/media-bus-format.h
+++ b/include/linux/media-bus-format.h
@@ -34,7 +34,7 @@
 
 #define MEDIA_BUS_FMT_FIXED			0x0001
 
-/* RGB - next is	0x101e */
+/* RGB - next is	0x1026 */
 #define MEDIA_BUS_FMT_RGB444_1X12		0x1016
 #define MEDIA_BUS_FMT_RGB444_2X8_PADHI_BE	0x1001
 #define MEDIA_BUS_FMT_RGB444_2X8_PADHI_LE	0x1002
@@ -46,8 +46,12 @@
 #define MEDIA_BUS_FMT_RGB565_2X8_BE		0x1007
 #define MEDIA_BUS_FMT_RGB565_2X8_LE		0x1008
 #define MEDIA_BUS_FMT_RGB666_1X18		0x1009
+#define MEDIA_BUS_FMT_RGB666_2X9_BE		0x1025
+#define MEDIA_BUS_FMT_BGR666_1X18		0x1023
 #define MEDIA_BUS_FMT_RBG888_1X24		0x100e
 #define MEDIA_BUS_FMT_RGB666_1X24_CPADHI	0x1015
+#define MEDIA_BUS_FMT_BGR666_1X24_CPADHI	0x1024
+#define MEDIA_BUS_FMT_RGB565_1X24_CPADHI	0x1022
 #define MEDIA_BUS_FMT_RGB666_1X7X3_SPWG		0x1010
 #define MEDIA_BUS_FMT_BGR888_1X24		0x1013
 #define MEDIA_BUS_FMT_BGR888_3X8		0x101b
@@ -59,13 +63,17 @@
 #define MEDIA_BUS_FMT_RGB888_3X8_DELTA		0x101d
 #define MEDIA_BUS_FMT_RGB888_1X7X4_SPWG		0x1011
 #define MEDIA_BUS_FMT_RGB888_1X7X4_JEIDA	0x1012
+#define MEDIA_BUS_FMT_RGB666_1X30_CPADLO	0x101e
+#define MEDIA_BUS_FMT_RGB888_1X30_CPADLO	0x101f
 #define MEDIA_BUS_FMT_ARGB8888_1X32		0x100d
 #define MEDIA_BUS_FMT_RGB888_1X32_PADHI		0x100f
 #define MEDIA_BUS_FMT_RGB101010_1X30		0x1018
+#define MEDIA_BUS_FMT_RGB666_1X36_CPADLO	0x1020
+#define MEDIA_BUS_FMT_RGB888_1X36_CPADLO	0x1021
 #define MEDIA_BUS_FMT_RGB121212_1X36		0x1019
 #define MEDIA_BUS_FMT_RGB161616_1X48		0x101a
 
-/* YUV (including grey) - next is	0x202e */
+/* YUV (including grey) - next is	0x202f */
 #define MEDIA_BUS_FMT_Y8_1X8			0x2001
 #define MEDIA_BUS_FMT_UV8_1X8			0x2015
 #define MEDIA_BUS_FMT_UYVY8_1_5X8		0x2002
@@ -88,6 +96,7 @@
 #define MEDIA_BUS_FMT_YUYV12_2X12		0x201e
 #define MEDIA_BUS_FMT_YVYU12_2X12		0x201f
 #define MEDIA_BUS_FMT_Y14_1X14			0x202d
+#define MEDIA_BUS_FMT_Y16_1X16			0x202e
 #define MEDIA_BUS_FMT_UYVY8_1X16		0x200f
 #define MEDIA_BUS_FMT_VYUY8_1X16		0x2010
 #define MEDIA_BUS_FMT_YUYV8_1X16		0x2011
diff --git a/include/linux/media.h b/include/linux/media.h
index e3123d1a..b5a77bbf 100644
--- a/include/linux/media.h
+++ b/include/linux/media.h
@@ -20,7 +20,6 @@
 #ifndef __LINUX_MEDIA_H
 #define __LINUX_MEDIA_H
 
-#include <stdint.h>
 #include <linux/ioctl.h>
 #include <linux/types.h>
 
@@ -141,8 +140,8 @@ struct media_device_info {
 #define MEDIA_ENT_F_DV_ENCODER			(MEDIA_ENT_F_BASE + 0x6002)
 
 /* Entity flags */
-#define MEDIA_ENT_FL_DEFAULT			(1 << 0)
-#define MEDIA_ENT_FL_CONNECTOR			(1 << 1)
+#define MEDIA_ENT_FL_DEFAULT			(1U << 0)
+#define MEDIA_ENT_FL_CONNECTOR			(1U << 1)
 
 /* OR with the entity id value to find the next entity */
 #define MEDIA_ENT_ID_FLAG_NEXT			(1U << 31)
@@ -204,9 +203,9 @@ struct media_entity_desc {
 	};
 };
 
-#define MEDIA_PAD_FL_SINK			(1 << 0)
-#define MEDIA_PAD_FL_SOURCE			(1 << 1)
-#define MEDIA_PAD_FL_MUST_CONNECT		(1 << 2)
+#define MEDIA_PAD_FL_SINK			(1U << 0)
+#define MEDIA_PAD_FL_SOURCE			(1U << 1)
+#define MEDIA_PAD_FL_MUST_CONNECT		(1U << 2)
 
 struct media_pad_desc {
 	__u32 entity;		/* entity ID */
@@ -215,14 +214,14 @@ struct media_pad_desc {
 	__u32 reserved[2];
 };
 
-#define MEDIA_LNK_FL_ENABLED			(1 << 0)
-#define MEDIA_LNK_FL_IMMUTABLE			(1 << 1)
-#define MEDIA_LNK_FL_DYNAMIC			(1 << 2)
+#define MEDIA_LNK_FL_ENABLED			(1U << 0)
+#define MEDIA_LNK_FL_IMMUTABLE			(1U << 1)
+#define MEDIA_LNK_FL_DYNAMIC			(1U << 2)
 
 #define MEDIA_LNK_FL_LINK_TYPE			(0xf << 28)
-#  define MEDIA_LNK_FL_DATA_LINK		(0 << 28)
-#  define MEDIA_LNK_FL_INTERFACE_LINK		(1 << 28)
-#  define MEDIA_LNK_FL_ANCILLARY_LINK		(2 << 28)
+#  define MEDIA_LNK_FL_DATA_LINK		(0U << 28)
+#  define MEDIA_LNK_FL_INTERFACE_LINK		(1U << 28)
+#  define MEDIA_LNK_FL_ANCILLARY_LINK		(2U << 28)
 
 struct media_link_desc {
 	struct media_pad_desc source;
@@ -277,7 +276,7 @@ struct media_links_enum {
  * struct media_device_info.
  */
 #define MEDIA_V2_ENTITY_HAS_FLAGS(media_version) \
-	((media_version) >= ((4 << 16) | (19 << 8) | 0))
+	((media_version) >= ((4U << 16) | (19U << 8) | 0U))
 
 struct media_v2_entity {
 	__u32 id;
@@ -312,7 +311,7 @@ struct media_v2_interface {
  * struct media_device_info.
  */
 #define MEDIA_V2_PAD_HAS_INDEX(media_version) \
-	((media_version) >= ((4 << 16) | (19 << 8) | 0))
+	((media_version) >= ((4U << 16) | (19U << 8) | 0U))
 
 struct media_v2_pad {
 	__u32 id;
@@ -415,7 +414,7 @@ struct media_v2_topology {
 #define MEDIA_INTF_T_ALSA_TIMER                (MEDIA_INTF_T_ALSA_BASE + 7)
 
 /* Obsolete symbol for media_version, no longer used in the kernel */
-#define MEDIA_API_VERSION			((0 << 16) | (1 << 8) | 0)
+#define MEDIA_API_VERSION			((0U << 16) | (1U << 8) | 0U)
 
 
 #endif /* __LINUX_MEDIA_H */
diff --git a/include/linux/stm32-dcmipp-config.h b/include/linux/stm32-dcmipp-config.h
new file mode 100644
index 00000000..85b4cf73
--- /dev/null
+++ b/include/linux/stm32-dcmipp-config.h
@@ -0,0 +1,196 @@
+/* SPDX-License-Identifier: ((GPL-2.0+ WITH Linux-syscall-note) OR MIT) */
+/*
+ * STM32 DCMIPP ISP userspace API
+ * Copyright (C) STMicroelectronics SA 2023
+ */
+
+#ifndef _UAPI_STM32_DCMIPP_CONFIG_H
+#define _UAPI_STM32_DCMIPP_CONFIG_H
+
+#include <linux/types.h>
+
+/* Bad Pixel Removal */
+#define STM32_DCMIPP_ISP_BPR		(1U << 0)
+/* Black Level Correction */
+#define STM32_DCMIPP_ISP_BLC		(1U << 1)
+/* Exposure Control */
+#define STM32_DCMIPP_ISP_EX		(1U << 2)
+/* Demosaicing filters */
+#define STM32_DCMIPP_ISP_DM		(1U << 3)
+/* Color conversion Control */
+#define STM32_DCMIPP_ISP_CC		(1U << 4)
+/* Contrast Enhancement */
+#define STM32_DCMIPP_ISP_CE		(1U << 5)
+
+/**
+ * struct stm32_dcmipp_isp_bpr_cfg - STM32 DCMIPP ISP bad pixel removal
+ *
+ * @en: enable / disable the bad pixel removal block
+ * @strength: strength (aggressiveness) of the bad pixel detection
+ */
+struct stm32_dcmipp_isp_bpr_cfg {
+	__u32 en;
+	__u32 strength;
+};
+
+/**
+ * struct stm32_dcmipp_isp_blc_cfg - STM32 DCMIPP ISP black level correction
+ *
+ * @en: enable / disable the black level correction block
+ * @blc_r: Correction on the red component
+ * @blc_g: Correction on the green component
+ * @blc_b: Correction on the blue component
+ */
+struct stm32_dcmipp_isp_blc_cfg {
+	__u32 en;
+	__u8 blc_r;
+	__u8 blc_g;
+	__u8 blc_b;
+};
+
+/**
+ * struct stm32_dcmipp_isp_ex_cfg - STM32 DCMIPP ISP exposure control
+ *
+ * @en: enable / disable the exposure control block
+ * @shift_r: red component exposure shift
+ * @mult_r: red component exposure multiplier
+ * @shift_g: green component exposure shift
+ * @mult_g: green component exposure multiplier
+ * @shift_b: blue component exposure shift
+ * @mult_b: blue component exposure multiplier
+ */
+struct stm32_dcmipp_isp_ex_cfg {
+	__u32 en;
+	__u8 shift_r;
+	__u8 mult_r;
+	__u8 shift_g;
+	__u8 mult_g;
+	__u8 shift_b;
+	__u8 mult_b;
+};
+
+/**
+ * struct stm32_dcmipp_isp_dm_cfg - STM32 DCMIPP ISP demosaicing filters
+ *
+ * @en: enable / disable the demosaicing block
+ * @edge: strength of the edge detection
+ * @lineh: strength of the horizontal line detection
+ * @linev: strength of the vertical line detection
+ * @peak: strength of the peak detection
+ */
+struct stm32_dcmipp_isp_dm_cfg {
+	__u32 en;
+	__u8 edge;
+	__u8 lineh;
+	__u8 linev;
+	__u8 peak;
+};
+
+enum stm32_dcmipp_isp_cc_clamp {
+	STM32_DCMIPP_ISP_CC_CLAMP_DISABLED,
+	STM32_DCMIPP_ISP_CC_CLAMP_Y235_U240_V240,
+	STM32_DCMIPP_ISP_CC_CLAMP_YUV235,
+};
+
+/**
+ * struct stm32_dcmipp_isp_cc_cfg - STM32 DCMIPP ISP color conversion
+ *
+ * @en: enable / disable the color conversion block
+ * @clamp: clamp configuration (from enum stm32_dcmipp_isp_cc_clamp)
+ * @rr: row 1 col 1 value of the matrix
+ * @rg: row 1 col 2 value of the matrix
+ * @rb: row 1 col 3 value of the matrix
+ * @ra: row 1 added value of the matrix
+ * @gr: row 2 col 1 value of the matrix
+ * @gg: row 2 col 2 value of the matrix
+ * @gb: row 2 col 3 value of the matrix
+ * @ga: row 2 added value of the matrix
+ * @br: row 3 col 1 value of the matrix
+ * @bg: row 3 col 2 value of the matrix
+ * @bb: row 3 col 3 value of the matrix
+ * @ba: row 3 added value of the matrix
+ */
+struct stm32_dcmipp_isp_cc_cfg {
+	__u32 en;
+	__u32 clamp;
+	__u16 rr;
+	__u16 rg;
+	__u16 rb;
+	__u16 ra;
+	__u16 gr;
+	__u16 gg;
+	__u16 gb;
+	__u16 ga;
+	__u16 br;
+	__u16 bg;
+	__u16 bb;
+	__u16 ba;
+};
+
+/**
+ * struct stm32_dcmipp_isp_ce_cfg - STM32 DCMIPP ISP contrast enhancement
+ *
+ * @en: enable / disable the contrast enhancement block
+ * @lum: 9 elements table of luminance enhancement (value 16 is neutral)
+ */
+struct stm32_dcmipp_isp_ce_cfg {
+	__u32 en;
+	__u8 lum[9];
+};
+
+/**
+ * struct stm32_dcmipp_isp_ctrls_cfg - STM32 DCMIPP ISP Controls
+ *
+ * @bpr_cfg: configuration of the bad pixel removal block
+ * @blc_cfg: configuration of the black level correction block
+ * @ex_cfg: configuration of the exposure block
+ * @dm_cfg: configuration of the demosaicing filters block
+ * @cc_cfg: configuration of the color conversion block
+ * @ce_cfg: configuration of the contrast enhancement block
+ */
+struct stm32_dcmipp_isp_ctrls_cfg {
+	struct stm32_dcmipp_isp_bpr_cfg bpr_cfg;
+	struct stm32_dcmipp_isp_blc_cfg blc_cfg;
+	struct stm32_dcmipp_isp_ex_cfg ex_cfg;
+	struct stm32_dcmipp_isp_dm_cfg dm_cfg;
+	struct stm32_dcmipp_isp_cc_cfg cc_cfg;
+	struct stm32_dcmipp_isp_ce_cfg ce_cfg;
+};
+
+/**
+ * struct stm32_dcmipp_params_cfg - STM32 DCMIPP ISP Input Parameters Meta Data
+ *
+ * @module_cfg_update: mask the config bits of which module should be updated
+ * @ctrls: configuration of other ISP blocks
+ */
+struct stm32_dcmipp_params_cfg {
+	__u32 module_cfg_update;
+
+	struct stm32_dcmipp_isp_ctrls_cfg ctrls;
+};
+
+/**
+ * struct stm32_dcmipp_stat_avr_bins - average & bins statistics
+ *
+ * @average_rgb[3]: average value of R/G/B components
+ * @bins[12]: 12 values histogram
+ */
+struct stm32_dcmipp_stat_avr_bins {
+	__u32 average_RGB[3];
+	__u32 bins[12];
+};
+
+/**
+ * struct stm32_dcmipp_stat_buf - statistics buffer
+ *
+ * @pre: average & bins statistics at pre-demosaicing location
+ * @post: average & bins statistics at post-demosaicing location
+ * @bad_pixel_count: number of bad pixels detected in the frame
+ */
+struct stm32_dcmipp_stat_buf {
+	struct stm32_dcmipp_stat_avr_bins pre;
+	struct stm32_dcmipp_stat_avr_bins post;
+	__u32 bad_pixel_count;
+};
+
+#endif
diff --git a/include/linux/v4l2-common.h b/include/linux/v4l2-common.h
index 14de1731..c3ca11e3 100644
--- a/include/linux/v4l2-common.h
+++ b/include/linux/v4l2-common.h
@@ -10,45 +10,6 @@
  *
  * Copyright (C) 2012 Nokia Corporation
  * Contact: Sakari Ailus <sakari.ailus@iki.fi>
- *
- *  This program is free software; you can redistribute it and/or modify
- *  it under the terms of the GNU General Public License as published by
- *  the Free Software Foundation; either version 2 of the License, or
- *  (at your option) any later version.
- *
- *  This program is distributed in the hope that it will be useful,
- *  but WITHOUT ANY WARRANTY; without even the implied warranty of
- *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- *  GNU General Public License for more details.
- *
- *  Alternatively you can redistribute this file under the terms of the
- *  BSD license as stated below:
- *
- *  Redistribution and use in source and binary forms, with or without
- *  modification, are permitted provided that the following conditions
- *  are met:
- *  1. Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *  2. Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *  3. The names of its contributors may not be used to endorse or promote
- *     products derived from this software without specific prior written
- *     permission.
- *
- *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
- *  TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- *  PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
- *  LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
- *  NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
- *  SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
  */
 
 #ifndef __V4L2_COMMON__
diff --git a/include/linux/v4l2-controls.h b/include/linux/v4l2-controls.h
index 9d2a8237..23772e04 100644
--- a/include/linux/v4l2-controls.h
+++ b/include/linux/v4l2-controls.h
@@ -4,44 +4,6 @@
  *
  *  Copyright (C) 1999-2012 the contributors
  *
- *  This program is free software; you can redistribute it and/or modify
- *  it under the terms of the GNU General Public License as published by
- *  the Free Software Foundation; either version 2 of the License, or
- *  (at your option) any later version.
- *
- *  This program is distributed in the hope that it will be useful,
- *  but WITHOUT ANY WARRANTY; without even the implied warranty of
- *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- *  GNU General Public License for more details.
- *
- *  Alternatively you can redistribute this file under the terms of the
- *  BSD license as stated below:
- *
- *  Redistribution and use in source and binary forms, with or without
- *  modification, are permitted provided that the following conditions
- *  are met:
- *  1. Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *  2. Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *  3. The names of its contributors may not be used to endorse or promote
- *     products derived from this software without specific prior written
- *     permission.
- *
- *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
- *  TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- *  PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
- *  LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
- *  NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
- *  SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
  *  The contents of this header was split off from videodev2.h. All control
  *  definitions should be added to this header, which is included by
  *  videodev2.h.
@@ -153,8 +115,10 @@ enum v4l2_colorfx {
 
 /* USER-class private control IDs */
 
-/* The base for the meye driver controls. See linux/meye.h for the list
- * of controls. We reserve 16 controls for this driver. */
+/*
+ * The base for the meye driver controls. This driver was removed, but
+ * we keep this define in case any software still uses it.
+ */
 #define V4L2_CID_USER_MEYE_BASE			(V4L2_CID_USER_BASE + 0x1000)
 
 /* The base for the bttv driver controls.
@@ -229,6 +193,24 @@ enum v4l2_colorfx {
  */
 #define V4L2_CID_USER_ISL7998X_BASE		(V4L2_CID_USER_BASE + 0x1180)
 
+/*
+ * The base for DW100 driver controls.
+ * We reserve 16 controls for this driver.
+ */
+#define V4L2_CID_USER_DW100_BASE		(V4L2_CID_USER_BASE + 0x1190)
+
+/*
+ * The base for Aspeed driver controls.
+ * We reserve 16 controls for this driver.
+ */
+#define V4L2_CID_USER_ASPEED_BASE		(V4L2_CID_USER_BASE + 0x11a0)
+
+/*
+ * The base for Nuvoton NPCM driver controls.
+ * We reserve 16 controls for this driver.
+ */
+#define V4L2_CID_USER_NPCM_BASE			(V4L2_CID_USER_BASE + 0x11b0)
+
 /* MPEG-class control IDs */
 /* The MPEG controls are applicable to all codec controls
  * and the 'MPEG' part of the define is historical */
@@ -828,6 +810,88 @@ enum v4l2_mpeg_video_frame_skip_mode {
 #define V4L2_CID_MPEG_VIDEO_DEC_DISPLAY_DELAY		(V4L2_CID_CODEC_BASE + 653)
 #define V4L2_CID_MPEG_VIDEO_DEC_DISPLAY_DELAY_ENABLE	(V4L2_CID_CODEC_BASE + 654)
 
+#define V4L2_CID_MPEG_VIDEO_AV1_PROFILE (V4L2_CID_CODEC_BASE + 655)
+/**
+ * enum v4l2_mpeg_video_av1_profile - AV1 profiles
+ *
+ * @V4L2_MPEG_VIDEO_AV1_PROFILE_MAIN: compliant decoders must be able to decode
+ * streams with seq_profile equal to 0.
+ * @V4L2_MPEG_VIDEO_AV1_PROFILE_HIGH: compliant decoders must be able to decode
+ * streams with seq_profile equal less than or equal to 1.
+ * @V4L2_MPEG_VIDEO_AV1_PROFILE_PROFESSIONAL: compliant decoders must be able to
+ * decode streams with seq_profile less than or equal to 2.
+ *
+ * Conveys the highest profile a decoder can work with.
+ */
+enum v4l2_mpeg_video_av1_profile {
+	V4L2_MPEG_VIDEO_AV1_PROFILE_MAIN = 0,
+	V4L2_MPEG_VIDEO_AV1_PROFILE_HIGH = 1,
+	V4L2_MPEG_VIDEO_AV1_PROFILE_PROFESSIONAL = 2,
+};
+
+#define V4L2_CID_MPEG_VIDEO_AV1_LEVEL (V4L2_CID_CODEC_BASE + 656)
+/**
+ * enum v4l2_mpeg_video_av1_level - AV1 levels
+ *
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_2_0: Level 2.0.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_2_1: Level 2.1.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_2_2: Level 2.2.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_2_3: Level 2.3.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_3_0: Level 3.0.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_3_1: Level 3.1.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_3_2: Level 3.2.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_3_3: Level 3.3.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_4_0: Level 4.0.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_4_1: Level 4.1.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_4_2: Level 4.2.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_4_3: Level 4.3.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_5_0: Level 5.0.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_5_1: Level 5.1.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_5_2: Level 5.2.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_5_3: Level 5.3.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_6_0: Level 6.0.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_6_1: Level 6.1.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_6_2: Level 6.2.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_6_3: Level 6.3.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_7_0: Level 7.0.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_7_1: Level 7.1.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_7_2: Level 7.2.
+ * @V4L2_MPEG_VIDEO_AV1_LEVEL_7_3: Level 7.3.
+ *
+ * Conveys the highest level a decoder can work with.
+ */
+enum v4l2_mpeg_video_av1_level {
+	V4L2_MPEG_VIDEO_AV1_LEVEL_2_0 = 0,
+	V4L2_MPEG_VIDEO_AV1_LEVEL_2_1 = 1,
+	V4L2_MPEG_VIDEO_AV1_LEVEL_2_2 = 2,
+	V4L2_MPEG_VIDEO_AV1_LEVEL_2_3 = 3,
+
+	V4L2_MPEG_VIDEO_AV1_LEVEL_3_0 = 4,
+	V4L2_MPEG_VIDEO_AV1_LEVEL_3_1 = 5,
+	V4L2_MPEG_VIDEO_AV1_LEVEL_3_2 = 6,
+	V4L2_MPEG_VIDEO_AV1_LEVEL_3_3 = 7,
+
+	V4L2_MPEG_VIDEO_AV1_LEVEL_4_0 = 8,
+	V4L2_MPEG_VIDEO_AV1_LEVEL_4_1 = 9,
+	V4L2_MPEG_VIDEO_AV1_LEVEL_4_2 = 10,
+	V4L2_MPEG_VIDEO_AV1_LEVEL_4_3 = 11,
+
+	V4L2_MPEG_VIDEO_AV1_LEVEL_5_0 = 12,
+	V4L2_MPEG_VIDEO_AV1_LEVEL_5_1 = 13,
+	V4L2_MPEG_VIDEO_AV1_LEVEL_5_2 = 14,
+	V4L2_MPEG_VIDEO_AV1_LEVEL_5_3 = 15,
+
+	V4L2_MPEG_VIDEO_AV1_LEVEL_6_0 = 16,
+	V4L2_MPEG_VIDEO_AV1_LEVEL_6_1 = 17,
+	V4L2_MPEG_VIDEO_AV1_LEVEL_6_2 = 18,
+	V4L2_MPEG_VIDEO_AV1_LEVEL_6_3 = 19,
+
+	V4L2_MPEG_VIDEO_AV1_LEVEL_7_0 = 20,
+	V4L2_MPEG_VIDEO_AV1_LEVEL_7_1 = 21,
+	V4L2_MPEG_VIDEO_AV1_LEVEL_7_2 = 22,
+	V4L2_MPEG_VIDEO_AV1_LEVEL_7_3 = 23
+};
+
 /*  MPEG-class control IDs specific to the CX2341x driver as defined by V4L2 */
 #define V4L2_CID_CODEC_CX2341X_BASE				(V4L2_CTRL_CLASS_CODEC | 0x1000)
 #define V4L2_CID_MPEG_CX2341X_VIDEO_SPATIAL_FILTER_MODE		(V4L2_CID_CODEC_CX2341X_BASE+0)
@@ -1015,6 +1079,8 @@ enum v4l2_auto_focus_range {
 
 #define V4L2_CID_CAMERA_SENSOR_ROTATION		(V4L2_CID_CAMERA_CLASS_BASE+35)
 
+#define V4L2_CID_HDR_SENSOR_MODE		(V4L2_CID_CAMERA_CLASS_BASE+36)
+
 /* FM Modulator class control IDs */
 
 #define V4L2_CID_FM_TX_CLASS_BASE		(V4L2_CTRL_CLASS_FM_TX | 0x900)
@@ -1152,6 +1218,47 @@ enum v4l2_jpeg_chroma_subsampling {
 #define V4L2_CID_DEINTERLACING_MODE		(V4L2_CID_IMAGE_PROC_CLASS_BASE + 4)
 #define V4L2_CID_DIGITAL_GAIN			(V4L2_CID_IMAGE_PROC_CLASS_BASE + 5)
 
+#define V4L2_CID_ISP_STAT_REGION		(V4L2_CID_IMAGE_PROC_CLASS_BASE + 10)
+/**
+ * struct v4l2_ctrl_isp_stat_region - Region where ISP statistics are collected
+ *
+ * @nb_regions: number of regions
+ * @top: top coordinate of a region
+ * @left: left coordinate of a region
+ * @width: width of a region
+ * @height: height of a region
+ */
+struct v4l2_ctrl_isp_stat_region {
+	__u8 nb_regions;
+	__u32 top[25];
+	__u32 left[25];
+	__u32 width[25];
+	__u32 height[25];
+};
+
+#define V4L2_CID_ISP_STAT_AVG_FILTER		(V4L2_CID_IMAGE_PROC_CLASS_BASE + 12)
+enum v4l2_isp_stat_avg_filter {
+	V4L2_STAT_AVG_FILTER_NONE	= 0,
+	V4L2_STAT_AVG_FILTER_EXCL16	= 1,
+	V4L2_STAT_AVG_FILTER_EXCL32	= 2,
+	V4L2_STAT_AVG_FILTER_EXCL64	= 3,
+};
+
+#define V4L2_CID_ISP_STAT_BIN_COMP		(V4L2_CID_IMAGE_PROC_CLASS_BASE + 13)
+enum v4l2_isp_stat_bin_comp {
+	V4L2_STAT_BIN_COMP_R		= 0,
+	V4L2_STAT_BIN_COMP_G		= 1,
+	V4L2_STAT_BIN_COMP_B		= 2,
+	V4L2_STAT_BIN_COMP_L		= 3,
+};
+
+#define V4L2_CID_ISP_STAT_PROFILE		(V4L2_CID_IMAGE_PROC_CLASS_BASE + 14)
+enum v4l2_isp_stat_profile {
+	V4L2_STAT_PROFILE_FULL		= 0,
+	V4L2_STAT_PROFILE_AVERAGE_PRE	= 1,
+	V4L2_STAT_PROFILE_AVERAGE_POST	= 2,
+};
+
 /*  DV-class control IDs defined by V4L2 */
 #define V4L2_CID_DV_CLASS_BASE			(V4L2_CTRL_CLASS_DV | 0x900)
 #define V4L2_CID_DV_CLASS			(V4L2_CTRL_CLASS_DV | 1)
@@ -1732,7 +1839,7 @@ struct v4l2_vp8_segment {
  * @sharpness_level: matches sharpness_level syntax element.
  * @level: matches loop_filter_level syntax element.
  * @padding: padding field. Should be zeroed by applications.
- * @flags: see V4L2_VP8_LF_FLAG_{}.
+ * @flags: see V4L2_VP8_LF_{}.
  *
  * This structure contains loop filter related parameters.
  * See the 'mb_lf_adjustments()' part of the frame header syntax,
@@ -1999,6 +2106,469 @@ struct v4l2_ctrl_mpeg2_quantisation {
 	__u8	chroma_non_intra_quantiser_matrix[64];
 };
 
+#define V4L2_CID_STATELESS_HEVC_SPS		(V4L2_CID_CODEC_STATELESS_BASE + 400)
+#define V4L2_CID_STATELESS_HEVC_PPS		(V4L2_CID_CODEC_STATELESS_BASE + 401)
+#define V4L2_CID_STATELESS_HEVC_SLICE_PARAMS	(V4L2_CID_CODEC_STATELESS_BASE + 402)
+#define V4L2_CID_STATELESS_HEVC_SCALING_MATRIX	(V4L2_CID_CODEC_STATELESS_BASE + 403)
+#define V4L2_CID_STATELESS_HEVC_DECODE_PARAMS	(V4L2_CID_CODEC_STATELESS_BASE + 404)
+#define V4L2_CID_STATELESS_HEVC_DECODE_MODE	(V4L2_CID_CODEC_STATELESS_BASE + 405)
+#define V4L2_CID_STATELESS_HEVC_START_CODE	(V4L2_CID_CODEC_STATELESS_BASE + 406)
+#define V4L2_CID_STATELESS_HEVC_ENTRY_POINT_OFFSETS (V4L2_CID_CODEC_STATELESS_BASE + 407)
+
+enum v4l2_stateless_hevc_decode_mode {
+	V4L2_STATELESS_HEVC_DECODE_MODE_SLICE_BASED,
+	V4L2_STATELESS_HEVC_DECODE_MODE_FRAME_BASED,
+};
+
+enum v4l2_stateless_hevc_start_code {
+	V4L2_STATELESS_HEVC_START_CODE_NONE,
+	V4L2_STATELESS_HEVC_START_CODE_ANNEX_B,
+};
+
+#define V4L2_HEVC_SLICE_TYPE_B	0
+#define V4L2_HEVC_SLICE_TYPE_P	1
+#define V4L2_HEVC_SLICE_TYPE_I	2
+
+#define V4L2_HEVC_SPS_FLAG_SEPARATE_COLOUR_PLANE		(1ULL << 0)
+#define V4L2_HEVC_SPS_FLAG_SCALING_LIST_ENABLED			(1ULL << 1)
+#define V4L2_HEVC_SPS_FLAG_AMP_ENABLED				(1ULL << 2)
+#define V4L2_HEVC_SPS_FLAG_SAMPLE_ADAPTIVE_OFFSET		(1ULL << 3)
+#define V4L2_HEVC_SPS_FLAG_PCM_ENABLED				(1ULL << 4)
+#define V4L2_HEVC_SPS_FLAG_PCM_LOOP_FILTER_DISABLED		(1ULL << 5)
+#define V4L2_HEVC_SPS_FLAG_LONG_TERM_REF_PICS_PRESENT		(1ULL << 6)
+#define V4L2_HEVC_SPS_FLAG_SPS_TEMPORAL_MVP_ENABLED		(1ULL << 7)
+#define V4L2_HEVC_SPS_FLAG_STRONG_INTRA_SMOOTHING_ENABLED	(1ULL << 8)
+
+/**
+ * struct v4l2_ctrl_hevc_sps - ITU-T Rec. H.265: Sequence parameter set
+ *
+ * @video_parameter_set_id: specifies the value of the
+ *			vps_video_parameter_set_id of the active VPS
+ * @seq_parameter_set_id: provides an identifier for the SPS for
+ *			  reference by other syntax elements
+ * @pic_width_in_luma_samples:	specifies the width of each decoded picture
+ *				in units of luma samples
+ * @pic_height_in_luma_samples: specifies the height of each decoded picture
+ *				in units of luma samples
+ * @bit_depth_luma_minus8: this value plus 8specifies the bit depth of the
+ *                         samples of the luma array
+ * @bit_depth_chroma_minus8: this value plus 8 specifies the bit depth of the
+ *                           samples of the chroma arrays
+ * @log2_max_pic_order_cnt_lsb_minus4: this value plus 4 specifies the value of
+ *                                     the variable MaxPicOrderCntLsb
+ * @sps_max_dec_pic_buffering_minus1: this value plus 1 specifies the maximum
+ *                                    required size of the decoded picture
+ *                                    buffer for the codec video sequence
+ * @sps_max_num_reorder_pics: indicates the maximum allowed number of pictures
+ * @sps_max_latency_increase_plus1: not equal to 0 is used to compute the
+ *				    value of SpsMaxLatencyPictures array
+ * @log2_min_luma_coding_block_size_minus3: plus 3 specifies the minimum
+ *					    luma coding block size
+ * @log2_diff_max_min_luma_coding_block_size: specifies the difference between
+ *					      the maximum and minimum luma
+ *					      coding block size
+ * @log2_min_luma_transform_block_size_minus2: plus 2 specifies the minimum luma
+ *					       transform block size
+ * @log2_diff_max_min_luma_transform_block_size: specifies the difference between
+ *						 the maximum and minimum luma
+ *						 transform block size
+ * @max_transform_hierarchy_depth_inter: specifies the maximum hierarchy
+ *					 depth for transform units of
+ *					 coding units coded in inter
+ *					 prediction mode
+ * @max_transform_hierarchy_depth_intra: specifies the maximum hierarchy
+ *					 depth for transform units of
+ *					 coding units coded in intra
+ *					 prediction mode
+ * @pcm_sample_bit_depth_luma_minus1: this value plus 1 specifies the number of
+ *                                    bits used to represent each of PCM sample
+ *                                    values of the luma component
+ * @pcm_sample_bit_depth_chroma_minus1: this value plus 1 specifies the number
+ *                                      of bits used to represent each of PCM
+ *                                      sample values of the chroma components
+ * @log2_min_pcm_luma_coding_block_size_minus3: this value plus 3 specifies the
+ *                                              minimum size of coding blocks
+ * @log2_diff_max_min_pcm_luma_coding_block_size: specifies the difference between
+ *						  the maximum and minimum size of
+ *						  coding blocks
+ * @num_short_term_ref_pic_sets: specifies the number of st_ref_pic_set()
+ *				 syntax structures included in the SPS
+ * @num_long_term_ref_pics_sps: specifies the number of candidate long-term
+ *				reference pictures that are specified in the SPS
+ * @chroma_format_idc: specifies the chroma sampling
+ * @sps_max_sub_layers_minus1: this value plus 1 specifies the maximum number
+ *                             of temporal sub-layers
+ * @reserved: padding field. Should be zeroed by applications.
+ * @flags: see V4L2_HEVC_SPS_FLAG_{}
+ */
+struct v4l2_ctrl_hevc_sps {
+	__u8	video_parameter_set_id;
+	__u8	seq_parameter_set_id;
+	__u16	pic_width_in_luma_samples;
+	__u16	pic_height_in_luma_samples;
+	__u8	bit_depth_luma_minus8;
+	__u8	bit_depth_chroma_minus8;
+	__u8	log2_max_pic_order_cnt_lsb_minus4;
+	__u8	sps_max_dec_pic_buffering_minus1;
+	__u8	sps_max_num_reorder_pics;
+	__u8	sps_max_latency_increase_plus1;
+	__u8	log2_min_luma_coding_block_size_minus3;
+	__u8	log2_diff_max_min_luma_coding_block_size;
+	__u8	log2_min_luma_transform_block_size_minus2;
+	__u8	log2_diff_max_min_luma_transform_block_size;
+	__u8	max_transform_hierarchy_depth_inter;
+	__u8	max_transform_hierarchy_depth_intra;
+	__u8	pcm_sample_bit_depth_luma_minus1;
+	__u8	pcm_sample_bit_depth_chroma_minus1;
+	__u8	log2_min_pcm_luma_coding_block_size_minus3;
+	__u8	log2_diff_max_min_pcm_luma_coding_block_size;
+	__u8	num_short_term_ref_pic_sets;
+	__u8	num_long_term_ref_pics_sps;
+	__u8	chroma_format_idc;
+	__u8	sps_max_sub_layers_minus1;
+
+	__u8	reserved[6];
+	__u64	flags;
+};
+
+#define V4L2_HEVC_PPS_FLAG_DEPENDENT_SLICE_SEGMENT_ENABLED	(1ULL << 0)
+#define V4L2_HEVC_PPS_FLAG_OUTPUT_FLAG_PRESENT			(1ULL << 1)
+#define V4L2_HEVC_PPS_FLAG_SIGN_DATA_HIDING_ENABLED		(1ULL << 2)
+#define V4L2_HEVC_PPS_FLAG_CABAC_INIT_PRESENT			(1ULL << 3)
+#define V4L2_HEVC_PPS_FLAG_CONSTRAINED_INTRA_PRED		(1ULL << 4)
+#define V4L2_HEVC_PPS_FLAG_TRANSFORM_SKIP_ENABLED		(1ULL << 5)
+#define V4L2_HEVC_PPS_FLAG_CU_QP_DELTA_ENABLED			(1ULL << 6)
+#define V4L2_HEVC_PPS_FLAG_PPS_SLICE_CHROMA_QP_OFFSETS_PRESENT	(1ULL << 7)
+#define V4L2_HEVC_PPS_FLAG_WEIGHTED_PRED			(1ULL << 8)
+#define V4L2_HEVC_PPS_FLAG_WEIGHTED_BIPRED			(1ULL << 9)
+#define V4L2_HEVC_PPS_FLAG_TRANSQUANT_BYPASS_ENABLED		(1ULL << 10)
+#define V4L2_HEVC_PPS_FLAG_TILES_ENABLED			(1ULL << 11)
+#define V4L2_HEVC_PPS_FLAG_ENTROPY_CODING_SYNC_ENABLED		(1ULL << 12)
+#define V4L2_HEVC_PPS_FLAG_LOOP_FILTER_ACROSS_TILES_ENABLED	(1ULL << 13)
+#define V4L2_HEVC_PPS_FLAG_PPS_LOOP_FILTER_ACROSS_SLICES_ENABLED (1ULL << 14)
+#define V4L2_HEVC_PPS_FLAG_DEBLOCKING_FILTER_OVERRIDE_ENABLED	(1ULL << 15)
+#define V4L2_HEVC_PPS_FLAG_PPS_DISABLE_DEBLOCKING_FILTER	(1ULL << 16)
+#define V4L2_HEVC_PPS_FLAG_LISTS_MODIFICATION_PRESENT		(1ULL << 17)
+#define V4L2_HEVC_PPS_FLAG_SLICE_SEGMENT_HEADER_EXTENSION_PRESENT (1ULL << 18)
+#define V4L2_HEVC_PPS_FLAG_DEBLOCKING_FILTER_CONTROL_PRESENT	(1ULL << 19)
+#define V4L2_HEVC_PPS_FLAG_UNIFORM_SPACING			(1ULL << 20)
+
+/**
+ * struct v4l2_ctrl_hevc_pps - ITU-T Rec. H.265: Picture parameter set
+ *
+ * @pic_parameter_set_id: identifies the PPS for reference by other
+ *			  syntax elements
+ * @num_extra_slice_header_bits: specifies the number of extra slice header
+ *				 bits that are present in the slice header RBSP
+ *				 for coded pictures referring to the PPS.
+ * @num_ref_idx_l0_default_active_minus1: this value plus 1 specifies the
+ *                                        inferred value of num_ref_idx_l0_active_minus1
+ * @num_ref_idx_l1_default_active_minus1: this value plus 1 specifies the
+ *                                        inferred value of num_ref_idx_l1_active_minus1
+ * @init_qp_minus26: this value plus 26 specifies the initial value of SliceQp Y for
+ *		     each slice referring to the PPS
+ * @diff_cu_qp_delta_depth: specifies the difference between the luma coding
+ *			    tree block size and the minimum luma coding block
+ *			    size of coding units that convey cu_qp_delta_abs
+ *			    and cu_qp_delta_sign_flag
+ * @pps_cb_qp_offset: specify the offsets to the luma quantization parameter Cb
+ * @pps_cr_qp_offset: specify the offsets to the luma quantization parameter Cr
+ * @num_tile_columns_minus1: this value plus 1 specifies the number of tile columns
+ *			     partitioning the picture
+ * @num_tile_rows_minus1: this value plus 1 specifies the number of tile rows partitioning
+ *			  the picture
+ * @column_width_minus1: this value plus 1 specifies the width of the each tile column in
+ *			 units of coding tree blocks
+ * @row_height_minus1: this value plus 1 specifies the height of the each tile row in
+ *		       units of coding tree blocks
+ * @pps_beta_offset_div2: specify the default deblocking parameter offsets for
+ *			  beta divided by 2
+ * @pps_tc_offset_div2: specify the default deblocking parameter offsets for tC
+ *			divided by 2
+ * @log2_parallel_merge_level_minus2: this value plus 2 specifies the value of
+ *                                    the variable Log2ParMrgLevel
+ * @reserved: padding field. Should be zeroed by applications.
+ * @flags: see V4L2_HEVC_PPS_FLAG_{}
+ */
+struct v4l2_ctrl_hevc_pps {
+	__u8	pic_parameter_set_id;
+	__u8	num_extra_slice_header_bits;
+	__u8	num_ref_idx_l0_default_active_minus1;
+	__u8	num_ref_idx_l1_default_active_minus1;
+	__s8	init_qp_minus26;
+	__u8	diff_cu_qp_delta_depth;
+	__s8	pps_cb_qp_offset;
+	__s8	pps_cr_qp_offset;
+	__u8	num_tile_columns_minus1;
+	__u8	num_tile_rows_minus1;
+	__u8	column_width_minus1[20];
+	__u8	row_height_minus1[22];
+	__s8	pps_beta_offset_div2;
+	__s8	pps_tc_offset_div2;
+	__u8	log2_parallel_merge_level_minus2;
+	__u8	reserved;
+	__u64	flags;
+};
+
+#define V4L2_HEVC_DPB_ENTRY_LONG_TERM_REFERENCE	0x01
+
+#define V4L2_HEVC_SEI_PIC_STRUCT_FRAME				0
+#define V4L2_HEVC_SEI_PIC_STRUCT_TOP_FIELD			1
+#define V4L2_HEVC_SEI_PIC_STRUCT_BOTTOM_FIELD			2
+#define V4L2_HEVC_SEI_PIC_STRUCT_TOP_BOTTOM			3
+#define V4L2_HEVC_SEI_PIC_STRUCT_BOTTOM_TOP			4
+#define V4L2_HEVC_SEI_PIC_STRUCT_TOP_BOTTOM_TOP			5
+#define V4L2_HEVC_SEI_PIC_STRUCT_BOTTOM_TOP_BOTTOM		6
+#define V4L2_HEVC_SEI_PIC_STRUCT_FRAME_DOUBLING			7
+#define V4L2_HEVC_SEI_PIC_STRUCT_FRAME_TRIPLING			8
+#define V4L2_HEVC_SEI_PIC_STRUCT_TOP_PAIRED_PREVIOUS_BOTTOM	9
+#define V4L2_HEVC_SEI_PIC_STRUCT_BOTTOM_PAIRED_PREVIOUS_TOP	10
+#define V4L2_HEVC_SEI_PIC_STRUCT_TOP_PAIRED_NEXT_BOTTOM		11
+#define V4L2_HEVC_SEI_PIC_STRUCT_BOTTOM_PAIRED_NEXT_TOP		12
+
+#define V4L2_HEVC_DPB_ENTRIES_NUM_MAX		16
+
+/**
+ * struct v4l2_hevc_dpb_entry - HEVC decoded picture buffer entry
+ *
+ * @timestamp: timestamp of the V4L2 capture buffer to use as reference.
+ * @flags: long term flag for the reference frame
+ * @field_pic: whether the reference is a field picture or a frame.
+ * @reserved: padding field. Should be zeroed by applications.
+ * @pic_order_cnt_val: the picture order count of the current picture.
+ */
+struct v4l2_hevc_dpb_entry {
+	__u64	timestamp;
+	__u8	flags;
+	__u8	field_pic;
+	__u16	reserved;
+	__s32	pic_order_cnt_val;
+};
+
+/**
+ * struct v4l2_hevc_pred_weight_table - HEVC weighted prediction parameters
+ *
+ * @delta_luma_weight_l0: the difference of the weighting factor applied
+ *			  to the luma prediction value for list 0
+ * @luma_offset_l0: the additive offset applied to the luma prediction value
+ *		    for list 0
+ * @delta_chroma_weight_l0: the difference of the weighting factor applied
+ *			    to the chroma prediction values for list 0
+ * @chroma_offset_l0: the difference of the additive offset applied to
+ *		      the chroma prediction values for list 0
+ * @delta_luma_weight_l1: the difference of the weighting factor applied
+ *			  to the luma prediction value for list 1
+ * @luma_offset_l1: the additive offset applied to the luma prediction value
+ *		    for list 1
+ * @delta_chroma_weight_l1: the difference of the weighting factor applied
+ *			    to the chroma prediction values for list 1
+ * @chroma_offset_l1: the difference of the additive offset applied to
+ *		      the chroma prediction values for list 1
+ * @luma_log2_weight_denom: the base 2 logarithm of the denominator for
+ *			    all luma weighting factors
+ * @delta_chroma_log2_weight_denom: the difference of the base 2 logarithm
+ *				    of the denominator for all chroma
+ *				    weighting factors
+ */
+struct v4l2_hevc_pred_weight_table {
+	__s8	delta_luma_weight_l0[V4L2_HEVC_DPB_ENTRIES_NUM_MAX];
+	__s8	luma_offset_l0[V4L2_HEVC_DPB_ENTRIES_NUM_MAX];
+	__s8	delta_chroma_weight_l0[V4L2_HEVC_DPB_ENTRIES_NUM_MAX][2];
+	__s8	chroma_offset_l0[V4L2_HEVC_DPB_ENTRIES_NUM_MAX][2];
+
+	__s8	delta_luma_weight_l1[V4L2_HEVC_DPB_ENTRIES_NUM_MAX];
+	__s8	luma_offset_l1[V4L2_HEVC_DPB_ENTRIES_NUM_MAX];
+	__s8	delta_chroma_weight_l1[V4L2_HEVC_DPB_ENTRIES_NUM_MAX][2];
+	__s8	chroma_offset_l1[V4L2_HEVC_DPB_ENTRIES_NUM_MAX][2];
+
+	__u8	luma_log2_weight_denom;
+	__s8	delta_chroma_log2_weight_denom;
+};
+
+#define V4L2_HEVC_SLICE_PARAMS_FLAG_SLICE_SAO_LUMA		(1ULL << 0)
+#define V4L2_HEVC_SLICE_PARAMS_FLAG_SLICE_SAO_CHROMA		(1ULL << 1)
+#define V4L2_HEVC_SLICE_PARAMS_FLAG_SLICE_TEMPORAL_MVP_ENABLED	(1ULL << 2)
+#define V4L2_HEVC_SLICE_PARAMS_FLAG_MVD_L1_ZERO			(1ULL << 3)
+#define V4L2_HEVC_SLICE_PARAMS_FLAG_CABAC_INIT			(1ULL << 4)
+#define V4L2_HEVC_SLICE_PARAMS_FLAG_COLLOCATED_FROM_L0		(1ULL << 5)
+#define V4L2_HEVC_SLICE_PARAMS_FLAG_USE_INTEGER_MV		(1ULL << 6)
+#define V4L2_HEVC_SLICE_PARAMS_FLAG_SLICE_DEBLOCKING_FILTER_DISABLED (1ULL << 7)
+#define V4L2_HEVC_SLICE_PARAMS_FLAG_SLICE_LOOP_FILTER_ACROSS_SLICES_ENABLED (1ULL << 8)
+#define V4L2_HEVC_SLICE_PARAMS_FLAG_DEPENDENT_SLICE_SEGMENT	(1ULL << 9)
+
+/**
+ * struct v4l2_ctrl_hevc_slice_params - HEVC slice parameters
+ *
+ * This control is a dynamically sized 1-dimensional array,
+ * V4L2_CTRL_FLAG_DYNAMIC_ARRAY flag must be set when using it.
+ *
+ * @bit_size: size (in bits) of the current slice data
+ * @data_byte_offset: offset (in bytes) to the video data in the current slice data
+ * @num_entry_point_offsets: specifies the number of entry point offset syntax
+ *			     elements in the slice header.
+ * @nal_unit_type: specifies the coding type of the slice (B, P or I)
+ * @nuh_temporal_id_plus1: minus 1 specifies a temporal identifier for the NAL unit
+ * @slice_type: see V4L2_HEVC_SLICE_TYPE_{}
+ * @colour_plane_id: specifies the colour plane associated with the current slice
+ * @slice_pic_order_cnt: specifies the picture order count
+ * @num_ref_idx_l0_active_minus1: this value plus 1 specifies the maximum
+ *                                reference index for reference picture list 0
+ *                                that may be used to decode the slice
+ * @num_ref_idx_l1_active_minus1: this value plus 1 specifies the maximum
+ *                                reference index for reference picture list 1
+ *                                that may be used to decode the slice
+ * @collocated_ref_idx: specifies the reference index of the collocated picture used
+ *			for temporal motion vector prediction
+ * @five_minus_max_num_merge_cand: specifies the maximum number of merging
+ *				   motion vector prediction candidates supported in
+ *				   the slice subtracted from 5
+ * @slice_qp_delta: specifies the initial value of QpY to be used for the coding
+ *		    blocks in the slice
+ * @slice_cb_qp_offset: specifies a difference to be added to the value of pps_cb_qp_offset
+ * @slice_cr_qp_offset: specifies a difference to be added to the value of pps_cr_qp_offset
+ * @slice_act_y_qp_offset: screen content extension parameters
+ * @slice_act_cb_qp_offset: screen content extension parameters
+ * @slice_act_cr_qp_offset: screen content extension parameters
+ * @slice_beta_offset_div2: specify the deblocking parameter offsets for beta divided by 2
+ * @slice_tc_offset_div2: specify the deblocking parameter offsets for tC divided by 2
+ * @pic_struct: indicates whether a picture should be displayed as a frame or as one or
+ *		more fields
+ * @reserved0: padding field. Should be zeroed by applications.
+ * @slice_segment_addr: specifies the address of the first coding tree block in
+ *			the slice segment
+ * @ref_idx_l0: the list of L0 reference elements as indices in the DPB
+ * @ref_idx_l1: the list of L1 reference elements as indices in the DPB
+ * @short_term_ref_pic_set_size: specifies the size of short-term reference
+ *				 pictures set included in the SPS
+ * @long_term_ref_pic_set_size: specifies the size of long-term reference
+ *				pictures set include in the SPS
+ * @pred_weight_table: the prediction weight coefficients for inter-picture
+ *		       prediction
+ * @reserved1: padding field. Should be zeroed by applications.
+ * @flags: see V4L2_HEVC_SLICE_PARAMS_FLAG_{}
+ */
+struct v4l2_ctrl_hevc_slice_params {
+	__u32	bit_size;
+	__u32	data_byte_offset;
+	__u32	num_entry_point_offsets;
+
+	/* ISO/IEC 23008-2, ITU-T Rec. H.265: NAL unit header */
+	__u8	nal_unit_type;
+	__u8	nuh_temporal_id_plus1;
+
+	/* ISO/IEC 23008-2, ITU-T Rec. H.265: General slice segment header */
+	__u8	slice_type;
+	__u8	colour_plane_id;
+	__s32	slice_pic_order_cnt;
+	__u8	num_ref_idx_l0_active_minus1;
+	__u8	num_ref_idx_l1_active_minus1;
+	__u8	collocated_ref_idx;
+	__u8	five_minus_max_num_merge_cand;
+	__s8	slice_qp_delta;
+	__s8	slice_cb_qp_offset;
+	__s8	slice_cr_qp_offset;
+	__s8	slice_act_y_qp_offset;
+	__s8	slice_act_cb_qp_offset;
+	__s8	slice_act_cr_qp_offset;
+	__s8	slice_beta_offset_div2;
+	__s8	slice_tc_offset_div2;
+
+	/* ISO/IEC 23008-2, ITU-T Rec. H.265: Picture timing SEI message */
+	__u8	pic_struct;
+
+	__u8	reserved0[3];
+	/* ISO/IEC 23008-2, ITU-T Rec. H.265: General slice segment header */
+	__u32	slice_segment_addr;
+	__u8	ref_idx_l0[V4L2_HEVC_DPB_ENTRIES_NUM_MAX];
+	__u8	ref_idx_l1[V4L2_HEVC_DPB_ENTRIES_NUM_MAX];
+	__u16	short_term_ref_pic_set_size;
+	__u16	long_term_ref_pic_set_size;
+
+	/* ISO/IEC 23008-2, ITU-T Rec. H.265: Weighted prediction parameter */
+	struct v4l2_hevc_pred_weight_table pred_weight_table;
+
+	__u8	reserved1[2];
+	__u64	flags;
+};
+
+#define V4L2_HEVC_DECODE_PARAM_FLAG_IRAP_PIC		0x1
+#define V4L2_HEVC_DECODE_PARAM_FLAG_IDR_PIC		0x2
+#define V4L2_HEVC_DECODE_PARAM_FLAG_NO_OUTPUT_OF_PRIOR  0x4
+
+/**
+ * struct v4l2_ctrl_hevc_decode_params - HEVC decode parameters
+ *
+ * @pic_order_cnt_val: picture order count
+ * @short_term_ref_pic_set_size: specifies the size of short-term reference
+ *				 pictures set included in the SPS of the first slice
+ * @long_term_ref_pic_set_size: specifies the size of long-term reference
+ *				pictures set include in the SPS of the first slice
+ * @num_active_dpb_entries: the number of entries in dpb
+ * @num_poc_st_curr_before: the number of reference pictures in the short-term
+ *			    set that come before the current frame
+ * @num_poc_st_curr_after: the number of reference pictures in the short-term
+ *			   set that come after the current frame
+ * @num_poc_lt_curr: the number of reference pictures in the long-term set
+ * @poc_st_curr_before: provides the index of the short term before references
+ *			in DPB array
+ * @poc_st_curr_after: provides the index of the short term after references
+ *		       in DPB array
+ * @poc_lt_curr: provides the index of the long term references in DPB array
+ * @num_delta_pocs_of_ref_rps_idx: same as the derived value NumDeltaPocs[RefRpsIdx],
+ *				   can be used to parse the RPS data in slice headers
+ *				   instead of skipping it with @short_term_ref_pic_set_size.
+ * @reserved: padding field. Should be zeroed by applications.
+ * @dpb: the decoded picture buffer, for meta-data about reference frames
+ * @flags: see V4L2_HEVC_DECODE_PARAM_FLAG_{}
+ */
+struct v4l2_ctrl_hevc_decode_params {
+	__s32	pic_order_cnt_val;
+	__u16	short_term_ref_pic_set_size;
+	__u16	long_term_ref_pic_set_size;
+	__u8	num_active_dpb_entries;
+	__u8	num_poc_st_curr_before;
+	__u8	num_poc_st_curr_after;
+	__u8	num_poc_lt_curr;
+	__u8	poc_st_curr_before[V4L2_HEVC_DPB_ENTRIES_NUM_MAX];
+	__u8	poc_st_curr_after[V4L2_HEVC_DPB_ENTRIES_NUM_MAX];
+	__u8	poc_lt_curr[V4L2_HEVC_DPB_ENTRIES_NUM_MAX];
+	__u8	num_delta_pocs_of_ref_rps_idx;
+	__u8	reserved[3];
+	struct	v4l2_hevc_dpb_entry dpb[V4L2_HEVC_DPB_ENTRIES_NUM_MAX];
+	__u64	flags;
+};
+
+/**
+ * struct v4l2_ctrl_hevc_scaling_matrix - HEVC scaling lists parameters
+ *
+ * @scaling_list_4x4: scaling list is used for the scaling process for
+ *		      transform coefficients. The values on each scaling
+ *		      list are expected in raster scan order
+ * @scaling_list_8x8: scaling list is used for the scaling process for
+ *		      transform coefficients. The values on each scaling
+ *		      list are expected in raster scan order
+ * @scaling_list_16x16:	scaling list is used for the scaling process for
+ *			transform coefficients. The values on each scaling
+ *			list are expected in raster scan order
+ * @scaling_list_32x32:	scaling list is used for the scaling process for
+ *			transform coefficients. The values on each scaling
+ *			list are expected in raster scan order
+ * @scaling_list_dc_coef_16x16:	scaling list is used for the scaling process
+ *				for transform coefficients. The values on each
+ *				scaling list are expected in raster scan order.
+ * @scaling_list_dc_coef_32x32:	scaling list is used for the scaling process
+ *				for transform coefficients. The values on each
+ *				scaling list are expected in raster scan order.
+ */
+struct v4l2_ctrl_hevc_scaling_matrix {
+	__u8	scaling_list_4x4[6][16];
+	__u8	scaling_list_8x8[6][64];
+	__u8	scaling_list_16x16[6][64];
+	__u8	scaling_list_32x32[2][64];
+	__u8	scaling_list_dc_coef_16x16[6];
+	__u8	scaling_list_dc_coef_32x32[2];
+};
+
 #define V4L2_CID_COLORIMETRY_CLASS_BASE	(V4L2_CTRL_CLASS_COLORIMETRY | 0x900)
 #define V4L2_CID_COLORIMETRY_CLASS	(V4L2_CTRL_CLASS_COLORIMETRY | 1)
 
@@ -2317,6 +2887,645 @@ struct v4l2_ctrl_vp9_compressed_hdr {
 	struct v4l2_vp9_mv_probs mv;
 };
 
+/* Stateless AV1 controls */
+
+#define V4L2_AV1_TOTAL_REFS_PER_FRAME	8
+#define V4L2_AV1_CDEF_MAX		8
+#define V4L2_AV1_NUM_PLANES_MAX		3 /* 1 if monochrome, 3 otherwise */
+#define V4L2_AV1_MAX_SEGMENTS		8
+#define V4L2_AV1_MAX_OPERATING_POINTS	(1 << 5) /* 5 bits to encode */
+#define V4L2_AV1_REFS_PER_FRAME		7
+#define V4L2_AV1_MAX_NUM_Y_POINTS	(1 << 4) /* 4 bits to encode */
+#define V4L2_AV1_MAX_NUM_CB_POINTS	(1 << 4) /* 4 bits to encode */
+#define V4L2_AV1_MAX_NUM_CR_POINTS	(1 << 4) /* 4 bits to encode */
+#define V4L2_AV1_AR_COEFFS_SIZE		25 /* (2 * 3 * (3 + 1)) + 1 */
+#define V4L2_AV1_MAX_NUM_PLANES		3
+#define V4L2_AV1_MAX_TILE_COLS		64
+#define V4L2_AV1_MAX_TILE_ROWS		64
+#define V4L2_AV1_MAX_TILE_COUNT		512
+
+#define V4L2_AV1_SEQUENCE_FLAG_STILL_PICTURE		  0x00000001
+#define V4L2_AV1_SEQUENCE_FLAG_USE_128X128_SUPERBLOCK	  0x00000002
+#define V4L2_AV1_SEQUENCE_FLAG_ENABLE_FILTER_INTRA	  0x00000004
+#define V4L2_AV1_SEQUENCE_FLAG_ENABLE_INTRA_EDGE_FILTER   0x00000008
+#define V4L2_AV1_SEQUENCE_FLAG_ENABLE_INTERINTRA_COMPOUND 0x00000010
+#define V4L2_AV1_SEQUENCE_FLAG_ENABLE_MASKED_COMPOUND	  0x00000020
+#define V4L2_AV1_SEQUENCE_FLAG_ENABLE_WARPED_MOTION	  0x00000040
+#define V4L2_AV1_SEQUENCE_FLAG_ENABLE_DUAL_FILTER	  0x00000080
+#define V4L2_AV1_SEQUENCE_FLAG_ENABLE_ORDER_HINT	  0x00000100
+#define V4L2_AV1_SEQUENCE_FLAG_ENABLE_JNT_COMP		  0x00000200
+#define V4L2_AV1_SEQUENCE_FLAG_ENABLE_REF_FRAME_MVS	  0x00000400
+#define V4L2_AV1_SEQUENCE_FLAG_ENABLE_SUPERRES		  0x00000800
+#define V4L2_AV1_SEQUENCE_FLAG_ENABLE_CDEF		  0x00001000
+#define V4L2_AV1_SEQUENCE_FLAG_ENABLE_RESTORATION	  0x00002000
+#define V4L2_AV1_SEQUENCE_FLAG_MONO_CHROME		  0x00004000
+#define V4L2_AV1_SEQUENCE_FLAG_COLOR_RANGE		  0x00008000
+#define V4L2_AV1_SEQUENCE_FLAG_SUBSAMPLING_X		  0x00010000
+#define V4L2_AV1_SEQUENCE_FLAG_SUBSAMPLING_Y		  0x00020000
+#define V4L2_AV1_SEQUENCE_FLAG_FILM_GRAIN_PARAMS_PRESENT  0x00040000
+#define V4L2_AV1_SEQUENCE_FLAG_SEPARATE_UV_DELTA_Q	  0x00080000
+
+#define V4L2_CID_STATELESS_AV1_SEQUENCE (V4L2_CID_CODEC_STATELESS_BASE + 500)
+/**
+ * struct v4l2_ctrl_av1_sequence - AV1 Sequence
+ *
+ * Represents an AV1 Sequence OBU. See section 5.5 "Sequence header OBU syntax"
+ * for more details.
+ *
+ * @flags: See V4L2_AV1_SEQUENCE_FLAG_{}.
+ * @seq_profile: specifies the features that can be used in the coded video
+ * sequence.
+ * @order_hint_bits: specifies the number of bits used for the order_hint field
+ * at each frame.
+ * @bit_depth: the bitdepth to use for the sequence as described in section
+ * 5.5.2 "Color config syntax".
+ * @reserved: padding field. Should be zeroed by applications.
+ * @max_frame_width_minus_1: specifies the maximum frame width minus 1 for the
+ * frames represented by this sequence header.
+ * @max_frame_height_minus_1: specifies the maximum frame height minus 1 for the
+ * frames represented by this sequence header.
+ */
+struct v4l2_ctrl_av1_sequence {
+	__u32 flags;
+	__u8 seq_profile;
+	__u8 order_hint_bits;
+	__u8 bit_depth;
+	__u8 reserved;
+	__u16 max_frame_width_minus_1;
+	__u16 max_frame_height_minus_1;
+};
+
+#define V4L2_CID_STATELESS_AV1_TILE_GROUP_ENTRY (V4L2_CID_CODEC_STATELESS_BASE + 501)
+/**
+ * struct v4l2_ctrl_av1_tile_group_entry - AV1 Tile Group entry
+ *
+ * Represents a single AV1 tile inside an AV1 Tile Group. Note that MiRowStart,
+ * MiRowEnd, MiColStart and MiColEnd can be retrieved from struct
+ * v4l2_av1_tile_info in struct v4l2_ctrl_av1_frame using tile_row and
+ * tile_col. See section 6.10.1 "General tile group OBU semantics" for more
+ * details.
+ *
+ * @tile_offset: offset from the OBU data, i.e. where the coded tile data
+ * actually starts.
+ * @tile_size: specifies the size in bytes of the coded tile. Equivalent to
+ * "TileSize" in the AV1 Specification.
+ * @tile_row: specifies the row of the current tile. Equivalent to "TileRow" in
+ * the AV1 Specification.
+ * @tile_col: specifies the col of the current tile. Equivalent to "TileCol" in
+ * the AV1 Specification.
+ */
+struct v4l2_ctrl_av1_tile_group_entry {
+	__u32 tile_offset;
+	__u32 tile_size;
+	__u32 tile_row;
+	__u32 tile_col;
+};
+
+/**
+ * enum v4l2_av1_warp_model - AV1 Warp Model as described in section 3
+ * "Symbols and abbreviated terms" of the AV1 Specification.
+ *
+ * @V4L2_AV1_WARP_MODEL_IDENTITY: Warp model is just an identity transform.
+ * @V4L2_AV1_WARP_MODEL_TRANSLATION: Warp model is a pure translation.
+ * @V4L2_AV1_WARP_MODEL_ROTZOOM: Warp model is a rotation + symmetric zoom +
+ * translation.
+ * @V4L2_AV1_WARP_MODEL_AFFINE: Warp model is a general affine transform.
+ */
+enum v4l2_av1_warp_model {
+	V4L2_AV1_WARP_MODEL_IDENTITY = 0,
+	V4L2_AV1_WARP_MODEL_TRANSLATION = 1,
+	V4L2_AV1_WARP_MODEL_ROTZOOM = 2,
+	V4L2_AV1_WARP_MODEL_AFFINE = 3,
+};
+
+/**
+ * enum v4l2_av1_reference_frame - AV1 reference frames
+ *
+ * @V4L2_AV1_REF_INTRA_FRAME: Intra Frame Reference
+ * @V4L2_AV1_REF_LAST_FRAME: Last Reference Frame
+ * @V4L2_AV1_REF_LAST2_FRAME: Last2 Reference Frame
+ * @V4L2_AV1_REF_LAST3_FRAME: Last3 Reference Frame
+ * @V4L2_AV1_REF_GOLDEN_FRAME: Golden Reference Frame
+ * @V4L2_AV1_REF_BWDREF_FRAME: BWD Reference Frame
+ * @V4L2_AV1_REF_ALTREF2_FRAME: Alternative2 Reference Frame
+ * @V4L2_AV1_REF_ALTREF_FRAME: Alternative Reference Frame
+ */
+enum v4l2_av1_reference_frame {
+	V4L2_AV1_REF_INTRA_FRAME = 0,
+	V4L2_AV1_REF_LAST_FRAME = 1,
+	V4L2_AV1_REF_LAST2_FRAME = 2,
+	V4L2_AV1_REF_LAST3_FRAME = 3,
+	V4L2_AV1_REF_GOLDEN_FRAME = 4,
+	V4L2_AV1_REF_BWDREF_FRAME = 5,
+	V4L2_AV1_REF_ALTREF2_FRAME = 6,
+	V4L2_AV1_REF_ALTREF_FRAME = 7,
+};
+
+#define V4L2_AV1_GLOBAL_MOTION_IS_INVALID(ref) (1 << (ref))
+
+#define V4L2_AV1_GLOBAL_MOTION_FLAG_IS_GLOBAL	   0x1
+#define V4L2_AV1_GLOBAL_MOTION_FLAG_IS_ROT_ZOOM	   0x2
+#define V4L2_AV1_GLOBAL_MOTION_FLAG_IS_TRANSLATION 0x4
+/**
+ * struct v4l2_av1_global_motion - AV1 Global Motion parameters as described in
+ * section 6.8.17 "Global motion params semantics" of the AV1 specification.
+ *
+ * @flags: A bitfield containing the flags per reference frame. See
+ * V4L2_AV1_GLOBAL_MOTION_FLAG_{}
+ * @type: The type of global motion transform used.
+ * @params: this field has the same meaning as "gm_params" in the AV1
+ * specification.
+ * @invalid: bitfield indicating whether the global motion params are invalid
+ * for a given reference frame. See section 7.11.3.6 Setup shear process and
+ * the variable "warpValid". Use V4L2_AV1_GLOBAL_MOTION_IS_INVALID(ref) to
+ * create a suitable mask.
+ * @reserved: padding field. Should be zeroed by applications.
+ */
+
+struct v4l2_av1_global_motion {
+	__u8 flags[V4L2_AV1_TOTAL_REFS_PER_FRAME];
+	enum v4l2_av1_warp_model type[V4L2_AV1_TOTAL_REFS_PER_FRAME];
+	__s32 params[V4L2_AV1_TOTAL_REFS_PER_FRAME][6];
+	__u8 invalid;
+	__u8 reserved[3];
+};
+
+/**
+ * enum v4l2_av1_frame_restoration_type - AV1 Frame Restoration Type
+ * @V4L2_AV1_FRAME_RESTORE_NONE: no filtering is applied.
+ * @V4L2_AV1_FRAME_RESTORE_WIENER: Wiener filter process is invoked.
+ * @V4L2_AV1_FRAME_RESTORE_SGRPROJ: self guided filter process is invoked.
+ * @V4L2_AV1_FRAME_RESTORE_SWITCHABLE: restoration filter is swichtable.
+ */
+enum v4l2_av1_frame_restoration_type {
+	V4L2_AV1_FRAME_RESTORE_NONE = 0,
+	V4L2_AV1_FRAME_RESTORE_WIENER = 1,
+	V4L2_AV1_FRAME_RESTORE_SGRPROJ = 2,
+	V4L2_AV1_FRAME_RESTORE_SWITCHABLE = 3,
+};
+
+#define V4L2_AV1_LOOP_RESTORATION_FLAG_USES_LR		0x1
+#define V4L2_AV1_LOOP_RESTORATION_FLAG_USES_CHROMA_LR	0x2
+
+/**
+ * struct v4l2_av1_loop_restoration - AV1 Loop Restauration as described in
+ * section 6.10.15 "Loop restoration params semantics" of the AV1 specification.
+ *
+ * @flags: See V4L2_AV1_LOOP_RESTORATION_FLAG_{}.
+ * @lr_unit_shift: specifies if the luma restoration size should be halved.
+ * @lr_uv_shift: specifies if the chroma size should be half the luma size.
+ * @reserved: padding field. Should be zeroed by applications.
+ * @frame_restoration_type: specifies the type of restoration used for each
+ * plane. See enum v4l2_av1_frame_restoration_type.
+ * @loop_restoration_size: specifies the size of loop restoration units in units
+ * of samples in the current plane.
+ */
+struct v4l2_av1_loop_restoration {
+	__u8 flags;
+	__u8 lr_unit_shift;
+	__u8 lr_uv_shift;
+	__u8 reserved;
+	enum v4l2_av1_frame_restoration_type frame_restoration_type[V4L2_AV1_NUM_PLANES_MAX];
+	__u32 loop_restoration_size[V4L2_AV1_MAX_NUM_PLANES];
+};
+
+/**
+ * struct v4l2_av1_cdef - AV1 CDEF params semantics as described in section
+ * 6.10.14 "CDEF params semantics" of the AV1 specification
+ *
+ * @damping_minus_3: controls the amount of damping in the deringing filter.
+ * @bits: specifies the number of bits needed to specify which CDEF filter to
+ * apply.
+ * @y_pri_strength: specifies the strength of the primary filter.
+ * @y_sec_strength: specifies the strength of the secondary filter.
+ * @uv_pri_strength: specifies the strength of the primary filter.
+ * @uv_sec_strength: specifies the strength of the secondary filter.
+ */
+struct v4l2_av1_cdef {
+	__u8 damping_minus_3;
+	__u8 bits;
+	__u8 y_pri_strength[V4L2_AV1_CDEF_MAX];
+	__u8 y_sec_strength[V4L2_AV1_CDEF_MAX];
+	__u8 uv_pri_strength[V4L2_AV1_CDEF_MAX];
+	__u8 uv_sec_strength[V4L2_AV1_CDEF_MAX];
+};
+
+#define V4L2_AV1_SEGMENTATION_FLAG_ENABLED	   0x1
+#define V4L2_AV1_SEGMENTATION_FLAG_UPDATE_MAP	   0x2
+#define V4L2_AV1_SEGMENTATION_FLAG_TEMPORAL_UPDATE 0x4
+#define V4L2_AV1_SEGMENTATION_FLAG_UPDATE_DATA	   0x8
+#define V4L2_AV1_SEGMENTATION_FLAG_SEG_ID_PRE_SKIP 0x10
+
+/**
+ * enum v4l2_av1_segment_feature - AV1 segment features as described in section
+ * 3 "Symbols and abbreviated terms" of the AV1 specification.
+ *
+ * @V4L2_AV1_SEG_LVL_ALT_Q: Index for quantizer segment feature.
+ * @V4L2_AV1_SEG_LVL_ALT_LF_Y_V: Index for vertical luma loop filter segment
+ * feature.
+ * @V4L2_AV1_SEG_LVL_REF_FRAME: Index for reference frame segment feature.
+ * @V4L2_AV1_SEG_LVL_REF_SKIP: Index for skip segment feature.
+ * @V4L2_AV1_SEG_LVL_REF_GLOBALMV: Index for global mv feature.
+ * @V4L2_AV1_SEG_LVL_MAX: Number of segment features.
+ */
+enum v4l2_av1_segment_feature {
+	V4L2_AV1_SEG_LVL_ALT_Q = 0,
+	V4L2_AV1_SEG_LVL_ALT_LF_Y_V = 1,
+	V4L2_AV1_SEG_LVL_REF_FRAME = 5,
+	V4L2_AV1_SEG_LVL_REF_SKIP = 6,
+	V4L2_AV1_SEG_LVL_REF_GLOBALMV = 7,
+	V4L2_AV1_SEG_LVL_MAX = 8
+};
+
+#define V4L2_AV1_SEGMENT_FEATURE_ENABLED(id)	(1 << (id))
+
+/**
+ * struct v4l2_av1_segmentation - AV1 Segmentation params as defined in section
+ * 6.8.13 "Segmentation params semantics" of the AV1 specification.
+ *
+ * @flags: see V4L2_AV1_SEGMENTATION_FLAG_{}.
+ * @last_active_seg_id: indicates the highest numbered segment id that has some
+ * enabled feature. This is used when decoding the segment id to only decode
+ * choices corresponding to used segments.
+ * @feature_enabled: bitmask defining which features are enabled in each
+ * segment. Use V4L2_AV1_SEGMENT_FEATURE_ENABLED to build a suitable mask.
+ * @feature_data: data attached to each feature. Data entry is only valid if the
+ * feature is enabled
+ */
+struct v4l2_av1_segmentation {
+	__u8 flags;
+	__u8 last_active_seg_id;
+	__u8 feature_enabled[V4L2_AV1_MAX_SEGMENTS];
+	__s16 feature_data[V4L2_AV1_MAX_SEGMENTS][V4L2_AV1_SEG_LVL_MAX];
+};
+
+#define V4L2_AV1_LOOP_FILTER_FLAG_DELTA_ENABLED    0x1
+#define V4L2_AV1_LOOP_FILTER_FLAG_DELTA_UPDATE     0x2
+#define V4L2_AV1_LOOP_FILTER_FLAG_DELTA_LF_PRESENT 0x4
+#define V4L2_AV1_LOOP_FILTER_FLAG_DELTA_LF_MULTI   0x8
+
+/**
+ * struct v4l2_av1_loop_filter - AV1 Loop filter params as defined in section
+ * 6.8.10 "Loop filter semantics" and 6.8.16 "Loop filter delta parameters
+ * semantics" of the AV1 specification.
+ *
+ * @flags: see V4L2_AV1_LOOP_FILTER_FLAG_{}
+ * @level: an array containing loop filter strength values. Different loop
+ * filter strength values from the array are used depending on the image plane
+ * being filtered, and the edge direction (vertical or horizontal) being
+ * filtered.
+ * @sharpness: indicates the sharpness level. The loop_filter_level and
+ * loop_filter_sharpness together determine when a block edge is filtered, and
+ * by how much the filtering can change the sample values. The loop filter
+ * process is described in section 7.14 of the AV1 specification.
+ * @ref_deltas: contains the adjustment needed for the filter level based on the
+ * chosen reference frame. If this syntax element is not present, it maintains
+ * its previous value.
+ * @mode_deltas: contains the adjustment needed for the filter level based on
+ * the chosen mode. If this syntax element is not present, it maintains its
+ * previous value.
+ * @delta_lf_res: specifies the left shift which should be applied to decoded
+ * loop filter delta values.
+ */
+struct v4l2_av1_loop_filter {
+	__u8 flags;
+	__u8 level[4];
+	__u8 sharpness;
+	__s8 ref_deltas[V4L2_AV1_TOTAL_REFS_PER_FRAME];
+	__s8 mode_deltas[2];
+	__u8 delta_lf_res;
+};
+
+#define V4L2_AV1_QUANTIZATION_FLAG_DIFF_UV_DELTA   0x1
+#define V4L2_AV1_QUANTIZATION_FLAG_USING_QMATRIX   0x2
+#define V4L2_AV1_QUANTIZATION_FLAG_DELTA_Q_PRESENT 0x4
+
+/**
+ * struct v4l2_av1_quantization - AV1 Quantization params as defined in section
+ * 6.8.11 "Quantization params semantics" of the AV1 specification.
+ *
+ * @flags: see V4L2_AV1_QUANTIZATION_FLAG_{}
+ * @base_q_idx: indicates the base frame qindex. This is used for Y AC
+ * coefficients and as the base value for the other quantizers.
+ * @delta_q_y_dc: indicates the Y DC quantizer relative to base_q_idx.
+ * @delta_q_u_dc: indicates the U DC quantizer relative to base_q_idx.
+ * @delta_q_u_ac: indicates the U AC quantizer relative to base_q_idx.
+ * @delta_q_v_dc: indicates the V DC quantizer relative to base_q_idx.
+ * @delta_q_v_ac: indicates the V AC quantizer relative to base_q_idx.
+ * @qm_y: specifies the level in the quantizer matrix that should be used for
+ * luma plane decoding.
+ * @qm_u: specifies the level in the quantizer matrix that should be used for
+ * chroma U plane decoding.
+ * @qm_v: specifies the level in the quantizer matrix that should be used for
+ * chroma V plane decoding.
+ * @delta_q_res: specifies the left shift which should be applied to decoded
+ * quantizer index delta values.
+ */
+struct v4l2_av1_quantization {
+	__u8 flags;
+	__u8 base_q_idx;
+	__s8 delta_q_y_dc;
+	__s8 delta_q_u_dc;
+	__s8 delta_q_u_ac;
+	__s8 delta_q_v_dc;
+	__s8 delta_q_v_ac;
+	__u8 qm_y;
+	__u8 qm_u;
+	__u8 qm_v;
+	__u8 delta_q_res;
+};
+
+#define V4L2_AV1_TILE_INFO_FLAG_UNIFORM_TILE_SPACING	0x1
+
+/**
+ * struct v4l2_av1_tile_info - AV1 Tile info as defined in section 6.8.14 "Tile
+ * info semantics" of the AV1 specification.
+ *
+ * @flags: see V4L2_AV1_TILE_INFO_FLAG_{}
+ * @context_update_tile_id: specifies which tile to use for the CDF update.
+ * @tile_rows: specifies the number of tiles down the frame.
+ * @tile_cols: specifies the number of tiles across the frame.
+ * @mi_col_starts: an array specifying the start column (in units of 4x4 luma
+ * samples) for each tile across the image.
+ * @mi_row_starts: an array specifying the start row (in units of 4x4 luma
+ * samples) for each tile down the image.
+ * @width_in_sbs_minus_1: specifies the width of a tile minus 1 in units of
+ * superblocks.
+ * @height_in_sbs_minus_1:  specifies the height of a tile minus 1 in units of
+ * superblocks.
+ * @tile_size_bytes: specifies the number of bytes needed to code each tile
+ * size.
+ * @reserved: padding field. Should be zeroed by applications.
+ */
+struct v4l2_av1_tile_info {
+	__u8 flags;
+	__u8 context_update_tile_id;
+	__u8 tile_cols;
+	__u8 tile_rows;
+	__u32 mi_col_starts[V4L2_AV1_MAX_TILE_COLS + 1];
+	__u32 mi_row_starts[V4L2_AV1_MAX_TILE_ROWS + 1];
+	__u32 width_in_sbs_minus_1[V4L2_AV1_MAX_TILE_COLS];
+	__u32 height_in_sbs_minus_1[V4L2_AV1_MAX_TILE_ROWS];
+	__u8 tile_size_bytes;
+	__u8 reserved[3];
+};
+
+/**
+ * enum v4l2_av1_frame_type - AV1 Frame Type
+ *
+ * @V4L2_AV1_KEY_FRAME: Key frame
+ * @V4L2_AV1_INTER_FRAME: Inter frame
+ * @V4L2_AV1_INTRA_ONLY_FRAME: Intra-only frame
+ * @V4L2_AV1_SWITCH_FRAME: Switch frame
+ */
+enum v4l2_av1_frame_type {
+	V4L2_AV1_KEY_FRAME = 0,
+	V4L2_AV1_INTER_FRAME = 1,
+	V4L2_AV1_INTRA_ONLY_FRAME = 2,
+	V4L2_AV1_SWITCH_FRAME = 3
+};
+
+/**
+ * enum v4l2_av1_interpolation_filter - AV1 interpolation filter types
+ *
+ * @V4L2_AV1_INTERPOLATION_FILTER_EIGHTTAP: eight tap filter
+ * @V4L2_AV1_INTERPOLATION_FILTER_EIGHTTAP_SMOOTH: eight tap smooth filter
+ * @V4L2_AV1_INTERPOLATION_FILTER_EIGHTTAP_SHARP: eight tap sharp filter
+ * @V4L2_AV1_INTERPOLATION_FILTER_BILINEAR: bilinear filter
+ * @V4L2_AV1_INTERPOLATION_FILTER_SWITCHABLE: filter selection is signaled at
+ * the block level
+ *
+ * See section 6.8.9 "Interpolation filter semantics" of the AV1 specification
+ * for more details.
+ */
+enum v4l2_av1_interpolation_filter {
+	V4L2_AV1_INTERPOLATION_FILTER_EIGHTTAP = 0,
+	V4L2_AV1_INTERPOLATION_FILTER_EIGHTTAP_SMOOTH = 1,
+	V4L2_AV1_INTERPOLATION_FILTER_EIGHTTAP_SHARP = 2,
+	V4L2_AV1_INTERPOLATION_FILTER_BILINEAR = 3,
+	V4L2_AV1_INTERPOLATION_FILTER_SWITCHABLE = 4,
+};
+
+/**
+ * enum v4l2_av1_tx_mode - AV1 Tx mode as described in section 6.8.21 "TX mode
+ * semantics" of the AV1 specification.
+ * @V4L2_AV1_TX_MODE_ONLY_4X4: the inverse transform will use only 4x4
+ * transforms
+ * @V4L2_AV1_TX_MODE_LARGEST: the inverse transform will use the largest
+ * transform size that fits inside the block
+ * @V4L2_AV1_TX_MODE_SELECT: the choice of transform size is specified
+ * explicitly for each block.
+ */
+enum v4l2_av1_tx_mode {
+	V4L2_AV1_TX_MODE_ONLY_4X4 = 0,
+	V4L2_AV1_TX_MODE_LARGEST = 1,
+	V4L2_AV1_TX_MODE_SELECT = 2
+};
+
+#define V4L2_AV1_FRAME_FLAG_SHOW_FRAME			 0x00000001
+#define V4L2_AV1_FRAME_FLAG_SHOWABLE_FRAME		 0x00000002
+#define V4L2_AV1_FRAME_FLAG_ERROR_RESILIENT_MODE	 0x00000004
+#define V4L2_AV1_FRAME_FLAG_DISABLE_CDF_UPDATE		 0x00000008
+#define V4L2_AV1_FRAME_FLAG_ALLOW_SCREEN_CONTENT_TOOLS	 0x00000010
+#define V4L2_AV1_FRAME_FLAG_FORCE_INTEGER_MV		 0x00000020
+#define V4L2_AV1_FRAME_FLAG_ALLOW_INTRABC		 0x00000040
+#define V4L2_AV1_FRAME_FLAG_USE_SUPERRES		 0x00000080
+#define V4L2_AV1_FRAME_FLAG_ALLOW_HIGH_PRECISION_MV	 0x00000100
+#define V4L2_AV1_FRAME_FLAG_IS_MOTION_MODE_SWITCHABLE	 0x00000200
+#define V4L2_AV1_FRAME_FLAG_USE_REF_FRAME_MVS		 0x00000400
+#define V4L2_AV1_FRAME_FLAG_DISABLE_FRAME_END_UPDATE_CDF 0x00000800
+#define V4L2_AV1_FRAME_FLAG_ALLOW_WARPED_MOTION		 0x00001000
+#define V4L2_AV1_FRAME_FLAG_REFERENCE_SELECT		 0x00002000
+#define V4L2_AV1_FRAME_FLAG_REDUCED_TX_SET		 0x00004000
+#define V4L2_AV1_FRAME_FLAG_SKIP_MODE_ALLOWED		 0x00008000
+#define V4L2_AV1_FRAME_FLAG_SKIP_MODE_PRESENT		 0x00010000
+#define V4L2_AV1_FRAME_FLAG_FRAME_SIZE_OVERRIDE		 0x00020000
+#define V4L2_AV1_FRAME_FLAG_BUFFER_REMOVAL_TIME_PRESENT	 0x00040000
+#define V4L2_AV1_FRAME_FLAG_FRAME_REFS_SHORT_SIGNALING	 0x00080000
+
+#define V4L2_CID_STATELESS_AV1_FRAME (V4L2_CID_CODEC_STATELESS_BASE + 502)
+/**
+ * struct v4l2_ctrl_av1_frame - Represents an AV1 Frame Header OBU.
+ *
+ * @tile_info: tile info
+ * @quantization: quantization params
+ * @segmentation: segmentation params
+ * @superres_denom: the denominator for the upscaling ratio.
+ * @loop_filter: loop filter params
+ * @cdef: cdef params
+ * @skip_mode_frame: specifies the frames to use for compound prediction when
+ * skip_mode is equal to 1.
+ * @primary_ref_frame: specifies which reference frame contains the CDF values
+ * and other state that should be loaded at the start of the frame.
+ * @loop_restoration: loop restoration params
+ * @global_motion: global motion params
+ * @flags: see V4L2_AV1_FRAME_FLAG_{}
+ * @frame_type: specifies the AV1 frame type
+ * @order_hint: specifies OrderHintBits least significant bits of the expected
+ * output order for this frame.
+ * @upscaled_width: the upscaled width.
+ * @interpolation_filter: specifies the filter selection used for performing
+ * inter prediction.
+ * @tx_mode: specifies how the transform size is determined.
+ * @frame_width_minus_1: add 1 to get the frame's width.
+ * @frame_height_minus_1: add 1 to get the frame's height
+ * @render_width_minus_1: add 1 to get the render width of the frame in luma
+ * samples.
+ * @render_height_minus_1: add 1 to get the render height of the frame in luma
+ * samples.
+ * @current_frame_id: specifies the frame id number for the current frame. Frame
+ * id numbers are additional information that do not affect the decoding
+ * process, but provide decoders with a way of detecting missing reference
+ * frames so that appropriate action can be taken.
+ * @buffer_removal_time: specifies the frame removal time in units of DecCT clock
+ * ticks counted from the removal time of the last random access point for
+ * operating point opNum.
+ * @reserved: padding field. Should be zeroed by applications.
+ * @order_hints: specifies the expected output order hint for each reference
+ * frame. This field corresponds to the OrderHints variable from the
+ * specification (section 5.9.2 "Uncompressed header syntax"). As such, this is
+ * only used for non-intra frames and ignored otherwise. order_hints[0] is
+ * always ignored.
+ * @reference_frame_ts: the V4L2 timestamp of the reference frame slots.
+ * @ref_frame_idx: used to index into @reference_frame_ts when decoding
+ * inter-frames. The meaning of this array is the same as in the specification.
+ * The timestamp refers to the timestamp field in struct v4l2_buffer. Use
+ * v4l2_timeval_to_ns() to convert the struct timeval to a __u64.
+ * @refresh_frame_flags: contains a bitmask that specifies which reference frame
+ * slots will be updated with the current frame after it is decoded.
+ */
+struct v4l2_ctrl_av1_frame {
+	struct v4l2_av1_tile_info tile_info;
+	struct v4l2_av1_quantization quantization;
+	__u8 superres_denom;
+	struct v4l2_av1_segmentation segmentation;
+	struct v4l2_av1_loop_filter loop_filter;
+	struct v4l2_av1_cdef cdef;
+	__u8 skip_mode_frame[2];
+	__u8 primary_ref_frame;
+	struct v4l2_av1_loop_restoration loop_restoration;
+	struct v4l2_av1_global_motion global_motion;
+	__u32 flags;
+	enum v4l2_av1_frame_type frame_type;
+	__u32 order_hint;
+	__u32 upscaled_width;
+	enum v4l2_av1_interpolation_filter interpolation_filter;
+	enum v4l2_av1_tx_mode tx_mode;
+	__u32 frame_width_minus_1;
+	__u32 frame_height_minus_1;
+	__u16 render_width_minus_1;
+	__u16 render_height_minus_1;
+
+	__u32 current_frame_id;
+	__u32 buffer_removal_time[V4L2_AV1_MAX_OPERATING_POINTS];
+	__u8 reserved[4];
+	__u32 order_hints[V4L2_AV1_TOTAL_REFS_PER_FRAME];
+	__u64 reference_frame_ts[V4L2_AV1_TOTAL_REFS_PER_FRAME];
+	__s8 ref_frame_idx[V4L2_AV1_REFS_PER_FRAME];
+	__u8 refresh_frame_flags;
+};
+
+#define V4L2_AV1_FILM_GRAIN_FLAG_APPLY_GRAIN 0x1
+#define V4L2_AV1_FILM_GRAIN_FLAG_UPDATE_GRAIN 0x2
+#define V4L2_AV1_FILM_GRAIN_FLAG_CHROMA_SCALING_FROM_LUMA 0x4
+#define V4L2_AV1_FILM_GRAIN_FLAG_OVERLAP 0x8
+#define V4L2_AV1_FILM_GRAIN_FLAG_CLIP_TO_RESTRICTED_RANGE 0x10
+
+#define V4L2_CID_STATELESS_AV1_FILM_GRAIN (V4L2_CID_CODEC_STATELESS_BASE + 505)
+/**
+ * struct v4l2_ctrl_av1_film_grain - AV1 Film Grain parameters.
+ *
+ * Film grain parameters as specified by section 6.8.20 of the AV1 Specification.
+ *
+ * @flags: see V4L2_AV1_FILM_GRAIN_{}.
+ * @cr_mult: represents a multiplier for the cr component used in derivation of
+ * the input index to the cr component scaling function.
+ * @grain_seed: specifies the starting value for the pseudo-random numbers used
+ * during film grain synthesis.
+ * @film_grain_params_ref_idx: indicates which reference frame contains the
+ * film grain parameters to be used for this frame.
+ * @num_y_points: specifies the number of points for the piece-wise linear
+ * scaling function of the luma component.
+ * @point_y_value: represents the x (luma value) coordinate for the i-th point
+ * of the piecewise linear scaling function for luma component. The values are
+ * signaled on the scale of 0..255. In case of 10 bit video, these values
+ * correspond to luma values divided by 4. In case of 12 bit video, these values
+ * correspond to luma values divided by 16.
+ * @point_y_scaling:  represents the scaling (output) value for the i-th point
+ * of the piecewise linear scaling function for luma component.
+ * @num_cb_points: specifies the number of points for the piece-wise linear
+ * scaling function of the cb component.
+ * @point_cb_value: represents the x coordinate for the i-th point of the
+ * piece-wise linear scaling function for cb component. The values are signaled
+ * on the scale of 0..255.
+ * @point_cb_scaling: represents the scaling (output) value for the i-th point
+ * of the piecewise linear scaling function for cb component.
+ * @num_cr_points: specifies represents the number of points for the piece-wise
+ * linear scaling function of the cr component.
+ * @point_cr_value:  represents the x coordinate for the i-th point of the
+ * piece-wise linear scaling function for cr component. The values are signaled
+ * on the scale of 0..255.
+ * @point_cr_scaling:  represents the scaling (output) value for the i-th point
+ * of the piecewise linear scaling function for cr component.
+ * @grain_scaling_minus_8: represents the shift – 8 applied to the values of the
+ * chroma component. The grain_scaling_minus_8 can take values of 0..3 and
+ * determines the range and quantization step of the standard deviation of film
+ * grain.
+ * @ar_coeff_lag: specifies the number of auto-regressive coefficients for luma
+ * and chroma.
+ * @ar_coeffs_y_plus_128: specifies auto-regressive coefficients used for the Y
+ * plane.
+ * @ar_coeffs_cb_plus_128: specifies auto-regressive coefficients used for the U
+ * plane.
+ * @ar_coeffs_cr_plus_128: specifies auto-regressive coefficients used for the V
+ * plane.
+ * @ar_coeff_shift_minus_6: specifies the range of the auto-regressive
+ * coefficients. Values of 0, 1, 2, and 3 correspond to the ranges for
+ * auto-regressive coefficients of [-2, 2), [-1, 1), [-0.5, 0.5) and [-0.25,
+ * 0.25) respectively.
+ * @grain_scale_shift: specifies how much the Gaussian random numbers should be
+ * scaled down during the grain synthesis process.
+ * @cb_mult: represents a multiplier for the cb component used in derivation of
+ * the input index to the cb component scaling function.
+ * @cb_luma_mult: represents a multiplier for the average luma component used in
+ * derivation of the input index to the cb component scaling function.
+ * @cr_luma_mult: represents a multiplier for the average luma component used in
+ * derivation of the input index to the cr component scaling function.
+ * @cb_offset: represents an offset used in derivation of the input index to the
+ * cb component scaling function.
+ * @cr_offset: represents an offset used in derivation of the input index to the
+ * cr component scaling function.
+ * @reserved: padding field. Should be zeroed by applications.
+ */
+struct v4l2_ctrl_av1_film_grain {
+	__u8 flags;
+	__u8 cr_mult;
+	__u16 grain_seed;
+	__u8 film_grain_params_ref_idx;
+	__u8 num_y_points;
+	__u8 point_y_value[V4L2_AV1_MAX_NUM_Y_POINTS];
+	__u8 point_y_scaling[V4L2_AV1_MAX_NUM_Y_POINTS];
+	__u8 num_cb_points;
+	__u8 point_cb_value[V4L2_AV1_MAX_NUM_CB_POINTS];
+	__u8 point_cb_scaling[V4L2_AV1_MAX_NUM_CB_POINTS];
+	__u8 num_cr_points;
+	__u8 point_cr_value[V4L2_AV1_MAX_NUM_CR_POINTS];
+	__u8 point_cr_scaling[V4L2_AV1_MAX_NUM_CR_POINTS];
+	__u8 grain_scaling_minus_8;
+	__u8 ar_coeff_lag;
+	__u8 ar_coeffs_y_plus_128[V4L2_AV1_AR_COEFFS_SIZE];
+	__u8 ar_coeffs_cb_plus_128[V4L2_AV1_AR_COEFFS_SIZE];
+	__u8 ar_coeffs_cr_plus_128[V4L2_AV1_AR_COEFFS_SIZE];
+	__u8 ar_coeff_shift_minus_6;
+	__u8 grain_scale_shift;
+	__u8 cb_mult;
+	__u8 cb_luma_mult;
+	__u8 cr_luma_mult;
+	__u16 cb_offset;
+	__u16 cr_offset;
+	__u8 reserved[4];
+};
+
 /* MPEG-compression definitions kept for backwards compatibility */
 #define V4L2_CTRL_CLASS_MPEG            V4L2_CTRL_CLASS_CODEC
 #define V4L2_CID_MPEG_CLASS             V4L2_CID_CODEC_CLASS
diff --git a/include/linux/v4l2-mediabus.h b/include/linux/v4l2-mediabus.h
index 846dadfb..2c318de1 100644
--- a/include/linux/v4l2-mediabus.h
+++ b/include/linux/v4l2-mediabus.h
@@ -3,10 +3,6 @@
  * Media Bus API header
  *
  * Copyright (C) 2009, Guennadi Liakhovetski <g.liakhovetski@gmx.de>
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
  */
 
 #ifndef __LINUX_V4L2_MEDIABUS_H
diff --git a/include/linux/v4l2-subdev.h b/include/linux/v4l2-subdev.h
index 480891db..b383c2fe 100644
--- a/include/linux/v4l2-subdev.h
+++ b/include/linux/v4l2-subdev.h
@@ -6,24 +6,12 @@
  *
  * Contacts: Laurent Pinchart <laurent.pinchart@ideasonboard.com>
  *	     Sakari Ailus <sakari.ailus@iki.fi>
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
  */
 
 #ifndef __LINUX_V4L2_SUBDEV_H
 #define __LINUX_V4L2_SUBDEV_H
 
+#include <linux/const.h>
 #include <linux/ioctl.h>
 #include <linux/types.h>
 #include <linux/v4l2-common.h>
@@ -202,29 +190,14 @@ struct v4l2_subdev_capability {
 /* The v4l2 sub-device video device node is registered in read-only mode. */
 #define V4L2_SUBDEV_CAP_RO_SUBDEV		0x00000001
 
-/* The v4l2 sub-device supports multiplexed streams. */
-#define V4L2_SUBDEV_CAP_MPLEXED			0x00000002
+/* The v4l2 sub-device supports routing and multiplexed streams. */
+#define V4L2_SUBDEV_CAP_STREAMS			0x00000002
 
 /*
  * Is the route active? An active route will start when streaming is enabled
  * on a video node.
  */
-#define V4L2_SUBDEV_ROUTE_FL_ACTIVE		_BITUL(0)
-
-/*
- * Is the route immutable, i.e. can it be activated and inactivated?
- * Set by the driver.
- */
-#define V4L2_SUBDEV_ROUTE_FL_IMMUTABLE		_BITUL(1)
-
-/*
- * Is the route a source endpoint? A source endpoint route refers to a stream
- * generated internally by the subdevice (usually a sensor), and thus there
- * is no sink-side endpoint for the route. The sink_pad and sink_stream
- * fields are unused.
- * Set by the driver.
- */
-#define V4L2_SUBDEV_ROUTE_FL_SOURCE		_BITUL(2)
+#define V4L2_SUBDEV_ROUTE_FL_ACTIVE		(1U << 0)
 
 /**
  * struct v4l2_subdev_route - A route inside a subdev
@@ -260,6 +233,24 @@ struct v4l2_subdev_routing {
 	__u32 reserved[6];
 };
 
+/*
+ * The client is aware of streams. Setting this flag enables the use of 'stream'
+ * fields (referring to the stream number) with various ioctls. If this is not
+ * set (which is the default), the 'stream' fields will be forced to 0 by the
+ * kernel.
+ */
+ #define V4L2_SUBDEV_CLIENT_CAP_STREAMS		(1ULL << 0)
+
+/**
+ * struct v4l2_subdev_client_capability - Capabilities of the client accessing
+ *					  the subdev
+ *
+ * @capabilities: A bitmask of V4L2_SUBDEV_CLIENT_CAP_* flags.
+ */
+struct v4l2_subdev_client_capability {
+	__u64 capabilities;
+};
+
 /* Backwards compatibility define --- to be removed */
 #define v4l2_subdev_edid v4l2_edid
 
@@ -277,6 +268,9 @@ struct v4l2_subdev_routing {
 #define VIDIOC_SUBDEV_S_SELECTION		_IOWR('V', 62, struct v4l2_subdev_selection)
 #define VIDIOC_SUBDEV_G_ROUTING			_IOWR('V', 38, struct v4l2_subdev_routing)
 #define VIDIOC_SUBDEV_S_ROUTING			_IOWR('V', 39, struct v4l2_subdev_routing)
+#define VIDIOC_SUBDEV_G_CLIENT_CAP		_IOR('V',  101, struct v4l2_subdev_client_capability)
+#define VIDIOC_SUBDEV_S_CLIENT_CAP		_IOWR('V',  102, struct v4l2_subdev_client_capability)
+
 /* The following ioctls are identical to the ioctls in videodev2.h */
 #define VIDIOC_SUBDEV_G_STD			_IOR('V', 23, v4l2_std_id)
 #define VIDIOC_SUBDEV_S_STD			_IOW('V', 24, v4l2_std_id)
diff --git a/include/linux/videodev2.h b/include/linux/videodev2.h
index bfb315d6..14b1a06d 100644
--- a/include/linux/videodev2.h
+++ b/include/linux/videodev2.h
@@ -243,6 +243,7 @@ enum v4l2_colorspace {
 
 	/* DCI-P3 colorspace, used by cinema projectors */
 	V4L2_COLORSPACE_DCI_P3        = 12,
+
 };
 
 /*
@@ -474,7 +475,6 @@ struct v4l2_capability {
 #define V4L2_CAP_META_CAPTURE		0x00800000  /* Is a metadata capture device */
 
 #define V4L2_CAP_READWRITE              0x01000000  /* read/write systemcalls */
-#define V4L2_CAP_ASYNCIO                0x02000000  /* async I/O */
 #define V4L2_CAP_STREAMING              0x04000000  /* streaming I/O ioctls */
 #define V4L2_CAP_META_OUTPUT		0x08000000  /* Is a metadata output device */
 
@@ -549,6 +549,13 @@ struct v4l2_pix_format {
 #define V4L2_PIX_FMT_RGBX32  v4l2_fourcc('X', 'B', '2', '4') /* 32  RGBX-8-8-8-8  */
 #define V4L2_PIX_FMT_ARGB32  v4l2_fourcc('B', 'A', '2', '4') /* 32  ARGB-8-8-8-8  */
 #define V4L2_PIX_FMT_XRGB32  v4l2_fourcc('B', 'X', '2', '4') /* 32  XRGB-8-8-8-8  */
+#define V4L2_PIX_FMT_RGBX1010102 v4l2_fourcc('R', 'X', '3', '0') /* 32  RGBX-10-10-10-2 */
+#define V4L2_PIX_FMT_RGBA1010102 v4l2_fourcc('R', 'A', '3', '0') /* 32  RGBA-10-10-10-2 */
+#define V4L2_PIX_FMT_ARGB2101010 v4l2_fourcc('A', 'R', '3', '0') /* 32  ARGB-2-10-10-10 */
+
+/* RGB formats (6 or 8 bytes per pixel) */
+#define V4L2_PIX_FMT_BGR48_12    v4l2_fourcc('B', '3', '1', '2') /* 48  BGR 12-bit per component */
+#define V4L2_PIX_FMT_ABGR64_12   v4l2_fourcc('B', '4', '1', '2') /* 64  BGRA 12-bit per component */
 
 /* Grey formats */
 #define V4L2_PIX_FMT_GREY    v4l2_fourcc('G', 'R', 'E', 'Y') /*  8  Greyscale     */
@@ -556,6 +563,7 @@ struct v4l2_pix_format {
 #define V4L2_PIX_FMT_Y6      v4l2_fourcc('Y', '0', '6', ' ') /*  6  Greyscale     */
 #define V4L2_PIX_FMT_Y10     v4l2_fourcc('Y', '1', '0', ' ') /* 10  Greyscale     */
 #define V4L2_PIX_FMT_Y12     v4l2_fourcc('Y', '1', '2', ' ') /* 12  Greyscale     */
+#define V4L2_PIX_FMT_Y012    v4l2_fourcc('Y', '0', '1', '2') /* 12  Greyscale     */
 #define V4L2_PIX_FMT_Y14     v4l2_fourcc('Y', '1', '4', ' ') /* 14  Greyscale     */
 #define V4L2_PIX_FMT_Y16     v4l2_fourcc('Y', '1', '6', ' ') /* 16  Greyscale     */
 #define V4L2_PIX_FMT_Y16_BE  v4l2_fourcc_be('Y', '1', '6', ' ') /* 16  Greyscale BE  */
@@ -590,6 +598,15 @@ struct v4l2_pix_format {
 #define V4L2_PIX_FMT_YUVA32  v4l2_fourcc('Y', 'U', 'V', 'A') /* 32  YUVA-8-8-8-8  */
 #define V4L2_PIX_FMT_YUVX32  v4l2_fourcc('Y', 'U', 'V', 'X') /* 32  YUVX-8-8-8-8  */
 #define V4L2_PIX_FMT_M420    v4l2_fourcc('M', '4', '2', '0') /* 12  YUV 4:2:0 2 lines y, 1 line uv interleaved */
+#define V4L2_PIX_FMT_YUV48_12    v4l2_fourcc('Y', '3', '1', '2') /* 48  YUV 4:4:4 12-bit per component */
+
+/*
+ * YCbCr packed format. For each Y2xx format, xx bits of valid data occupy the MSBs
+ * of the 16 bit components, and 16-xx bits of zero padding occupy the LSBs.
+ */
+#define V4L2_PIX_FMT_Y210    v4l2_fourcc('Y', '2', '1', '0') /* 32  YUYV 4:2:2 */
+#define V4L2_PIX_FMT_Y212    v4l2_fourcc('Y', '2', '1', '2') /* 32  YUYV 4:2:2 */
+#define V4L2_PIX_FMT_Y216    v4l2_fourcc('Y', '2', '1', '6') /* 32  YUYV 4:2:2 */
 
 /* two planes -- one Y, one Cr + Cb interleaved  */
 #define V4L2_PIX_FMT_NV12    v4l2_fourcc('N', 'V', '1', '2') /* 12  Y/CbCr 4:2:0  */
@@ -598,12 +615,15 @@ struct v4l2_pix_format {
 #define V4L2_PIX_FMT_NV61    v4l2_fourcc('N', 'V', '6', '1') /* 16  Y/CrCb 4:2:2  */
 #define V4L2_PIX_FMT_NV24    v4l2_fourcc('N', 'V', '2', '4') /* 24  Y/CbCr 4:4:4  */
 #define V4L2_PIX_FMT_NV42    v4l2_fourcc('N', 'V', '4', '2') /* 24  Y/CrCb 4:4:4  */
+#define V4L2_PIX_FMT_P010    v4l2_fourcc('P', '0', '1', '0') /* 24  Y/CbCr 4:2:0 10-bit per component */
+#define V4L2_PIX_FMT_P012    v4l2_fourcc('P', '0', '1', '2') /* 24  Y/CbCr 4:2:0 12-bit per component */
 
 /* two non contiguous planes - one Y, one Cr + Cb interleaved  */
 #define V4L2_PIX_FMT_NV12M   v4l2_fourcc('N', 'M', '1', '2') /* 12  Y/CbCr 4:2:0  */
 #define V4L2_PIX_FMT_NV21M   v4l2_fourcc('N', 'M', '2', '1') /* 21  Y/CrCb 4:2:0  */
 #define V4L2_PIX_FMT_NV16M   v4l2_fourcc('N', 'M', '1', '6') /* 16  Y/CbCr 4:2:2  */
 #define V4L2_PIX_FMT_NV61M   v4l2_fourcc('N', 'M', '6', '1') /* 16  Y/CrCb 4:2:2  */
+#define V4L2_PIX_FMT_P012M   v4l2_fourcc('P', 'M', '1', '2') /* 24  Y/CbCr 4:2:0 12-bit per component */
 
 /* three planes - Y Cb, Cr */
 #define V4L2_PIX_FMT_YUV410  v4l2_fourcc('Y', 'U', 'V', '9') /*  9  YUV 4:1:0     */
@@ -625,6 +645,10 @@ struct v4l2_pix_format {
 #define V4L2_PIX_FMT_NV12_4L4 v4l2_fourcc('V', 'T', '1', '2')   /* 12  Y/CbCr 4:2:0  4x4 tiles */
 #define V4L2_PIX_FMT_NV12_16L16 v4l2_fourcc('H', 'M', '1', '2') /* 12  Y/CbCr 4:2:0 16x16 tiles */
 #define V4L2_PIX_FMT_NV12_32L32 v4l2_fourcc('S', 'T', '1', '2') /* 12  Y/CbCr 4:2:0 32x32 tiles */
+#define V4L2_PIX_FMT_NV15_4L4 v4l2_fourcc('V', 'T', '1', '5') /* 15 Y/CbCr 4:2:0 10-bit 4x4 tiles */
+#define V4L2_PIX_FMT_P010_4L4 v4l2_fourcc('T', '0', '1', '0') /* 12  Y/CbCr 4:2:0 10-bit 4x4 macroblocks */
+#define V4L2_PIX_FMT_NV12_8L128       v4l2_fourcc('A', 'T', '1', '2') /* Y/CbCr 4:2:0 8x128 tiles */
+#define V4L2_PIX_FMT_NV12_10BE_8L128  v4l2_fourcc_be('A', 'X', '1', '2') /* Y/CbCr 4:2:0 10-bit 8x128 tiles */
 
 /* Tiled YUV formats, non contiguous planes */
 #define V4L2_PIX_FMT_NV12MT  v4l2_fourcc('T', 'M', '1', '2') /* 12  Y/CbCr 4:2:0 64x32 tiles */
@@ -707,6 +731,11 @@ struct v4l2_pix_format {
 #define V4L2_PIX_FMT_FWHT     v4l2_fourcc('F', 'W', 'H', 'T') /* Fast Walsh Hadamard Transform (vicodec) */
 #define V4L2_PIX_FMT_FWHT_STATELESS     v4l2_fourcc('S', 'F', 'W', 'H') /* Stateless FWHT (vicodec) */
 #define V4L2_PIX_FMT_H264_SLICE v4l2_fourcc('S', '2', '6', '4') /* H264 parsed slices */
+#define V4L2_PIX_FMT_HEVC_SLICE v4l2_fourcc('S', '2', '6', '5') /* HEVC parsed slices */
+#define V4L2_PIX_FMT_AV1_FRAME v4l2_fourcc('A', 'V', '1', 'F') /* AV1 parsed frame */
+#define V4L2_PIX_FMT_SPK      v4l2_fourcc('S', 'P', 'K', '0') /* Sorenson Spark */
+#define V4L2_PIX_FMT_RV30     v4l2_fourcc('R', 'V', '3', '0') /* RealVideo 8 */
+#define V4L2_PIX_FMT_RV40     v4l2_fourcc('R', 'V', '4', '0') /* RealVideo 9 & 10 */
 
 /*  Vendor-specific formats   */
 #define V4L2_PIX_FMT_CPIA1    v4l2_fourcc('C', 'P', 'I', 'A') /* cpia1 YUV */
@@ -740,11 +769,15 @@ struct v4l2_pix_format {
 #define V4L2_PIX_FMT_Z16      v4l2_fourcc('Z', '1', '6', ' ') /* Depth data 16-bit */
 #define V4L2_PIX_FMT_MT21C    v4l2_fourcc('M', 'T', '2', '1') /* Mediatek compressed block mode  */
 #define V4L2_PIX_FMT_MM21     v4l2_fourcc('M', 'M', '2', '1') /* Mediatek 8-bit block mode, two non-contiguous planes */
+#define V4L2_PIX_FMT_MT2110T  v4l2_fourcc('M', 'T', '2', 'T') /* Mediatek 10-bit block tile mode */
+#define V4L2_PIX_FMT_MT2110R  v4l2_fourcc('M', 'T', '2', 'R') /* Mediatek 10-bit block raster mode */
 #define V4L2_PIX_FMT_INZI     v4l2_fourcc('I', 'N', 'Z', 'I') /* Intel Planar Greyscale 10-bit and Depth 16-bit */
 #define V4L2_PIX_FMT_CNF4     v4l2_fourcc('C', 'N', 'F', '4') /* Intel 4-bit packed depth confidence information */
 #define V4L2_PIX_FMT_HI240    v4l2_fourcc('H', 'I', '2', '4') /* BTTV 8-bit dithered RGB */
 #define V4L2_PIX_FMT_QC08C    v4l2_fourcc('Q', '0', '8', 'C') /* Qualcomm 8-bit compressed */
 #define V4L2_PIX_FMT_QC10C    v4l2_fourcc('Q', '1', '0', 'C') /* Qualcomm 10-bit compressed */
+#define V4L2_PIX_FMT_AJPG     v4l2_fourcc('A', 'J', 'P', 'G') /* Aspeed JPEG */
+#define V4L2_PIX_FMT_HEXTILE  v4l2_fourcc('H', 'X', 'T', 'L') /* Hextile compressed */
 
 /* 10bit raw packed, 32 bytes for every 25 pixels, last LSB 6 bits unused */
 #define V4L2_PIX_FMT_IPU3_SBGGR10	v4l2_fourcc('i', 'p', '3', 'b') /* IPU3 packed 10-bit BGGR bayer */
@@ -781,6 +814,10 @@ struct v4l2_pix_format {
 #define V4L2_META_FMT_RK_ISP1_PARAMS	v4l2_fourcc('R', 'K', '1', 'P') /* Rockchip ISP1 3A Parameters */
 #define V4L2_META_FMT_RK_ISP1_STAT_3A	v4l2_fourcc('R', 'K', '1', 'S') /* Rockchip ISP1 3A Statistics */
 
+/* Vendor specific - used for STM32_DCMIPP camera sub-system */
+#define V4L2_META_FMT_ST_DCMIPP_ISP_PARAMS	v4l2_fourcc('S', 'T', 'I', 'P') /* STM32 DCMIPP ISP Parameters */
+#define V4L2_META_FMT_ST_DCMIPP_ISP_STAT	v4l2_fourcc('S', 'T', 'I', 'S') /* STM32 DCMIPP ISP Statistics */
+
 /* priv field value to indicates that subsequent fields are valid. */
 #define V4L2_PIX_FMT_PRIV_MAGIC		0xfeedcafe
 
@@ -1550,7 +1587,8 @@ struct v4l2_bt_timings {
 	((bt)->width + V4L2_DV_BT_BLANKING_WIDTH(bt))
 #define V4L2_DV_BT_BLANKING_HEIGHT(bt) \
 	((bt)->vfrontporch + (bt)->vsync + (bt)->vbackporch + \
-	 (bt)->il_vfrontporch + (bt)->il_vsync + (bt)->il_vbackporch)
+	 ((bt)->interlaced ? \
+	  ((bt)->il_vfrontporch + (bt)->il_vsync + (bt)->il_vbackporch) : 0))
 #define V4L2_DV_BT_FRAME_HEIGHT(bt) \
 	((bt)->height + V4L2_DV_BT_BLANKING_HEIGHT(bt))
 
@@ -1641,7 +1679,7 @@ struct v4l2_input {
 	__u8	     name[32];		/*  Label */
 	__u32	     type;		/*  Type of input */
 	__u32	     audioset;		/*  Associated audios (bitfield) */
-	__u32        tuner;             /*  enum v4l2_tuner_type */
+	__u32        tuner;             /*  Tuner index */
 	v4l2_std_id  std;
 	__u32	     status;
 	__u32	     capabilities;
@@ -1728,6 +1766,8 @@ struct v4l2_ext_control {
 		__u8 *p_u8;
 		__u16 *p_u16;
 		__u32 *p_u32;
+		__s32 *p_s32;
+		__s64 *p_s64;
 		struct v4l2_area *p_area;
 		struct v4l2_ctrl_h264_sps *p_h264_sps;
 		struct v4l2_ctrl_h264_pps *p_h264_pps;
@@ -1742,6 +1782,15 @@ struct v4l2_ext_control {
 		struct v4l2_ctrl_mpeg2_quantisation *p_mpeg2_quantisation;
 		struct v4l2_ctrl_vp9_compressed_hdr *p_vp9_compressed_hdr_probs;
 		struct v4l2_ctrl_vp9_frame *p_vp9_frame;
+		struct v4l2_ctrl_hevc_sps *p_hevc_sps;
+		struct v4l2_ctrl_hevc_pps *p_hevc_pps;
+		struct v4l2_ctrl_hevc_slice_params *p_hevc_slice_params;
+		struct v4l2_ctrl_hevc_scaling_matrix *p_hevc_scaling_matrix;
+		struct v4l2_ctrl_hevc_decode_params *p_hevc_decode_params;
+		struct v4l2_ctrl_av1_sequence *p_av1_sequence;
+		struct v4l2_ctrl_av1_tile_group_entry *p_av1_tile_group_entry;
+		struct v4l2_ctrl_av1_frame *p_av1_frame;
+		struct v4l2_ctrl_av1_film_grain *p_av1_film_grain;
 		void *ptr;
 	};
 } __attribute__ ((packed));
@@ -1805,6 +1854,18 @@ enum v4l2_ctrl_type {
 
 	V4L2_CTRL_TYPE_VP9_COMPRESSED_HDR	= 0x0260,
 	V4L2_CTRL_TYPE_VP9_FRAME		= 0x0261,
+
+	V4L2_CTRL_TYPE_HEVC_SPS			= 0x0270,
+	V4L2_CTRL_TYPE_HEVC_PPS			= 0x0271,
+	V4L2_CTRL_TYPE_HEVC_SLICE_PARAMS	= 0x0272,
+	V4L2_CTRL_TYPE_HEVC_SCALING_MATRIX	= 0x0273,
+	V4L2_CTRL_TYPE_HEVC_DECODE_PARAMS	= 0x0274,
+
+	V4L2_CTRL_TYPE_ISP_STAT_REGION     = 0x0310,
+	V4L2_CTRL_TYPE_AV1_SEQUENCE	    = 0x280,
+	V4L2_CTRL_TYPE_AV1_TILE_GROUP_ENTRY = 0x281,
+	V4L2_CTRL_TYPE_AV1_FRAME	    = 0x282,
+	V4L2_CTRL_TYPE_AV1_FILM_GRAIN	    = 0x283,
 };
 
 /*  Used in the VIDIOC_QUERYCTRL ioctl for querying controls */
@@ -1860,6 +1921,7 @@ struct v4l2_querymenu {
 #define V4L2_CTRL_FLAG_HAS_PAYLOAD	0x0100
 #define V4L2_CTRL_FLAG_EXECUTE_ON_WRITE	0x0200
 #define V4L2_CTRL_FLAG_MODIFY_LAYOUT	0x0400
+#define V4L2_CTRL_FLAG_DYNAMIC_ARRAY	0x0800
 
 /*  Query flags, to be ORed with the control ID */
 #define V4L2_CTRL_FLAG_NEXT_CTRL	0x80000000
@@ -2367,6 +2429,7 @@ struct v4l2_event_vsync {
 #define V4L2_EVENT_CTRL_CH_VALUE		(1 << 0)
 #define V4L2_EVENT_CTRL_CH_FLAGS		(1 << 1)
 #define V4L2_EVENT_CTRL_CH_RANGE		(1 << 2)
+#define V4L2_EVENT_CTRL_CH_DIMENSIONS		(1 << 3)
 
 struct v4l2_event_ctrl {
 	__u32 changes;
@@ -2609,5 +2672,10 @@ struct v4l2_create_buffers {
 /* Deprecated definitions kept for backwards compatibility */
 #define V4L2_PIX_FMT_HM12 V4L2_PIX_FMT_NV12_16L16
 #define V4L2_PIX_FMT_SUNXI_TILED_NV12 V4L2_PIX_FMT_NV12_32L32
+/*
+ * This capability was never implemented, anyone using this cap should drop it
+ * from their code.
+ */
+#define V4L2_CAP_ASYNCIO 0x02000000
 
 #endif /* __LINUX_VIDEODEV2_H */
diff --git a/meson.build b/meson.build
index cb6b666a..27644e8e 100644
--- a/meson.build
+++ b/meson.build
@@ -201,6 +201,7 @@ pipelines_support = {
     'rkisp1':       arch_arm,
     'rpi/vc4':      arch_arm,
     'simple':       arch_arm,
+    'dcmipp':       arch_arm,
     'uvcvideo':     ['any'],
     'vimc':         ['test'],
 }
diff --git a/meson_options.txt b/meson_options.txt
index 5fdc7be8..0b4bc25a 100644
--- a/meson_options.txt
+++ b/meson_options.txt
@@ -27,7 +27,7 @@ option('gstreamer',
 
 option('ipas',
         type : 'array',
-        choices : ['ipu3', 'rkisp1', 'rpi/vc4', 'vimc'],
+        choices : ['dcmipp', 'ipu3', 'rkisp1', 'rpi/vc4', 'vimc'],
         description : 'Select which IPA modules to build')
 
 option('lc-compliance',
@@ -47,7 +47,8 @@ option('pipelines',
             'rpi/vc4',
             'simple',
             'uvcvideo',
-            'vimc'
+            'vimc',
+            'dcmipp'
         ],
         description : 'Select which pipeline handlers to build. If this is set to "auto", all the pipelines applicable to the target architecture will be built. If this is set to "all", all the pipelines will be built. If both are selected then "all" will take precedence.')
 
@@ -80,3 +81,8 @@ option('v4l2',
         type : 'boolean',
         value : false,
         description : 'Compile the V4L2 compatibility layer')
+
+option('evision_algo',
+        type : 'boolean',
+        value : false,
+        description : 'Compile dcmipp with algorithms from evision libraries')
diff --git a/src/apps/cam/camera_session.cpp b/src/apps/cam/camera_session.cpp
index 8447f932..42fa9dd7 100644
--- a/src/apps/cam/camera_session.cpp
+++ b/src/apps/cam/camera_session.cpp
@@ -360,8 +360,15 @@ int CameraSession::queueRequest(Request *request)
 	if (captureLimit_ && queueCount_ >= captureLimit_)
 		return 0;
 
-	if (script_)
-		request->controls() = script_->frameControls(queueCount_);
+	if (script_) {
+		const ControlList &controls = script_->frameControls(queueCount_);
+		for (auto const &ctrl : controls)
+			std::cout << "\tRequest ctrl: "
+				  << controls::controls.at(ctrl.first)->name()
+				  << " = " << ctrl.second.toString()
+				  << std::endl;
+		request->controls() = controls;
+	}
 
 	queueCount_++;
 
diff --git a/src/apps/cam/capture_script.cpp b/src/apps/cam/capture_script.cpp
index 062a7258..1215713f 100644
--- a/src/apps/cam/capture_script.cpp
+++ b/src/apps/cam/capture_script.cpp
@@ -351,7 +351,10 @@ ControlValue CaptureScript::parseRectangles()
 	}
 
 	ControlValue controlValue;
-	controlValue.set(Span<const Rectangle>(rectangles));
+	if (rectangles.size() == 1)
+		controlValue.set(rectangles.at(0));
+	else
+		controlValue.set(Span<const Rectangle>(rectangles));
 
 	return controlValue;
 }
diff --git a/src/apps/common/dng_writer.cpp b/src/apps/common/dng_writer.cpp
index c945edce..82bc065a 100644
--- a/src/apps/common/dng_writer.cpp
+++ b/src/apps/common/dng_writer.cpp
@@ -248,6 +248,7 @@ void thumbScanlineIPU3([[maybe_unused]] const FormatInfo &info, void *output,
 
 		uint16_t val1, val2, val3, val4;
 		switch (pixelInBlock % 4) {
+		default:
 		case 0:
 			val1 = (in[1] & 0x03) << 14 | (in[0] & 0xff) << 6;
 			val2 = (in[2] & 0x0f) << 12 | (in[1] & 0xfc) << 4;
diff --git a/src/gstreamer/gstlibcamera-utils.cpp b/src/gstreamer/gstlibcamera-utils.cpp
index 750ec351..3f0c13f5 100644
--- a/src/gstreamer/gstlibcamera-utils.cpp
+++ b/src/gstreamer/gstlibcamera-utils.cpp
@@ -25,6 +25,22 @@ static struct {
 	{ GST_VIDEO_FORMAT_ENCODED, formats::SGBRG8 },
 	{ GST_VIDEO_FORMAT_ENCODED, formats::SGRBG8 },
 	{ GST_VIDEO_FORMAT_ENCODED, formats::SRGGB8 },
+	{ GST_VIDEO_FORMAT_ENCODED, formats::SBGGR10 },
+	{ GST_VIDEO_FORMAT_ENCODED, formats::SGBRG10 },
+	{ GST_VIDEO_FORMAT_ENCODED, formats::SGRBG10 },
+	{ GST_VIDEO_FORMAT_ENCODED, formats::SRGGB10 },
+	{ GST_VIDEO_FORMAT_ENCODED, formats::SBGGR12 },
+	{ GST_VIDEO_FORMAT_ENCODED, formats::SGBRG12 },
+	{ GST_VIDEO_FORMAT_ENCODED, formats::SGRBG12 },
+	{ GST_VIDEO_FORMAT_ENCODED, formats::SRGGB12 },
+	{ GST_VIDEO_FORMAT_ENCODED, formats::SBGGR14 },
+	{ GST_VIDEO_FORMAT_ENCODED, formats::SGBRG14 },
+	{ GST_VIDEO_FORMAT_ENCODED, formats::SGRBG14 },
+	{ GST_VIDEO_FORMAT_ENCODED, formats::SRGGB14 },
+	{ GST_VIDEO_FORMAT_ENCODED, formats::SBGGR16 },
+	{ GST_VIDEO_FORMAT_ENCODED, formats::SGBRG16 },
+	{ GST_VIDEO_FORMAT_ENCODED, formats::SGRBG16 },
+	{ GST_VIDEO_FORMAT_ENCODED, formats::SRGGB16 },
 
 	/* RGB16 */
 	{ GST_VIDEO_FORMAT_RGB16, formats::RGB565 },
@@ -246,6 +262,38 @@ bayer_format_to_string(int format)
 		return "grbg";
 	case formats::SRGGB8:
 		return "rggb";
+	case formats::SBGGR10:
+		return "bggr10le";
+	case formats::SGBRG10:
+		return "gbrg10le";
+	case formats::SGRBG10:
+		return "grbg10le";
+	case formats::SRGGB10:
+		return "rggb10le";
+	case formats::SBGGR12:
+		return "bggr12le";
+	case formats::SGBRG12:
+		return "gbrg12le";
+	case formats::SGRBG12:
+		return "grbg12le";
+	case formats::SRGGB12:
+		return "rggb12le";
+	case formats::SBGGR14:
+		return "bggr14le";
+	case formats::SGBRG14:
+		return "gbrg14le";
+	case formats::SGRBG14:
+		return "grbg14le";
+	case formats::SRGGB14:
+		return "rggb14le";
+	case formats::SBGGR16:
+		return "bggr16le";
+	case formats::SGBRG16:
+		return "gbrg16le";
+	case formats::SGRBG16:
+		return "grbg16le";
+	case formats::SRGGB16:
+		return "rggb16le";
 	}
 	return NULL;
 }
@@ -270,6 +318,22 @@ bare_structure_from_format(const PixelFormat &format)
 	case formats::SGBRG8:
 	case formats::SGRBG8:
 	case formats::SRGGB8:
+	case formats::SBGGR10:
+	case formats::SGBRG10:
+	case formats::SGRBG10:
+	case formats::SRGGB10:
+	case formats::SBGGR12:
+	case formats::SGBRG12:
+	case formats::SGRBG12:
+	case formats::SRGGB12:
+	case formats::SBGGR14:
+	case formats::SGBRG14:
+	case formats::SGRBG14:
+	case formats::SRGGB14:
+	case formats::SBGGR16:
+	case formats::SGBRG16:
+	case formats::SGRBG16:
+	case formats::SRGGB16:
 		return gst_structure_new("video/x-bayer", "format", G_TYPE_STRING,
 					 bayer_format_to_string(format), nullptr);
 
diff --git a/src/gstreamer/gstlibcamerapad.cpp b/src/gstreamer/gstlibcamerapad.cpp
index 9e710a47..5f43ed81 100644
--- a/src/gstreamer/gstlibcamerapad.cpp
+++ b/src/gstreamer/gstlibcamerapad.cpp
@@ -99,6 +99,10 @@ gst_libcamera_stream_role_get_type()
 			static_cast<gint>(StreamRole::Viewfinder),
 			"libcamera::Viewfinder",
 			"view-finder",
+		}, {
+			static_cast<gint>(StreamRole::Raw),
+			"libcamera::Raw",
+			"raw",
 		},
 		{ 0, NULL, NULL }
 	};
diff --git a/src/gstreamer/gstlibcamerasrc.cpp b/src/gstreamer/gstlibcamerasrc.cpp
index f015c6d2..c6029738 100644
--- a/src/gstreamer/gstlibcamerasrc.cpp
+++ b/src/gstreamer/gstlibcamerasrc.cpp
@@ -30,6 +30,7 @@
 #include <atomic>
 #include <queue>
 #include <vector>
+#include <sstream>
 
 #include <libcamera/camera.h>
 #include <libcamera/camera_manager.h>
@@ -129,6 +130,9 @@ struct GstLibcameraSrcState {
 	ControlList initControls_;
 	guint group_id_;
 
+	GMutex controlsLock_; /* Protects pendingControls_ */
+	ControlList pendingControls_;
+
 	int queueRequest();
 	void requestCompleted(Request *request);
 	int processRequest();
@@ -144,6 +148,44 @@ struct _GstLibcameraSrc {
 	gchar *camera_name;
 	controls::AfModeEnum auto_focus_mode = controls::AfModeManual;
 
+	struct LibCameraControls {
+		/* Add all ISP controls */
+		int hwrevision[2];
+		int decimation;
+		bool black_level_enable;
+		int black_level_values[3];
+		libcamera::Rectangle statistic_area;
+		bool contrast_enable;
+		int contrast_values[9];
+		bool aec_algo_enable;
+		float aec_algo_exposure_compensation;
+		int aec_algo_exposure_target;
+		float sensor_gain_dB;
+		int sensor_exposure;
+		bool badpix_enable;
+		int badpix_strength;
+		int badpix_count;
+		int badpix_algo_threshold;
+		bool ispgain_enable;
+		int ispgain_values[3];
+		bool ccm_enable;
+		int ccm_values[9];
+		bool awb_algo_enable;
+		std::array<std::string, 5> awb_algo_profile_names;
+		std::array<int, 5> awb_algo_profile_color_temps;
+		std::array<int, 5 * 3> awb_algo_profile_isp_gains;
+		std::array<int, 5 * 3 * 3> awb_algo_profile_ccms;
+		std::string awb_current_profile_name;
+		int awb_current_profile_color_temp;
+		bool demosaicing_enable;
+		std::array<int, 4> demosaicing_filters;
+		int statistic_profile;
+		std::array<int, 4> statistic_avg_up;
+		std::array<int, 4> statistic_avg_down;
+		std::array<int, 12> statistic_hist_up;
+		std::array<int, 12> statistic_hist_down;
+	} ctrl;
+
 	std::atomic<GstEvent *> pending_eos;
 
 	GstLibcameraSrcState *state;
@@ -155,9 +197,48 @@ enum {
 	PROP_0,
 	PROP_CAMERA_NAME,
 	PROP_AUTO_FOCUS_MODE,
+	PROP_HW_REVISION,
+	PROP_DECIMATION,
+	PROP_BLACK_LEVEL_ENABLE,
+	PROP_BLACK_LEVEL_VALUES,
+	PROP_STATISTIC_AREA,
+	PROP_CONTRAST_ENABLE,
+	PROP_CONTRAST_VALUES,
+	PROP_AEC_ALGO_ENABLE,
+	PROP_AEC_ALGO_EXPOSURE_COMPENSATION,
+	PROP_AEC_ALGO_EXPOSURE_TARGET,
+	PROP_SENSOR_GAIN,
+	PROP_SENSOR_EXPOSURE,
+	PROP_BADPIX_ENABLE,
+	PROP_BADPIX_STRENGTH,
+	PROP_BADPIX_COUNT,
+	PROP_BADPIX_ALGO_THRESHOLD,
+	PROP_ISP_GAIN_ENABLE,
+	PROP_ISP_GAIN_VALUES,
+	PROP_CCM_ENABLE,
+	PROP_CCM_VALUES,
+	PROP_AWB_ALGO_ENABLE,
+	PROP_AWB_ALGO_PROFILE_NAMES,
+	PROP_AWB_ALGO_PROFILE_COLOR_TEMPS,
+	PROP_AWB_ALGO_PROFILE_ISP_GAINS,
+	PROP_AWB_ALGO_PROFILE_CCMS,
+	PROP_AWB_CURRENT_PROFILE_NAME,
+	PROP_AWB_CURRENT_PROFILE_COLOR_TEMP,
+	PROP_DEMOSAICING_ENABLE,
+	PROP_DEMOSAICING_FILTERS,
+	PROP_STATISTIC_PROFILE,
+	PROP_STATISTIC_GET_AVERAGE_UP,
+	PROP_STATISTIC_GET_AVERAGE_DOWN,
+	PROP_STATISTIC_GET_HISTOGRAM_UP,
+	PROP_STATISTIC_GET_HISTOGRAM_DOWN,
 };
 
+static void gst_libcamera_src_child_proxy_init(gpointer g_iface,
+					       gpointer iface_data);
+
 G_DEFINE_TYPE_WITH_CODE(GstLibcameraSrc, gst_libcamera_src, GST_TYPE_ELEMENT,
+			G_IMPLEMENT_INTERFACE(GST_TYPE_CHILD_PROXY,
+					      gst_libcamera_src_child_proxy_init)
 			GST_DEBUG_CATEGORY_INIT(source_debug, "libcamerasrc", 0,
 						"libcamera Source"))
 
@@ -203,7 +284,19 @@ int GstLibcameraSrcState::queueRequest()
 	}
 
 	GST_TRACE_OBJECT(src_, "Requesting buffers");
-	cam_->queueRequest(wrap->request_.get());
+
+	Request *req = wrap->request_.get();
+
+	/* Add then clear pending controls to the request */
+	ControlList controls;
+	{
+		GLibLocker locker(&src_->state->controlsLock_);
+		controls = src_->state->pendingControls_;
+		src_->state->pendingControls_.clear();
+	}
+	req->controls() = controls;
+
+	cam_->queueRequest(req);
 
 	{
 		GLibLocker locker(&lock_);
@@ -234,6 +327,160 @@ GstLibcameraSrcState::requestCompleted(Request *request)
 		return;
 	}
 
+	/* Update the properties from the libcamera metadata */
+	const auto HwRevision = request->metadata().get(controls::draft::PipelineHwRevision);
+	if (HwRevision) {
+		src_->ctrl.hwrevision[0] = *HwRevision >> 4;    /* Major */
+		src_->ctrl.hwrevision[1] = *HwRevision & 0x0F;  /* Minor */
+	}
+	const auto IspDecimation = request->metadata().get(controls::draft::IspDecimationRatio);
+	if (IspDecimation) {
+		src_->ctrl.decimation = *IspDecimation;
+	}
+	const auto BlackLevelEnable = request->metadata().get(controls::draft::BlackLevelCorrectionEnable);
+	if (BlackLevelEnable) {
+		src_->ctrl.black_level_enable = *BlackLevelEnable;
+	}
+	const auto BlackLevel = request->metadata().get(controls::draft::BlackLevelCorrectionLevels);
+	if (BlackLevel) {
+		src_->ctrl.black_level_values[0] = (*BlackLevel)[0];
+		src_->ctrl.black_level_values[1] = (*BlackLevel)[1];
+		src_->ctrl.black_level_values[2] = (*BlackLevel)[2];
+	}
+	const auto StatisticArea = request->metadata().get(controls::draft::StatisticArea);
+	if (StatisticArea) {
+		src_->ctrl.statistic_area = *StatisticArea;
+	}
+	const auto ContrastEnable = request->metadata().get(controls::draft::ContrastLuminanceEnable);
+	if (ContrastEnable) {
+		src_->ctrl.contrast_enable = *ContrastEnable;
+	}
+	const auto ContrastLevel = request->metadata().get(controls::draft::ContrastLuminance);
+	if (ContrastLevel) {
+		for (unsigned int i = 0; i < 9; i++) {
+			src_->ctrl.contrast_values[i] = (*ContrastLevel)[i];
+		}
+	}
+	const auto AecAlgoEnable = request->metadata().get(controls::AeEnable);
+	if (AecAlgoEnable) {
+		src_->ctrl.aec_algo_enable = *AecAlgoEnable;
+	}
+	const auto AecAlgoExposureCompensation = request->metadata().get(controls::ExposureValue);
+	if (AecAlgoExposureCompensation) {
+		src_->ctrl.aec_algo_exposure_compensation = *AecAlgoExposureCompensation;
+	}
+	const auto AecAlgoExposureTarget = request->metadata().get(controls::draft::AeExposureTarget);
+	if (AecAlgoExposureTarget) {
+		src_->ctrl.aec_algo_exposure_target = *AecAlgoExposureTarget;
+	}
+	const auto SensorGaindB = request->metadata().get(controls::draft::AnalogueGain_dB);
+	if (SensorGaindB) {
+		src_->ctrl.sensor_gain_dB = *SensorGaindB;
+	}
+	const auto SensorExposure = request->metadata().get(controls::ExposureTime);
+	if (SensorExposure) {
+		src_->ctrl.sensor_exposure = *SensorExposure;
+	}
+	const auto BadPixEnable = request->metadata().get(controls::draft::BadPixelRemovalEnable);
+	if (BadPixEnable) {
+		src_->ctrl.badpix_enable = *BadPixEnable;
+	}
+	const auto BadPixStrength = request->metadata().get(controls::draft::BadPixelRemovalStrength);
+	if (BadPixStrength) {
+		src_->ctrl.badpix_strength = *BadPixStrength;
+	}
+	const auto BadPixCount = request->metadata().get(controls::draft::BadPixelRemovalCount);
+	if (BadPixCount) {
+		src_->ctrl.badpix_count = *BadPixCount;
+	}
+	const auto BadPixAlgoThreshold = request->metadata().get(controls::draft::BadPixelRemovalThreshold);
+	if (BadPixAlgoThreshold) {
+		src_->ctrl.badpix_algo_threshold = *BadPixAlgoThreshold;
+	}
+	const auto IspGainEnable = request->metadata().get(controls::draft::ColourGains3Enable);
+	if (IspGainEnable) {
+		src_->ctrl.ispgain_enable = *IspGainEnable;
+	}
+	const auto IspGainValues = request->metadata().get(controls::draft::ColourGains3);
+	if (IspGainValues) {
+		for (unsigned int i = 0; i < 3; i++) {
+			src_->ctrl.ispgain_values[i] = (*IspGainValues)[i];
+		}
+	}
+	const auto CcmEnable = request->metadata().get(controls::draft::ColourCorrectionEnable);
+	if (CcmEnable) {
+		src_->ctrl.ccm_enable = *CcmEnable;
+	}
+	const auto CcmValues = request->metadata().get(controls::draft::ColourCorrection);
+	if (CcmValues) {
+		for (unsigned int i = 0; i < 9; i++) {
+			src_->ctrl.ccm_values[i] = (*CcmValues)[i];
+		}
+	}
+	const auto AwbAlgoEnable = request->metadata().get(controls::AwbEnable);
+	if (AwbAlgoEnable) {
+		src_->ctrl.awb_algo_enable = *AwbAlgoEnable;
+	}
+	const auto AwbAlgoProfileNames = request->metadata().get(controls::draft::AwbProfileName);
+	if (AwbAlgoProfileNames) {
+		/* The Controls class does not support array of string. So, split the concatenated string */
+		std::string token;
+		std::stringstream ss(*AwbAlgoProfileNames);
+		for (int i = 0; i < (int)src_->ctrl.awb_algo_profile_names.size(); i++) {
+			if (!getline(ss, token, '$'))
+				token = "";
+			src_->ctrl.awb_algo_profile_names[i] = token;
+		}
+	}
+	const auto AwbAlgoProfileColorTemps = request->metadata().get(controls::draft::AwbReferenceColorTemperature);
+	if (AwbAlgoProfileColorTemps) {
+		std::copy(std::begin(*AwbAlgoProfileColorTemps), std::end(*AwbAlgoProfileColorTemps), src_->ctrl.awb_algo_profile_color_temps.begin());
+	}
+	const auto AwbAlgoProfileIspGains = request->metadata().get(controls::draft::AwbColourGains3);
+	if (AwbAlgoProfileIspGains) {
+		std::copy(std::begin(*AwbAlgoProfileIspGains), std::end(*AwbAlgoProfileIspGains), src_->ctrl.awb_algo_profile_isp_gains.begin());
+	}
+	const auto AwbAlgoProfilesCcms = request->metadata().get(controls::draft::AwbColourCorrection);
+	if (AwbAlgoProfilesCcms) {
+		std::copy(std::begin(*AwbAlgoProfilesCcms), std::end(*AwbAlgoProfilesCcms), src_->ctrl.awb_algo_profile_ccms.begin());
+	}
+	const auto AwbCurProfileName = request->metadata().get(controls::draft::AwbCurrentProfileName);
+	if (AwbCurProfileName) {
+		src_->ctrl.awb_current_profile_name = *AwbCurProfileName;
+	}
+	const auto AwbCurProfileColorTemp = request->metadata().get(controls::ColourTemperature);
+	if (AwbCurProfileColorTemp) {
+		src_->ctrl.awb_current_profile_color_temp = *AwbCurProfileColorTemp;
+	}
+	const auto DemosaicingEnable = request->metadata().get(controls::draft::DemosaicingEnable);
+	if (DemosaicingEnable) {
+		src_->ctrl.demosaicing_enable = *DemosaicingEnable;
+	}
+	const auto DemosaicingFilters = request->metadata().get(controls::draft::DemosaicingFilter);
+	if (DemosaicingFilters) {
+		std::copy(std::begin(*DemosaicingFilters), std::end(*DemosaicingFilters), src_->ctrl.demosaicing_filters.begin());
+	}
+	const auto StatProfile = request->metadata().get(controls::draft::StatisticProfile);
+	if (StatProfile) {
+		src_->ctrl.statistic_profile = *StatProfile;
+	}
+	const auto StatAvgUp = request->metadata().get(controls::draft::StatisticAverageUp);
+	if (StatAvgUp) {
+		std::copy(std::begin(*StatAvgUp), std::end(*StatAvgUp), src_->ctrl.statistic_avg_up.begin());
+	}
+	const auto StatAvgDown = request->metadata().get(controls::draft::StatisticAverageDown);
+	if (StatAvgDown) {
+		std::copy(std::begin(*StatAvgDown), std::end(*StatAvgDown), src_->ctrl.statistic_avg_down.begin());
+	}
+	const auto StatHistUp = request->metadata().get(controls::draft::StatisticBinsUp);
+	if (StatHistUp) {
+		std::copy(std::begin(*StatHistUp), std::end(*StatHistUp), src_->ctrl.statistic_hist_up.begin());
+	}
+	const auto StatHistDown = request->metadata().get(controls::draft::StatisticBinsDown);
+	if (StatHistDown) {
+		std::copy(std::begin(*StatHistDown), std::end(*StatHistDown), src_->ctrl.statistic_hist_down.begin());
+	}
+
 	if (GST_ELEMENT_CLOCK(src_)) {
 		int64_t timestamp = request->metadata().get(controls::SensorTimestamp).value_or(0);
 
@@ -669,6 +916,7 @@ gst_libcamera_src_task_enter(GstTask *task, [[maybe_unused]] GThread *thread,
 		}
 	}
 
+	/* Note: controls provided at start() are dropped by IPA */
 	ret = state->cam_->start(&state->initControls_);
 	if (ret) {
 		GST_ELEMENT_ERROR(self, RESOURCE, SETTINGS,
@@ -730,6 +978,7 @@ gst_libcamera_src_set_property(GObject *object, guint prop_id,
 {
 	GLibLocker lock(GST_OBJECT(object));
 	GstLibcameraSrc *self = GST_LIBCAMERA_SRC(object);
+	GstLibcameraSrcState *state = self->state;
 
 	switch (prop_id) {
 	case PROP_CAMERA_NAME:
@@ -739,6 +988,222 @@ gst_libcamera_src_set_property(GObject *object, guint prop_id,
 	case PROP_AUTO_FOCUS_MODE:
 		self->auto_focus_mode = static_cast<controls::AfModeEnum>(g_value_get_enum(value));
 		break;
+	case PROP_BLACK_LEVEL_ENABLE:
+	{
+		bool enable = g_value_get_boolean(value);
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::BlackLevelCorrectionEnable,
+					    enable);
+		break;
+	}
+	case PROP_BLACK_LEVEL_VALUES:
+	{
+		int blR = g_value_get_int(gst_value_array_get_value(value, 0));
+		int blG = g_value_get_int(gst_value_array_get_value(value, 1));
+		int blB = g_value_get_int(gst_value_array_get_value(value, 2));
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::BlackLevelCorrectionLevels,
+					    { blR, blG, blB });
+		break;
+	}
+	case PROP_STATISTIC_AREA:
+	{
+		libcamera::Rectangle statarea;
+		statarea.x = g_value_get_int(gst_value_array_get_value(value, 0));
+		statarea.y = g_value_get_int(gst_value_array_get_value(value, 1));
+		statarea.width = g_value_get_int(gst_value_array_get_value(value, 2));
+		statarea.height = g_value_get_int(gst_value_array_get_value(value, 3));
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::StatisticArea, statarea);
+		break;
+	}
+	case PROP_CONTRAST_ENABLE:
+	{
+		bool enable = g_value_get_boolean(value);
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::ContrastLuminanceEnable,
+					    enable);
+		break;
+	}
+	case PROP_CONTRAST_VALUES:
+	{
+		int LUM[9];
+		for (unsigned int i = 0; i < 9; i++) {
+			LUM[i] = g_value_get_int(gst_value_array_get_value(value, i));
+		}
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::ContrastLuminance,
+					    { LUM[0], LUM[1], LUM[2], LUM[3], LUM[4], LUM[5], LUM[6], LUM[7], LUM[8] });
+		break;
+	}
+	case PROP_AEC_ALGO_ENABLE:
+	{
+		bool enable = g_value_get_boolean(value);
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::AeEnable,
+					    enable);
+		break;
+	}
+	case PROP_AEC_ALGO_EXPOSURE_COMPENSATION:
+	{
+		float aec_algo_exposure_compensation;
+		aec_algo_exposure_compensation = g_value_get_float(value);
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::ExposureValue, aec_algo_exposure_compensation);
+		break;
+	}
+	case PROP_SENSOR_GAIN:
+	{
+		float gain_dB;
+		gain_dB = g_value_get_float(value);
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::AnalogueGain_dB, gain_dB);
+		break;
+	}
+	case PROP_SENSOR_EXPOSURE:
+	{
+		int exposure_time;
+		exposure_time = g_value_get_int(value);
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::ExposureTime, exposure_time);
+		break;
+	}
+	case PROP_BADPIX_ENABLE:
+	{
+		bool enable = g_value_get_boolean(value);
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::BadPixelRemovalEnable, enable);
+		break;
+	}
+	case PROP_BADPIX_STRENGTH:
+	{
+		int strength;
+		strength = g_value_get_int(value);
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::BadPixelRemovalStrength, strength);
+		break;
+	}
+	case PROP_BADPIX_ALGO_THRESHOLD:
+	{
+		int threshold;
+		threshold = g_value_get_int(value);
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::BadPixelRemovalThreshold, threshold);
+		break;
+	}
+	case PROP_ISP_GAIN_ENABLE:
+	{
+		bool enable = g_value_get_boolean(value);
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::ColourGains3Enable, enable);
+		break;
+	}
+	case PROP_ISP_GAIN_VALUES:
+	{
+		int ISPGain[3];
+		for (unsigned int i = 0; i < 3; i++) {
+			ISPGain[i] = g_value_get_int(gst_value_array_get_value(value, i));
+		}
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::ColourGains3,
+					    { ISPGain[0], ISPGain[1], ISPGain[2] });
+		break;
+	}
+	case PROP_CCM_ENABLE:
+	{
+		bool enable = g_value_get_boolean(value);
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::ColourCorrectionEnable, enable);
+		break;
+	}
+	case PROP_CCM_VALUES:
+	{
+		int CCMCoeff[9];
+		for (unsigned int i = 0; i < 9; i++) {
+				CCMCoeff[i] = g_value_get_int(gst_value_array_get_value(value, i));
+		}
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::ColourCorrection,
+					    { CCMCoeff[0], CCMCoeff[1], CCMCoeff[2],
+						  CCMCoeff[3], CCMCoeff[4], CCMCoeff[5],
+						  CCMCoeff[6], CCMCoeff[7], CCMCoeff[8] });
+		break;
+	}
+	case PROP_AWB_ALGO_ENABLE:
+	{
+		bool enable = g_value_get_boolean(value);
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::AwbEnable, enable);
+		break;
+	}
+	case PROP_AWB_ALGO_PROFILE_NAMES:
+	{
+		/* The Controls class does not support array of string. So, concatenate the strings in a single one */
+		std::string concatProfileNames = "";
+		for (unsigned int i = 0; i < 5; i++) {
+			if (!concatProfileNames.empty())
+				concatProfileNames += '$';
+			concatProfileNames += g_value_get_string(gst_value_array_get_value(value, i));
+		}
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::AwbProfileName, concatProfileNames);
+		break;
+	}
+	case PROP_AWB_ALGO_PROFILE_COLOR_TEMPS:
+	{
+		std::array<int, 5>  ColorTemps;
+		for (unsigned int i = 0; i < ColorTemps.size(); i++) {
+				ColorTemps[i] = g_value_get_int(gst_value_array_get_value(value, i));
+		}
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::AwbReferenceColorTemperature, ColorTemps);
+		break;
+	}
+	case PROP_AWB_ALGO_PROFILE_ISP_GAINS:
+	{
+		std::array<int, 5 * 3>  IspGains;
+		for (unsigned int i = 0; i < IspGains.size(); i++) {
+				IspGains[i] = g_value_get_int(gst_value_array_get_value(value, i));
+		}
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::AwbColourGains3, IspGains);
+		break;
+	}
+	case PROP_AWB_ALGO_PROFILE_CCMS:
+	{
+		std::array<int, 5 * 3 * 3>  Ccms;
+		for (unsigned int i = 0; i < Ccms.size(); i++) {
+				Ccms[i] = g_value_get_int(gst_value_array_get_value(value, i));
+		}
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::AwbColourCorrection, Ccms);
+		break;
+	}
+	case PROP_DEMOSAICING_ENABLE:
+	{
+		bool enable = g_value_get_boolean(value);
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::DemosaicingEnable, enable);
+		break;
+	}
+	case PROP_DEMOSAICING_FILTERS:
+	{
+		std::array<int, 4>  Filters;
+		for (unsigned int i = 0; i < Filters.size(); i++) {
+				Filters[i] = g_value_get_int(gst_value_array_get_value(value, i));
+		}
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::DemosaicingFilter, Filters);
+		break;
+	}
+	case PROP_STATISTIC_PROFILE:
+	{
+		int StatProfile;
+		StatProfile = g_value_get_int(value);
+		GLibLocker locker(&state->controlsLock_);
+		state->pendingControls_.set(controls::draft::StatisticProfile, StatProfile);
+		break;
+	}
 	default:
 		G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);
 		break;
@@ -759,6 +1224,250 @@ gst_libcamera_src_get_property(GObject *object, guint prop_id, GValue *value,
 	case PROP_AUTO_FOCUS_MODE:
 		g_value_set_enum(value, static_cast<gint>(self->auto_focus_mode));
 		break;
+	case PROP_HW_REVISION:
+	{
+		GValue val = G_VALUE_INIT;
+		g_value_reset (value);
+		g_value_init (&val, G_TYPE_INT);
+		for (guint i = 0; i < 2; ++i) {
+			g_value_set_int(&val, self->ctrl.hwrevision[i]);
+			gst_value_array_append_value(value, &val);
+		}
+		g_value_unset (&val);
+		break;
+	}
+	case PROP_DECIMATION:
+		g_value_set_int(value, self->ctrl.decimation);
+		break;
+	case PROP_BLACK_LEVEL_ENABLE:
+		g_value_set_boolean(value, self->ctrl.black_level_enable);
+		break;
+	case PROP_BLACK_LEVEL_VALUES:
+	{
+		GValue val = G_VALUE_INIT;
+		g_value_reset (value);
+		g_value_init (&val, G_TYPE_INT);
+		for (guint i = 0; i < 3; ++i) {
+			g_value_set_int(&val, self->ctrl.black_level_values[i]);
+			gst_value_array_append_value(value, &val);
+		}
+		g_value_unset (&val);
+		break;
+	}
+	case PROP_STATISTIC_AREA:
+	{
+		GValue val = G_VALUE_INIT;
+		g_value_reset (value);
+		g_value_init (&val, G_TYPE_INT);
+		g_value_set_int(&val, self->ctrl.statistic_area.x);
+		gst_value_array_append_value(value, &val);
+		g_value_set_int(&val, self->ctrl.statistic_area.y);
+		gst_value_array_append_value(value, &val);
+		g_value_set_int(&val, self->ctrl.statistic_area.width);
+		gst_value_array_append_value(value, &val);
+		g_value_set_int(&val, self->ctrl.statistic_area.height);
+		gst_value_array_append_value(value, &val);
+		g_value_unset (&val);
+		break;
+	}
+	case PROP_CONTRAST_ENABLE:
+		g_value_set_boolean(value, self->ctrl.contrast_enable);
+		break;
+	case PROP_CONTRAST_VALUES:
+	{
+		GValue val = G_VALUE_INIT;
+		g_value_reset (value);
+		g_value_init (&val, G_TYPE_INT);
+		for (guint i = 0; i < 9; ++i) {
+			g_value_set_int(&val, self->ctrl.contrast_values[i]);
+			gst_value_array_append_value(value, &val);
+		}
+		g_value_unset (&val);
+		break;
+	}
+	case PROP_AEC_ALGO_ENABLE:
+		g_value_set_boolean(value, self->ctrl.aec_algo_enable);
+		break;
+	case PROP_AEC_ALGO_EXPOSURE_COMPENSATION:
+		g_value_set_float(value, self->ctrl.aec_algo_exposure_compensation);
+		break;
+	case PROP_AEC_ALGO_EXPOSURE_TARGET:
+		g_value_set_int(value, self->ctrl.aec_algo_exposure_target);
+		break;
+	case PROP_SENSOR_GAIN:
+		g_value_set_float(value, self->ctrl.sensor_gain_dB);
+		break;
+	case PROP_SENSOR_EXPOSURE:
+		g_value_set_int(value, self->ctrl.sensor_exposure);
+		break;
+	case PROP_BADPIX_ENABLE:
+		g_value_set_boolean(value, self->ctrl.badpix_enable);
+		break;
+	case PROP_BADPIX_STRENGTH:
+		g_value_set_int(value, self->ctrl.badpix_strength);
+		break;
+	case PROP_BADPIX_COUNT:
+		g_value_set_int(value, self->ctrl.badpix_count);
+		break;
+	case PROP_BADPIX_ALGO_THRESHOLD:
+		g_value_set_int(value, self->ctrl.badpix_algo_threshold);
+		break;
+	case PROP_ISP_GAIN_ENABLE:
+		g_value_set_boolean(value, self->ctrl.ispgain_enable);
+		break;
+	case PROP_ISP_GAIN_VALUES:
+	{
+		GValue val = G_VALUE_INIT;
+		g_value_reset (value);
+		g_value_init (&val, G_TYPE_INT);
+		for (guint i = 0; i < 3; ++i) {
+			g_value_set_int(&val, self->ctrl.ispgain_values[i]);
+			gst_value_array_append_value(value, &val);
+		}
+		g_value_unset (&val);
+		break;
+	}
+	case PROP_CCM_ENABLE:
+		g_value_set_boolean(value, self->ctrl.ccm_enable);
+		break;
+	case PROP_CCM_VALUES:
+	{
+		GValue val = G_VALUE_INIT;
+		g_value_reset (value);
+		g_value_init (&val, G_TYPE_INT);
+		for (guint i = 0; i < 9; ++i) {
+			g_value_set_int(&val, self->ctrl.ccm_values[i]);
+			gst_value_array_append_value(value, &val);
+		}
+		g_value_unset (&val);
+		break;
+	}
+	case PROP_AWB_ALGO_ENABLE:
+		g_value_set_boolean(value, self->ctrl.awb_algo_enable);
+		break;
+	case PROP_AWB_ALGO_PROFILE_NAMES:
+	{
+		GValue val = G_VALUE_INIT;
+		g_value_reset (value);
+		g_value_init (&val, G_TYPE_STRING);
+		for (guint i = 0; i < self->ctrl.awb_algo_profile_names.size(); ++i) {
+			if (self->ctrl.awb_algo_profile_names[i].empty())
+				g_value_set_string(&val, "");
+			else
+				g_value_set_string(&val, self->ctrl.awb_algo_profile_names[i].c_str());
+			gst_value_array_append_value(value, &val);
+		}
+		g_value_unset (&val);
+		break;
+	}
+	case PROP_AWB_ALGO_PROFILE_COLOR_TEMPS:
+	{
+		GValue val = G_VALUE_INIT;
+		g_value_reset (value);
+		g_value_init (&val, G_TYPE_INT);
+		for (guint i = 0; i < self->ctrl.awb_algo_profile_color_temps.size(); ++i) {
+			g_value_set_int(&val, self->ctrl.awb_algo_profile_color_temps[i]);
+			gst_value_array_append_value(value, &val);
+		}
+		g_value_unset (&val);
+		break;
+	}
+	case PROP_AWB_ALGO_PROFILE_ISP_GAINS:
+	{
+		GValue val = G_VALUE_INIT;
+		g_value_reset (value);
+		g_value_init (&val, G_TYPE_INT);
+		for (guint i = 0; i < self->ctrl.awb_algo_profile_isp_gains.size(); ++i) {
+			g_value_set_int(&val, self->ctrl.awb_algo_profile_isp_gains[i]);
+			gst_value_array_append_value(value, &val);
+		}
+		g_value_unset (&val);
+		break;
+	}
+	case PROP_AWB_ALGO_PROFILE_CCMS:
+	{
+		GValue val = G_VALUE_INIT;
+		g_value_reset (value);
+		g_value_init (&val, G_TYPE_INT);
+		for (guint i = 0; i < self->ctrl.awb_algo_profile_ccms.size(); ++i) {
+			g_value_set_int(&val, self->ctrl.awb_algo_profile_ccms[i]);
+			gst_value_array_append_value(value, &val);
+		}
+		g_value_unset (&val);
+		break;
+	}
+	case PROP_AWB_CURRENT_PROFILE_NAME:
+		g_value_set_string(value, self->ctrl.awb_current_profile_name.c_str());
+		break;
+	case PROP_AWB_CURRENT_PROFILE_COLOR_TEMP:
+		g_value_set_int(value, self->ctrl.awb_current_profile_color_temp);
+		break;
+	case PROP_DEMOSAICING_ENABLE:
+		g_value_set_boolean(value, self->ctrl.demosaicing_enable);
+		break;
+	case PROP_DEMOSAICING_FILTERS:
+	{
+		GValue val = G_VALUE_INIT;
+		g_value_reset (value);
+		g_value_init (&val, G_TYPE_INT);
+		for (guint i = 0; i < self->ctrl.demosaicing_filters.size(); ++i) {
+			g_value_set_int(&val, self->ctrl.demosaicing_filters[i]);
+			gst_value_array_append_value(value, &val);
+		}
+		g_value_unset (&val);
+		break;
+	}
+	case PROP_STATISTIC_PROFILE:
+		g_value_set_int(value, self->ctrl.statistic_profile);
+		break;
+	case PROP_STATISTIC_GET_AVERAGE_UP:
+	{
+		GValue val = G_VALUE_INIT;
+		g_value_reset (value);
+		g_value_init (&val, G_TYPE_INT);
+		for (guint i = 0; i < self->ctrl.statistic_avg_up.size(); ++i) {
+			g_value_set_int(&val, self->ctrl.statistic_avg_up[i]);
+			gst_value_array_append_value(value, &val);
+		}
+		g_value_unset (&val);
+		break;
+	}
+	case PROP_STATISTIC_GET_AVERAGE_DOWN:
+	{
+		GValue val = G_VALUE_INIT;
+		g_value_reset (value);
+		g_value_init (&val, G_TYPE_INT);
+		for (guint i = 0; i < self->ctrl.statistic_avg_down.size(); ++i) {
+			g_value_set_int(&val, self->ctrl.statistic_avg_down[i]);
+			gst_value_array_append_value(value, &val);
+		}
+		g_value_unset (&val);
+		break;
+	}
+	case PROP_STATISTIC_GET_HISTOGRAM_UP:
+	{
+		GValue val = G_VALUE_INIT;
+		g_value_reset (value);
+		g_value_init (&val, G_TYPE_INT);
+		for (guint i = 0; i < self->ctrl.statistic_hist_up.size(); ++i) {
+			g_value_set_int(&val, self->ctrl.statistic_hist_up[i]);
+			gst_value_array_append_value(value, &val);
+		}
+		g_value_unset (&val);
+		break;
+	}
+	case PROP_STATISTIC_GET_HISTOGRAM_DOWN:
+	{
+		GValue val = G_VALUE_INIT;
+		g_value_reset (value);
+		g_value_init (&val, G_TYPE_INT);
+		for (guint i = 0; i < self->ctrl.statistic_hist_down.size(); ++i) {
+			g_value_set_int(&val, self->ctrl.statistic_hist_down[i]);
+			gst_value_array_append_value(value, &val);
+		}
+		g_value_unset (&val);
+		break;
+	}
 	default:
 		G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);
 		break;
@@ -844,6 +1553,7 @@ gst_libcamera_src_finalize(GObject *object)
 	g_rec_mutex_clear(&self->stream_lock);
 	g_clear_object(&self->task);
 	g_mutex_clear(&self->state->lock_);
+	g_mutex_clear(&self->state->controlsLock_);
 	g_free(self->camera_name);
 	delete self->state;
 
@@ -863,9 +1573,12 @@ gst_libcamera_src_init(GstLibcameraSrc *self)
 	gst_task_set_lock(self->task, &self->stream_lock);
 
 	g_mutex_init(&state->lock_);
+	g_mutex_init(&state->controlsLock_);
 
-	state->srcpads_.push_back(gst_pad_new_from_template(templ, "src"));
-	gst_element_add_pad(GST_ELEMENT(self), state->srcpads_.back());
+	GstPad *pad = gst_pad_new_from_template(templ, "src");
+	state->srcpads_.push_back(pad);
+	gst_element_add_pad(GST_ELEMENT(self), pad);
+	gst_child_proxy_child_added(GST_CHILD_PROXY(self), G_OBJECT(pad), GST_OBJECT_NAME(pad));
 
 	GST_OBJECT_FLAG_SET(self, GST_ELEMENT_FLAG_SOURCE);
 
@@ -896,6 +1609,8 @@ gst_libcamera_src_request_new_pad(GstElement *element, GstPadTemplate *templ,
 		return NULL;
 	}
 
+	gst_child_proxy_child_added(GST_CHILD_PROXY(self), G_OBJECT(pad), GST_OBJECT_NAME(pad));
+
 	return reinterpret_cast<GstPad *>(g_steal_pointer(&pad));
 }
 
@@ -904,6 +1619,8 @@ gst_libcamera_src_release_pad(GstElement *element, GstPad *pad)
 {
 	GstLibcameraSrc *self = GST_LIBCAMERA_SRC(element);
 
+	gst_child_proxy_child_removed(GST_CHILD_PROXY(self), G_OBJECT(pad), GST_OBJECT_NAME(pad));
+
 	GST_DEBUG_OBJECT(self, "Pad %" GST_PTR_FORMAT " being released", pad);
 
 	{
@@ -963,4 +1680,303 @@ gst_libcamera_src_class_init(GstLibcameraSrcClass *klass)
 				 static_cast<gint>(controls::AfModeManual),
 				 G_PARAM_WRITABLE);
 	g_object_class_install_property(object_class, PROP_AUTO_FOCUS_MODE, spec);
+
+	/* Add ISP properties */
+	/* HW Revision values read property */
+	spec = gst_param_spec_array("hw-revision",
+					"Hardware revsion ID",
+				    "ISP Hardware revsion ID ('Major, Minor')",
+				    g_param_spec_int ("hw-revision-value", "ISP Hardware revsion ID",
+						      "One of  Major, Minor value.", 0, 255, 0,
+						      G_PARAM_READABLE),
+					G_PARAM_READABLE);
+	g_object_class_install_property(object_class, PROP_HW_REVISION, spec);
+	/* Decimation values read property */
+	spec = g_param_spec_int("decimation-factor",
+					"Decimation factor",
+				    "ISP Decimation factor ('1, 2, 4 or 8')",
+					1, 8, 1,
+					G_PARAM_READABLE);
+	g_object_class_install_property(object_class, PROP_DECIMATION, spec);
+	/* Black level enable property */
+	spec = g_param_spec_boolean("black-level-enable",
+				    "Black level enable",
+				    "ISP Black Level correction bloc activation",
+				    false,
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_BLACK_LEVEL_ENABLE, spec);
+	/* Black level values property */
+	spec = gst_param_spec_array("black-level-values",
+				    "Black level RGB values",
+				    "ISP Black Level correction values ('<R, G, B>')",
+				    g_param_spec_int ("black-level-value", "Black level value",
+						      "One of R, G, B value.", 0, 255, 0,
+						      G_PARAM_READWRITE),
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_BLACK_LEVEL_VALUES, spec);
+	/* Satistic area property */
+	spec = gst_param_spec_array("statistic-area",
+				    "Statistic Area",
+				    "ISP Statistic Area ('<X0, Y0, XSize, YSize>')",
+				    g_param_spec_int ("statarea-value", "Satistic Area value",
+						      "One of X0, Y0, XSize, YSize", 0, 4096, 0,
+						      G_PARAM_READWRITE),
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_STATISTIC_AREA, spec);
+	/* Contrast enable property */
+	spec = g_param_spec_boolean("contrast-enable",
+				    "Contrast enable",
+				    "ISP Contrast bloc activation",
+				    false,
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_CONTRAST_ENABLE, spec);
+	/* Contrast values property */
+	spec = gst_param_spec_array("contrast-values",
+				    "Contrast multiplication factor values",
+				    "ISP Contrast multiplication factor values ('<LUM_0, LUM_32, LUM_64, LUM_96, LUM_128, LUM_160, LUM_192, LUM_224, LUM_256>')",
+				    g_param_spec_int ("contrast-value", "Contrast value",
+						      "One of LUM_0, LUM_32, LUM_64, LUM_96, LUM_128, LUM_160, LUM_192, LUM_224, LUM_256 value.", 0, 394, 0,
+						      G_PARAM_READWRITE),
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_CONTRAST_VALUES, spec);
+	/* AEC algo enable property */
+	spec = g_param_spec_boolean("aec-algo-enable",
+				    "AEC algo enable",
+				    "Activation of the AEC algorithm",
+				    false,
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_AEC_ALGO_ENABLE, spec);
+	/* AEC algo exposure compensation */
+	spec = g_param_spec_float("aec-algo-exposure-compensation",
+				  "AEC exposure compensation",
+				  "AEC exposure compensation when algo is enabled ('-2EV, -1.5EV, -1EV, -0.5EV, 0EV, +0.5EV, +1EV, +1.5EV, +2EV')",
+				  -2, 2, 0,
+				  G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_AEC_ALGO_EXPOSURE_COMPENSATION, spec);
+	/* AEC algo exposure target */
+	spec = g_param_spec_int("aec-algo-exposure-target",
+					"AEC exposure target",
+				    "AEC exposure target that depends on exposure compensation set",
+					0, 255, 56,
+					G_PARAM_READABLE);
+	g_object_class_install_property(object_class, PROP_AEC_ALGO_EXPOSURE_TARGET, spec);
+	/* Sensor gain property */
+	spec = g_param_spec_float("sensor-gain",
+				    "Sensor analog gain",
+				    "Gain of the sensor in dB",
+				    0, 100, 0,
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_SENSOR_GAIN, spec);
+	/* Sensor exposure time property */
+	spec = g_param_spec_int("sensor-exposure",
+				    "Sensor exposure time",
+				    "Sensor exposure time in us",
+				    0, 100000, 0,
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_SENSOR_EXPOSURE, spec);
+	/* Bad pixel removal enable property */
+	spec = g_param_spec_boolean("badpixel-enable",
+				    "Bad pixel removal enable",
+				    "Activation of the bad pixel removel block",
+				    false,
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_BADPIX_ENABLE, spec);
+	/* Bad pixel removal strength property */
+	spec = g_param_spec_int("badpixel-strength",
+				    "Bad pixel removal strength",
+				    "Bad pixel removal filter strength",
+				    0, 7, 0,
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_BADPIX_STRENGTH, spec);
+	/* Bad pixel removal count property */
+	spec = g_param_spec_int("badpixel-count",
+				    "Bad pixel removal count",
+				    "Count of the number of bad pixel detected",
+				    0, 4095, 0,
+				    G_PARAM_READABLE);
+	g_object_class_install_property(object_class, PROP_BADPIX_COUNT, spec);
+	/* Bad pixel removal algo threshold */
+	spec = g_param_spec_int("badpixel-algo-threshold",
+				    "Bad pixel removal algorithm threshold",
+				    "Threshold defining the maximum number of bad pixel expected to be detected",
+				    0, 4095, 0,
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_BADPIX_ALGO_THRESHOLD, spec);
+	/* ISP gain enable property */
+	spec = g_param_spec_boolean("isp-gain-enable",
+				    "ISP gain enable",
+				    "ISP gain bloc activation",
+				    false,
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_ISP_GAIN_ENABLE, spec);
+	/* ISP gain values property */
+	spec = gst_param_spec_array("isp-gain-values",
+				    "ISP gain values",
+				    "ISP gain multiplication factor values ('<ISPGainR, ISPGainG, ISPGainB>')",
+				    g_param_spec_int ("isp-gain-value", "ISP gain value",
+						      "One of ISPGainR, ISPGainG, ISPGainB value.", 0, 1600000000, 100000000,
+						      G_PARAM_READWRITE),
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_ISP_GAIN_VALUES, spec);
+	/* CCM enable property */
+	spec = g_param_spec_boolean("ccm-enable",
+				    "Color correction matrix enable",
+				    "ISP color correction matrix bloc activation",
+				    false,
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_CCM_ENABLE, spec);
+	/* CCM values property */
+	spec = gst_param_spec_array("ccm-values",
+				    "Color correction matrix values",
+				    "ISP color correction matrix values ('<CCMCoeff11, CCMCoeff12, CCMCoeff13, CCMCoeff21, CCMCoeff22, CCMCoeff23, CCMCoeff31, CCMCoeff32, CCMCoeff33>')",
+				    g_param_spec_int ("ccm-value", "CCM value",
+						      "One of CCMCoeff11, CCMCoeff12, CCMCoeff13, CCMCoeff21, CCMCoeff22, CCMCoeff23, CCMCoeff31, CCMCoeff32, CCMCoeff33 value.", -399000000, 399000000, 0,
+						      G_PARAM_READWRITE),
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_CCM_VALUES, spec);
+	/* AWB algo enable property */
+	spec = g_param_spec_boolean("awb-algo-enable",
+				    "AWB algo enable",
+				    "Activation of the AWB algorithm",
+				    false,
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_AWB_ALGO_ENABLE, spec);
+	/* AWB algo profileID values property */
+	spec = gst_param_spec_array("awb-algo-profile-names",
+				    "AWB algo profile names",
+				    "Array of AWB profile name (one entry per profile) used by the AWB algorithm ('<Name0, Name1, Name2, Name3, Name4>')",
+				    g_param_spec_string ("awb-algo-profile-name", "AWB profile name strings of 32bytes maximum",
+						      "One of Name0, Name1, Name2, Name3, Name4", NULL,
+						      G_PARAM_READWRITE),
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_AWB_ALGO_PROFILE_NAMES, spec);
+	/* AWB algo color temperature values property */
+	spec = gst_param_spec_array("awb-algo-profile-color-temps",
+				    "AWB algo color temperatures",
+				    "Array of reference color tempeartures (one entry per profile) used by the AWB algorithm ('<ColorTemp0, ColorTemp1, ColorTemp2, ColorTemp3, ColorTemp4>')",
+				    g_param_spec_int ("awb-algo-profile-color-temp", "AWB profile color temperature value",
+						      "One of ColorTemp0, ColorTemp1, ColorTemp2, ColorTemp3, ColorTemp4 value.", 0, 12000, 0,
+						      G_PARAM_READWRITE),
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_AWB_ALGO_PROFILE_COLOR_TEMPS, spec);
+	/* AWB algo ISP gain values property */
+	spec = gst_param_spec_array("awb-algo-profile-isp-gains",
+				    "AWB algo ISP gains",
+				    "Array of ISP gains (one entry per profile) used by the AWB algorithm ('<ISPGain0R, ISPGain0G, ISPGain0B, ..., ISPGain4R, ISPGain4G, ISPGain4B>')",
+				    g_param_spec_int ("awb-algo-profile-isp-gain", "AWB profile ISP Gain value",
+						      "One of ISPGain0R, ISPGain0G, ISPGain0B, ..., ISPGain4R, ISPGain4G, ISPGain4B value.", 0, 1600000000, 100000000,
+						      G_PARAM_READWRITE),
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_AWB_ALGO_PROFILE_ISP_GAINS, spec);
+	/* AWB algo color correction matrix values property */
+	spec = gst_param_spec_array("awb-algo-profile-ccms",
+				    "AWB algo color correction matrix values",
+				    "Array of color convertion matrices (one entry per profile) used by the AWB algorithm  ('<CCM0Coeff11, CCM0Coeff12, ... , CCM0Coeff32, CCM0Coeff33, ... , CCM4Coeff11, CCM4Coeff12, ... , CCM4Coeff32, CCM4Coeff33>')",
+				    g_param_spec_int ("awb-algo-profile-ccm", "AWB profile CCM value",
+						      "One of CCM0Coeff11, CCM0Coeff12, ... , CCM0Coeff32, CCM0Coeff33, ... , CCM4Coeff11, CCM4Coeff12, ... , CCM4Coeff32, CCM4Coeff33 value.", -399000000, 399000000, 0,
+						      G_PARAM_READWRITE),
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_AWB_ALGO_PROFILE_CCMS, spec);
+	/* AWB current profile name */
+	spec = g_param_spec_string("awb-current-profile-name",
+					"AWB current profile name",
+					"Name of the current profile applied by the AWB (string of 32bytes maximum)", NULL,
+				    G_PARAM_READABLE);
+	g_object_class_install_property(object_class, PROP_AWB_CURRENT_PROFILE_NAME, spec);
+	/* AWB current profile name */
+	spec = g_param_spec_int ("awb-current-profile-color-temp",
+					"AWB current color temperature",
+					"Color temperature of the current profile applied by the AWB",
+					0, 12000, 0,
+					G_PARAM_READABLE),
+	g_object_class_install_property(object_class, PROP_AWB_CURRENT_PROFILE_COLOR_TEMP, spec);
+	/* Demosaicing enable property */
+	spec = g_param_spec_boolean("demosaicing-enable",
+				    "Demosaicing enable",
+				    "ISP demosaicing bloc activation",
+				    false,
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_DEMOSAICING_ENABLE, spec);
+	/* Demosaicing filter values property */
+	spec = gst_param_spec_array("demosaicing-filters",
+				    "Demosaicing filter values",
+				    "ISP demosaicing filter values ('<Peak, LineV, LineH, Edge>')",
+				    g_param_spec_int ("demosaicing-filter", "Demosaicing filter value",
+						      "One of Peak, LineV, LineH, Edge value.", 0, 7, 0,
+						      G_PARAM_READWRITE),
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_DEMOSAICING_FILTERS, spec);
+	/* Statistic profile property */
+	spec = g_param_spec_int("statistic-profile",
+				    "Statistic profile",
+				    "ISP statistic extraction profile ('<0 = Full stats (histogram and average, up and down), 1 = average up stats, 2 = average down stats>')",
+				    0, 2, 0,
+				    G_PARAM_READWRITE);
+	g_object_class_install_property(object_class, PROP_STATISTIC_PROFILE, spec);
+	/* Statistic up average property */
+	spec = gst_param_spec_array("statistic-get-average-up",
+				    "Get statistic average at up level",
+				    "Up ISP average statistic results values ('<R, G, B, L>')",
+				    g_param_spec_int ("statistic-average-up", "Average statistic results value",
+						      "One of R, G, B, L average statistic value", 0, 255, 0,
+						      G_PARAM_READABLE),
+				    G_PARAM_READABLE);
+	g_object_class_install_property(object_class, PROP_STATISTIC_GET_AVERAGE_UP, spec);
+	/* Statistic down average property */
+	spec = gst_param_spec_array("statistic-get-average-down",
+				    "Get statistic average at down level",
+				    "Down ISP average statistic results values ('<R, G, B, L>')",
+				    g_param_spec_int ("statistic-average-down", "Average statistic results value",
+						      "One of R, G, B, L average statistic value", 0, 255, 0,
+						      G_PARAM_READABLE),
+				    G_PARAM_READABLE);
+	g_object_class_install_property(object_class, PROP_STATISTIC_GET_AVERAGE_DOWN, spec);
+	/* Statistic up histogram property */
+	spec = gst_param_spec_array("statistic-get-histogram-up",
+				    "Get statistic histogram at up level",
+				    "Up ISP histogram statistic results values ('<bin0, ... , bin11>')",
+				    g_param_spec_int ("statistic-histogram-up", "Histogram statistic results value",
+						      "One of bin0, ... , bin11 statistic value", 0, 16777215, 0,
+						      G_PARAM_READABLE),
+				    G_PARAM_READABLE);
+	g_object_class_install_property(object_class, PROP_STATISTIC_GET_HISTOGRAM_UP, spec);
+	/* Statistic down histogram property */
+	spec = gst_param_spec_array("statistic-get-histogram-down",
+				    "Get statistic histogram at down level",
+				    "Down ISP histogram statistic results values ('<bin0, ... , bin11>')",
+				    g_param_spec_int ("statistic-histogram-down", "Histogram statistic results value",
+						      "One of bin0, ... , bin11 statistic value", 0, 16777215, 0,
+						      G_PARAM_READABLE),
+				    G_PARAM_READABLE);
+	g_object_class_install_property(object_class, PROP_STATISTIC_GET_HISTOGRAM_DOWN, spec);
+}
+
+/* GstChildProxy implementation */
+static GObject *
+gst_libcamera_src_child_proxy_get_child_by_index(GstChildProxy * child_proxy,
+						 guint index)
+{
+	GLibLocker lock(GST_OBJECT(child_proxy));
+	GObject *obj = nullptr;
+
+	obj = reinterpret_cast<GObject*>(g_list_nth_data(GST_ELEMENT(child_proxy)->srcpads, index));
+	if (obj)
+		gst_object_ref(obj);
+
+	return obj;
+}
+
+static guint
+gst_libcamera_src_child_proxy_get_children_count(GstChildProxy * child_proxy)
+{
+	GLibLocker lock(GST_OBJECT(child_proxy));
+	return GST_ELEMENT_CAST(child_proxy)->numsrcpads;
+}
+
+static void
+gst_libcamera_src_child_proxy_init(gpointer g_iface, [[maybe_unused]] gpointer iface_data)
+{
+  GstChildProxyInterface *iface = reinterpret_cast<GstChildProxyInterface *>(g_iface);
+  iface->get_child_by_index = gst_libcamera_src_child_proxy_get_child_by_index;
+  iface->get_children_count = gst_libcamera_src_child_proxy_get_children_count;
 }
diff --git a/src/gstreamer/meson.build b/src/gstreamer/meson.build
index 20784b71..c2a01e7b 100644
--- a/src/gstreamer/meson.build
+++ b/src/gstreamer/meson.build
@@ -46,3 +46,15 @@ libcamera_gst = shared_library('gstlibcamera',
     install : true,
     install_dir : '@0@/gstreamer-1.0'.format(get_option('libdir')),
 )
+
+# Make the plugin visible to GStreamer inside meson devenv.
+fs = import('fs')
+gst_plugin_path = fs.parent(libcamera_gst.full_path())
+
+gst_env = environment()
+gst_env.prepend('GST_PLUGIN_PATH', gst_plugin_path)
+
+# Avoid polluting the system registry.
+gst_env.set('GST_REGISTRY', gst_plugin_path / 'registry.data')
+
+meson.add_devenv(gst_env)
diff --git a/src/ipa/dcmipp/algorithms/aec.cpp b/src/ipa/dcmipp/algorithms/aec.cpp
new file mode 100644
index 00000000..16d358c9
--- /dev/null
+++ b/src/ipa/dcmipp/algorithms/aec.cpp
@@ -0,0 +1,511 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024 ST Microelectronics
+ * Copyright (C) 2024 LACROIX - Impulse
+ *
+ * aec.cpp - STM32 DCMIPP AE control
+ */
+
+#include "aec.h"
+
+#include <math.h>
+
+#include <libcamera/base/log.h>
+
+#include <libcamera/control_ids.h>
+
+#ifdef EVISION_ALGO_ENABLED
+#include <dlfcn.h>
+#include <iostream>
+#include "evision-api-st-ae.h"
+#endif /* EVISION_ALGO_ENABLED */
+
+namespace libcamera {
+
+namespace ipa::dcmipp::algorithms {
+
+LOG_DEFINE_CATEGORY(DcmippAec)
+
+static constexpr uint8_t kAlgoIdealExposureTarget = 56;
+static constexpr float kEVMin = -2.0f;
+static constexpr float kEVMax = 2.0f;
+static constexpr float kEVDef = 0.0f;
+
+#ifdef EVISION_ALGO_ENABLED
+static constexpr uint32_t kmdB = 1000;
+
+static void *plib_handle = nullptr;
+static evision_st_ae_process_t *pIspAEprocess = nullptr;
+
+typedef evision_st_ae_process_t *(*evision_api_st_ae_new_t)(evision_api_log_callback log_cb);
+typedef evision_return_t (*evision_api_st_ae_delete_t)(evision_st_ae_process_t *self);
+typedef evision_return_t (*evision_api_st_ae_init_t)(evision_st_ae_process_t *const self);
+typedef evision_return_t (*evision_api_st_ae_process_t)(evision_st_ae_process_t *const self, uint32_t current_gain, uint32_t current_exposure, uint8_t average_lum);
+
+static evision_api_st_ae_new_t evision_api_st_ae_new = nullptr;
+static evision_api_st_ae_init_t evision_api_st_ae_init = nullptr;
+static evision_api_st_ae_delete_t evision_api_st_ae_delete = nullptr;
+static evision_api_st_ae_process_t evision_api_st_ae_process = nullptr;
+#endif /* EVISION_ALGO_ENABLED */
+
+static bool process_simple_algo = true;
+
+static bool isExposureValueValid(float exposureValue)
+{
+	return exposureValue >= kEVMin && exposureValue <= kEVMax;
+}
+
+static bool isExposureTimeValid(int32_t exposureTime, IPAContext &context)
+{
+	return exposureTime >= context.info.sensorExposureMin && exposureTime <= context.info.sensorExposureMax;
+}
+
+static bool isGainValid(double gain, IPAContext &context)
+{
+	return gain >= context.info.sensorGainMin && gain <= context.info.sensorGainMax;
+}
+
+#ifdef EVISION_ALGO_ENABLED
+static bool initializeLibrary()
+{
+	const char *lib_dir = "/usr/lib/";
+	const char *lib_name = "libevision-st-ae.so.1";
+	std::string lib_path = std::string(lib_dir) + lib_name;
+
+	plib_handle = dlopen(lib_path.c_str(), RTLD_LAZY);
+	if (!plib_handle) {
+		LOG(DcmippAec, Warning) << "Cannot open library: " << dlerror();
+		LOG(DcmippAec, Warning) << "Fall back to simple AEC algorithm processing";
+		return true;
+	}
+
+	dlerror(); // Clear any existing error
+
+	process_simple_algo = false;
+	evision_api_st_ae_new = (evision_api_st_ae_new_t)dlsym(plib_handle, "evision_api_st_ae_new");
+	const char *dlsym_error = dlerror();
+	if (dlsym_error) {
+		LOG(DcmippAec, Error) << "Cannot load symbol 'evision_api_st_ae_new': " << dlsym_error;
+		dlclose(plib_handle);
+		return false;
+	}
+
+	evision_api_st_ae_init = (evision_api_st_ae_init_t)dlsym(plib_handle, "evision_api_st_ae_init");
+	dlsym_error = dlerror();
+	if (dlsym_error) {
+		LOG(DcmippAec, Error) << "Cannot load symbol 'evision_api_st_ae_init': " << dlsym_error;
+		dlclose(plib_handle);
+		return false;
+	}
+
+	evision_api_st_ae_delete = (evision_api_st_ae_delete_t)dlsym(plib_handle, "evision_api_st_ae_delete");
+	dlsym_error = dlerror();
+	if (dlsym_error) {
+		LOG(DcmippAec, Error) << "Cannot load symbol 'evision_api_st_ae_delete': " << dlsym_error;
+		dlclose(plib_handle);
+		return false;
+	}
+
+	evision_api_st_ae_process = (evision_api_st_ae_process_t)dlsym(plib_handle, "evision_api_st_ae_process");
+	dlsym_error = dlerror();
+	if (dlsym_error) {
+		LOG(DcmippAec, Error) << "Cannot load symbol 'evision_api_st_ae_process': " << dlsym_error;
+		dlclose(plib_handle);
+		return false;
+	}
+
+	return true;
+}
+
+static void log_cb(const char *const msg)
+{
+	LOG(DcmippAec, Debug) << msg;
+}
+
+static bool initializeAeInstance()
+{
+	if (!plib_handle) {
+		LOG(DcmippAec, Error) << "Library not loaded";
+		return false;
+	}
+
+	pIspAEprocess = evision_api_st_ae_new(log_cb);
+	if (pIspAEprocess == nullptr) {
+		LOG(DcmippAec, Error) << "Failed to create pIspAEprocess";
+		return false;
+	}
+
+	evision_return_t init_result = evision_api_st_ae_init(pIspAEprocess);
+	if (init_result != EVISION_RET_SUCCESS) {
+		LOG(DcmippAec, Error) << "Failed to initialize pIspAEprocess";
+		evision_api_st_ae_delete(pIspAEprocess);
+		pIspAEprocess = nullptr;
+		return false;
+	}
+
+	return true;
+}
+
+static void deinitializeAeInstance()
+{
+	if (pIspAEprocess) {
+		evision_api_st_ae_delete(pIspAEprocess);
+		pIspAEprocess = nullptr;
+	}
+}
+
+static void deinitializeLibrary()
+{
+	if (plib_handle) {
+		dlclose(plib_handle);
+		plib_handle = nullptr;
+	}
+}
+
+evision_return_t processAeInstance(double *gain, int32_t *exposure, uint32_t average_lum)
+{
+	if (!pIspAEprocess) {
+		LOG(DcmippAec, Error) << "AE instance not initialized";
+		return EVISION_RET_PARAM_ERR;
+	}
+
+	if (!gain || !exposure) {
+		LOG(DcmippAec, Error) << "Null pointer passed for gain or exposure";
+		return EVISION_RET_PARAM_ERR;
+	}
+
+	evision_return_t e_ret = evision_api_st_ae_process(pIspAEprocess, static_cast<uint32_t>(*gain * kmdB), static_cast<uint32_t>(*exposure), static_cast<uint8_t>(average_lum));
+	if (e_ret != EVISION_RET_SUCCESS) {
+		LOG(DcmippAec, Error) << "AE process failed";
+		return EVISION_RET_FAILURE;
+	}
+
+	*gain = static_cast<double>(pIspAEprocess->new_gain) / kmdB;
+	*exposure = static_cast<int32_t>(pIspAEprocess->new_exposure);
+
+	return EVISION_RET_SUCCESS;
+}
+#endif /* EVISION_ALGO_ENABLED */
+
+int Aec::init([[maybe_unused]] IPAContext &context, const YamlObject &tuningData)
+{
+	/* Check for AEC algo config  */
+	params_.algoEnable = tuningData["AeEnable"].get<bool>(0);
+	params_.algoExposureValue = tuningData["ExposureValue"].get<double>(kEVDef);
+	if (!isExposureValueValid(params_.algoExposureValue)) {
+		LOG(DcmippAec, Error) << "Invalid Exposure value: " << params_.algoExposureValue;
+		return -EINVAL;
+	}
+
+	params_.algoTarget = kAlgoIdealExposureTarget * pow(2, params_.algoExposureValue);
+
+	/* Check for sensor static config (exposure time in microseconds, gain in dB) */
+	params_.sensorStatic.exposure = tuningData["ExposureTime"].get<int32_t>(10000);
+	if (!isExposureTimeValid(params_.sensorStatic.exposure, context)) {
+		LOG(DcmippAec, Error) << "Invalid Exposure time: " << params_.sensorStatic.exposure;
+		return -EINVAL;
+	}
+	params_.sensorStatic.gain = tuningData["AnalogueGain_dB"].get<double>(1);
+	if (!isGainValid(params_.sensorStatic.gain, context)) {
+		LOG(DcmippAec, Error) << "Invalid Gain: " << params_.sensorStatic.gain;
+		return -EINVAL;
+	}
+
+#ifdef EVISION_ALGO_ENABLED
+	/* Iniitialize the ST AE algorithm library */
+	if (params_.algoEnable) {
+		if (!initializeLibrary()) {
+			return 1;
+		}
+
+		if (!process_simple_algo) {
+			if (!initializeAeInstance()) {
+				deinitializeLibrary();
+				return 1;
+			}
+
+			/* Configure algo (AEC target) */
+			pIspAEprocess->hyper_params.target = (int32_t)params_.algoTarget;
+
+			/* Configure algo (sensor config) */
+			pIspAEprocess->hyper_params.exposure_min = context.info.sensorExposureMin;
+			pIspAEprocess->hyper_params.exposure_max = context.info.sensorExposureMax;
+			pIspAEprocess->hyper_params.gain_min = (uint32_t)(context.info.sensorGainMin * kmdB);
+			pIspAEprocess->hyper_params.gain_max = (uint32_t)(context.info.sensorGainMax * kmdB);
+		}
+	} else {
+		if (!process_simple_algo) {
+			deinitializeAeInstance();
+			deinitializeLibrary();
+		}
+	}
+#endif /* EVISION_ALGO_ENABLED */
+
+	/* Configure exposed controls */
+	context.dcmippControls[&controls::AeEnable] = ControlInfo(false, true);
+	context.dcmippControls[&controls::ExposureValue] = ControlInfo(kEVMin, kEVMax, kEVDef);
+	context.dcmippControls[&controls::ExposureTime] = ControlInfo(context.info.sensorExposureMin,
+								      context.info.sensorExposureMax,
+								      context.info.sensorExposureDef);
+	context.dcmippControls[&controls::draft::AnalogueGain_dB] = ControlInfo((float)context.info.sensorGainMin,
+										(float)context.info.sensorGainMax,
+										(float)context.info.sensorGainDef);
+	return 0;
+}
+
+int Aec::configure(IPAContext &context,
+		   [[maybe_unused]] const IPACameraSensorInfo &configInfo)
+{
+	/* Set the initial ISP/sensor values in the pending config */
+	if (params_.algoEnable) {
+		/* Start with gain and exposure = min */
+		config_.sensor.gain = context.info.sensorGainMin;
+		config_.sensor.exposure = context.info.sensorExposureMin;
+	} else {
+		/* Static config */
+		config_.sensor = params_.sensorStatic;
+	}
+
+	/* Update context immediately, so IPA can apply the sensor settings at start up */
+	context.sensor = config_.sensor;
+	config_.pending = true;
+
+	/* Update sensor exposed controls */
+	context.dcmippControls.emplace(std::piecewise_construct,
+				       std::forward_as_tuple(&controls::ExposureTime),
+				       std::forward_as_tuple(context.info.sensorExposureMin,
+							     context.info.sensorExposureMax,
+							     context.info.sensorExposureDef));
+	context.dcmippControls.emplace(std::piecewise_construct,
+				       std::forward_as_tuple(&controls::draft::AnalogueGain_dB),
+				       std::forward_as_tuple((float)context.info.sensorGainMin,
+							     (float)context.info.sensorGainMax,
+							     (float)context.info.sensorGainDef));
+	return 0;
+}
+
+void Aec::queueRequest([[maybe_unused]] IPAContext &context,
+		       [[maybe_unused]] const uint32_t frame,
+		       [[maybe_unused]] IPAFrameContext &frameContext,
+		       const ControlList &controls)
+{
+	/* Algo ctrl: only update params_ which will be considered upon the next process() call */
+	const auto &algoEnable = controls.get(controls::AeEnable);
+	const auto &algoExposureValue = controls.get(controls::ExposureValue);
+
+	if (algoEnable) {
+		params_.algoEnable = *algoEnable;
+		LOG(DcmippAec, Debug) << "Updating AeEnable to " << *algoEnable;
+	}
+
+	if (algoExposureValue) {
+		if (!isExposureValueValid(*algoExposureValue)) {
+			LOG(DcmippAec, Error) << "Invalid Exposure value: " << *algoExposureValue;
+			return;
+		}
+		params_.algoExposureValue = *algoExposureValue;
+		LOG(DcmippAec, Debug) << "Updating ExposureValue to " << params_.algoExposureValue;
+
+		params_.algoTarget = kAlgoIdealExposureTarget * pow(2, *algoExposureValue);
+		LOG(DcmippAec, Debug) << "Updating AeTarget to " << params_.algoTarget;
+	}
+
+	/* Static config: update params_ and if applicable force config_ update now */
+	const auto &gain = controls.get(controls::draft::AnalogueGain_dB);
+	const auto &exposure = controls.get(controls::ExposureTime);
+
+	if (gain) {
+		if (!isGainValid(*gain, context)) {
+			LOG(DcmippAec, Error) << "Invalid Gain: " << *gain;
+			return;
+		}
+		params_.sensorStatic.gain = *gain;
+		if (!params_.algoEnable) {
+			config_.sensor.gain = params_.sensorStatic.gain;
+			config_.pending = true;
+		}
+		LOG(DcmippAec, Debug) << "Updating static sensor gain to " << *gain;
+	}
+
+	if (exposure) {
+		if (!isExposureTimeValid(*exposure, context)) {
+			LOG(DcmippAec, Error) << "Invalid Exposure time: " << *exposure;
+			return;
+		}
+		params_.sensorStatic.exposure = *exposure;
+		if (!params_.algoEnable) {
+			config_.sensor.exposure = *exposure;
+			config_.pending = true;
+		}
+		LOG(DcmippAec, Debug) << "Updating static sensor exposure to " << *exposure;
+	}
+}
+
+void Aec::prepare(IPAContext &context,
+		  [[maybe_unused]] const uint32_t frame,
+		  [[maybe_unused]] IPAFrameContext &frameContext,
+		  [[maybe_unused]] stm32_dcmipp_params_cfg *params,
+		  ControlList &sensorControls,
+		  [[maybe_unused]] ControlList &ispControls)
+{
+	/* Copy the pending config to the isp_params and sensor_ctrl. Update the IPAContext */
+	if (config_.pending) {
+		/* Configure sensor controls */
+		sensorControls.set(controls::draft::AnalogueGain_dB, config_.sensor.gain);
+		sensorControls.set(controls::ExposureTime, config_.sensor.exposure);
+
+		/* Update context */
+		context.sensor = config_.sensor;
+
+		/* Start the invalid stats counter from this update. Consider both ISP and sensor */
+		internal_.invalidStats = context.info.ispStatLatency + context.info.sensorStatLatency;
+
+		/* Clear the pending request */
+		config_.pending = false;
+	}
+}
+
+const int32_t kAecTolerance = 15;
+const float kAecCoeffLumGain = 0.1f;
+const float kAecGainUpdateMax = 5.0f;
+const float kAecExposureUpdateRatio = 1.2f;
+const int32_t kAecExposureMin = 400;
+
+void Aec::process(IPAContext &context,
+		  [[maybe_unused]] const uint32_t frame,
+		  [[maybe_unused]] IPAFrameContext &frameContext,
+		  const stm32_dcmipp_stat_buf *stats,
+		  ControlList &metadata)
+{
+	/* Compute a new pending config from stats */
+	if (params_.algoEnable) {
+		/* Check if stats can be considered as valid */
+		if (internal_.invalidStats)
+			internal_.invalidStats--;
+
+		if (internal_.invalidStats) {
+			LOG(DcmippAec, Debug) << "Can't update now";
+		} else {
+			if (process_simple_algo) {
+				bool do_exposure_update;
+				float gain_update;
+				double gain = context.sensor.gain;
+				int32_t exposure = context.sensor.exposure;
+				int32_t target = (int32_t)params_.algoTarget;
+				int32_t avgL = (3 * stats->post.average_RGB[0] +
+						6 * stats->post.average_RGB[1] +
+						1 * stats->post.average_RGB[2]) /
+					       10;
+
+				LOG(DcmippAec, Debug) << "Status: L = " << avgL << " - "
+							    << "Gain = " << gain << " db - "
+							    << "Exposure = " << exposure << " us";
+
+				/* Compare the average luminance with the target */
+				gain_update = 0.0f;
+				if (avgL > target + kAecTolerance) {
+					/* Too bright, decrease gain */
+					gain_update = (float)(target - avgL) * kAecCoeffLumGain;
+					if (gain_update < -kAecGainUpdateMax)
+						gain_update = -kAecGainUpdateMax;
+				} else if (avgL < target - kAecTolerance) {
+					/* Too dark vador, call a Jedi and increase gain */
+					gain_update = (float)(target - avgL) * kAecCoeffLumGain;
+					if (gain_update > kAecGainUpdateMax)
+						gain_update = kAecGainUpdateMax;
+				}
+
+				if (gain_update == 0.0f) {
+					LOG(DcmippAec, Debug) << "No change required";
+				} else {
+					/* Need to change something (gain or exposure) */
+					/* Check current exposure to decide whether we shall update gain or exposure */
+					if ((gain == context.info.sensorGainMin) &&
+					    ((exposure != context.info.sensorExposureMax) || (gain_update < 0)))
+						do_exposure_update = true;
+					else
+						do_exposure_update = false;
+
+					if (!do_exposure_update) {
+						/* Update gain as it has not reached its min value */
+						gain += gain_update;
+						if (gain < context.info.sensorGainMin)
+							gain = context.info.sensorGainMin;
+						else if (gain > context.info.sensorGainMax)
+							gain = context.info.sensorGainMax;
+
+						LOG(DcmippAec, Debug) << "New gain: " << gain << " db";
+						config_.sensor.gain = gain;
+						config_.pending = true;
+					} else {
+						/* Update exposure since gain has reached its min value */
+						if (gain_update < 0) {
+							/* Decrease exposure */
+							exposure /= kAecExposureUpdateRatio;
+							/* Note: sensorExposureMin for IMX335 is wrong: use alternate value */
+							if (exposure < kAecExposureMin)
+								exposure = kAecExposureMin;
+						} else {
+							/* Increase exposure */
+							exposure *= kAecExposureUpdateRatio;
+							if (exposure > context.info.sensorExposureMax)
+								exposure = context.info.sensorExposureMax;
+						}
+
+						LOG(DcmippAec, Debug) << "New exposure: " << exposure << " us";
+						config_.sensor.exposure = exposure;
+						config_.pending = true;
+					}
+				}
+			}
+#ifdef EVISION_ALGO_ENABLED
+			else
+			{
+				double gain = context.sensor.gain;
+				int32_t exposure = context.sensor.exposure;
+				int32_t avgL = (3 * stats->post.average_RGB[0] +
+						6 * stats->post.average_RGB[1] +
+						1 * stats->post.average_RGB[2]) /
+					       10;
+
+				LOG(DcmippAec, Debug) << "Status: L = " << avgL << " - "
+						      << "Gain = " << gain << " db - "
+						      << "Exposure = " << exposure << " us";
+
+				/* Align on the target update (may have been updated with ISP_SetExposureTarget()) */
+				pIspAEprocess->hyper_params.target = (uint8_t)params_.algoTarget;
+
+				evision_return_t process_result = processAeInstance(&gain, &exposure, avgL);
+				if (process_result != EVISION_RET_SUCCESS) {
+					LOG(DcmippAec, Error) << "Failed to process pIspAEprocess";
+				}
+
+				if (config_.sensor.exposure != exposure) {
+					LOG(DcmippAec, Debug) << "New exposure: " << exposure << " us";
+					config_.sensor.exposure = exposure;
+					config_.pending = true;
+				}
+
+				if (config_.sensor.gain != gain) {
+					LOG(DcmippAec, Debug) << "New gain: " << gain << " db";
+					config_.sensor.gain = gain;
+					config_.pending = true;
+				}
+			}
+#endif /* EVISION_ALGO_ENABLED */
+		}
+	}
+
+	/* Set metadata */
+	metadata.set(controls::AeEnable, params_.algoEnable);
+	metadata.set(controls::draft::AeExposureTarget, params_.algoTarget);
+	metadata.set(controls::ExposureValue, params_.algoExposureValue);
+	metadata.set(controls::draft::AnalogueGain_dB, (float)config_.sensor.gain);
+	metadata.set(controls::ExposureTime, config_.sensor.exposure);
+}
+
+REGISTER_IPA_ALGORITHM(Aec, "Aec")
+
+} /* namespace ipa::dcmipp::algorithms */
+
+} /* namespace libcamera */
diff --git a/src/ipa/dcmipp/algorithms/aec.h b/src/ipa/dcmipp/algorithms/aec.h
new file mode 100644
index 00000000..b49c77d1
--- /dev/null
+++ b/src/ipa/dcmipp/algorithms/aec.h
@@ -0,0 +1,52 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024 ST Microelectronics
+ * Copyright (C) 2024 LACROIX - Impulse
+ *
+ * aec.h - STM32 DCMIPP AE control
+ */
+
+#pragma once
+
+#include "algorithm.h"
+
+namespace libcamera {
+
+namespace ipa::dcmipp::algorithms {
+
+class Aec : public Algorithm
+{
+public:
+	Aec() = default;
+
+	int init(IPAContext &context, const YamlObject &tuningData) override;
+	int configure(IPAContext &context, const IPACameraSensorInfo &configInfo) override;
+	void queueRequest(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+			  const ControlList &controls) override;
+	void prepare(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+		     stm32_dcmipp_params_cfg *params, ControlList &sensorControls,
+		     ControlList &ispControls) override;
+	void process(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+		     const stm32_dcmipp_stat_buf *stats, ControlList &metadata) override;
+
+private:
+	struct algoParams {
+		bool algoEnable;
+		uint32_t algoTarget;
+		float algoExposureValue;
+		struct IPASensor sensorStatic;
+	} params_;
+
+	struct algoInternal {
+		int32_t invalidStats;
+	} internal_;
+
+	struct algoConfig {
+		bool pending;
+		struct IPASensor sensor;
+	} config_;
+};
+
+} /* namespace ipa::dcmipp::algorithms */
+
+} /* namespace libcamera */
diff --git a/src/ipa/dcmipp/algorithms/algorithm.h b/src/ipa/dcmipp/algorithms/algorithm.h
new file mode 100644
index 00000000..af76c7dd
--- /dev/null
+++ b/src/ipa/dcmipp/algorithms/algorithm.h
@@ -0,0 +1,34 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024 ST Microelectronics
+ *
+ * algorithm.h - STM32 DCMIPP control algorithm interface
+ */
+
+#pragma once
+
+#include <libipa/algorithm.h>
+
+#include "../module.h"
+
+namespace libcamera {
+
+namespace ipa::dcmipp {
+
+class Algorithm : public libcamera::ipa::Algorithm<Module>
+{
+public:
+	/* prepare ISP params / controls and Sensor controls */
+	virtual void prepare([[maybe_unused]] typename Module::Context &context,
+			     [[maybe_unused]] const uint32_t frame,
+			     [[maybe_unused]] typename Module::FrameContext &frameContext,
+			     [[maybe_unused]] typename Module::Params *params,
+			     [[maybe_unused]] ControlList &sensorControls,
+			     [[maybe_unused]] ControlList &ispControls)
+	{
+	}
+};
+
+} /* namespace ipa::dcmipp */
+
+} /* namespace libcamera */
diff --git a/src/ipa/dcmipp/algorithms/awb.cpp b/src/ipa/dcmipp/algorithms/awb.cpp
new file mode 100644
index 00000000..9d7271c5
--- /dev/null
+++ b/src/ipa/dcmipp/algorithms/awb.cpp
@@ -0,0 +1,945 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024 ST Microelectronics
+ * Copyright (C) 2024 LACROIX - Impulse
+ *
+ * awb.cpp - STM32 DCMIPP AWB control
+ */
+
+#include "awb.h"
+
+#include <cmath>
+#include <limits.h>
+
+#include <libcamera/base/log.h>
+
+#include <libcamera/control_ids.h>
+
+#ifdef EVISION_ALGO_ENABLED
+#include <dlfcn.h>
+#include <iostream>
+#include "evision-api-awb.h"
+#endif /* EVISION_ALGO_ENABLED */
+
+namespace libcamera {
+
+namespace ipa::dcmipp::algorithms {
+
+LOG_DEFINE_CATEGORY(DcmippAwb)
+
+static constexpr uint32_t kPrecisionFactor = 100000000;
+static constexpr uint32_t kIdle = 128;
+static constexpr char kDelimiter = '$';
+static constexpr int kColGainMin = 0;
+static constexpr int kColGainMax = 1600000000;
+static constexpr int kColGainDef = 100000000;
+static constexpr int kColCorrectionMin = -400000000;
+static constexpr int kColCorrectionMax = 400000000;
+static constexpr int kColCorrectionDef = 0;
+static constexpr int kProfileNameLen = 32;
+static constexpr int kColTemperatureMin = 0;
+static constexpr int kColTemperatureMax = 10000;
+static constexpr int kColTemperatureDef = 0;
+static constexpr int kIspApplyConfigLatency = 3;
+
+#ifdef EVISION_ALGO_ENABLED
+static void *plib_handle = nullptr;
+static evision_awb_estimator_t *pIspAWBestimator = nullptr;
+static evision_awb_profile_t awbProfiles[EVISION_AWB_MAX_PROFILE_COUNT];
+static float colorTempThresholds[EVISION_AWB_MAX_PROFILE_COUNT - 1];
+
+typedef evision_awb_estimator_t *(*evision_api_awb_new_t)(evision_api_log_callback log_cb);
+typedef evision_return_t (*evision_api_awb_delete_t)(evision_awb_estimator_t *self);
+typedef void (*evision_api_awb_set_profile_t)(evision_awb_profile_t *awb_profile,
+					      float color_temperature, const float cfa_gains[EVISION_AWB_NB_DG_CFA_GAINS],
+					      const float ccm_coefficients[EVISION_AWB_CCM_SIZE][EVISION_AWB_CCM_SIZE],
+					      const float ccm_offsets[EVISION_AWB_CCM_SIZE]);
+typedef evision_return_t (*evision_api_awb_init_profiles_t)(evision_awb_estimator_t *const self,
+							    double min_temp, double max_temp,
+							    uint16_t nb_profiles, float decision_thresholds[EVISION_AWB_MAX_PROFILE_COUNT - 1],
+							    evision_awb_profile_t awb_profiles[EVISION_AWB_MAX_PROFILE_COUNT]);
+typedef evision_return_t (*evision_api_awb_run_average_t)(evision_awb_estimator_t *const self, const evision_image_t *const image,
+							  uint8_t use_ext_meas, double ext_meas[EVISION_AWB_EXT_MEAS_SIZE]);
+
+static evision_api_awb_new_t evision_api_awb_new = nullptr;
+static evision_api_awb_delete_t evision_api_awb_delete = nullptr;
+static evision_api_awb_set_profile_t evision_api_awb_set_profile = nullptr;
+static evision_api_awb_init_profiles_t evision_api_awb_init_profiles = nullptr;
+static evision_api_awb_run_average_t evision_api_awb_run_average = nullptr;
+#endif
+
+static bool process_simple_algo = true;
+
+static bool isColourGainValid(int32_t gain)
+{
+	return gain >= kColGainMin && gain <= kColGainMax;
+}
+
+static bool isColourGainValid(Span<const int32_t> gain)
+{
+	for (auto const &g : gain)
+		if (!isColourGainValid(g))
+			return false;
+	return true;
+}
+
+static bool isColourCorrectionValid(int32_t correction)
+{
+	return correction >= kColCorrectionMin && correction <= kColCorrectionMax;
+}
+
+static bool isColourCorrectionValid(std::vector<int32_t> matrix)
+{
+	for (auto const &c : matrix)
+		if (!isColourCorrectionValid(c))
+			return false;
+	return true;
+}
+
+static bool isColourCorrectionValid(Span<const int32_t> matrix)
+{
+	for (auto const &c : matrix)
+		if (!isColourCorrectionValid(c))
+			return false;
+	return true;
+}
+
+static bool isColourTemperatureValid(int32_t temperature)
+{
+	return temperature >= kColTemperatureMin && temperature <= kColTemperatureMax;
+}
+
+static bool isColourTemperatureValid(std::vector<int32_t> temperature)
+{
+	for (auto const &t : temperature)
+		if (!isColourTemperatureValid(t))
+			return false;
+	return true;
+}
+
+static bool isColourTemperatureValid(Span<const int32_t> temperature)
+{
+	for (auto const &t : temperature)
+		if (!isColourTemperatureValid(t))
+			return false;
+	return true;
+}
+
+static void toShiftMultiplier(uint32_t gain, uint8_t *shift, uint8_t *multiplier)
+{
+	/* Convert gain (Unit = 100000000 for "x1.0") to Multiplier (where 128 means "x1.0") */
+	uint64_t mult64 = gain;
+	mult64 = (mult64 * kIdle) / kPrecisionFactor;
+
+	/* Get Shift + Multiplier where Multiplier < 256 */
+	*shift = 0;
+	while (mult64 >= 256) {
+		mult64 /= 2;
+		(*shift)++;
+	}
+	*multiplier = (uint8_t)mult64;
+}
+
+static int16_t toCConvReg(int32_t coeff)
+{
+	/* Convert coefficient (Unit = 100000000 for "x1.0") to register format */
+	int64_t val = coeff;
+	int16_t reg;
+
+	val = (val * 256) / kPrecisionFactor;
+	if (val >= 0)
+		reg = val;
+	else
+		reg = ((-val ^ 0x7FF) + 1) & 0x7FF;
+
+	return reg;
+}
+
+#ifdef EVISION_ALGO_ENABLED
+double applyGammaInverse(uint32_t comp)
+{
+	return 255 * std::pow(static_cast<float>(comp) / 255, 1.0 / 2.2);
+}
+
+void applyCConv(IPAContext &context, const uint32_t inRGB[3], uint32_t outRGB[3])
+{
+	if (context.isp.cconv.enable) {
+		const int32_t(*coeff)[3] = context.isp.cconv.coeff;
+		int64_t ccR, ccG, ccB;
+
+		// Apply ColorConversion matrix to the input components
+		ccR = static_cast<int64_t>(inRGB[0]) * coeff[0][0] + static_cast<int64_t>(inRGB[1]) * coeff[0][1] + static_cast<int64_t>(inRGB[2]) * coeff[0][2];
+		ccG = static_cast<int64_t>(inRGB[0]) * coeff[1][0] + static_cast<int64_t>(inRGB[1]) * coeff[1][1] + static_cast<int64_t>(inRGB[2]) * coeff[1][2];
+		ccB = static_cast<int64_t>(inRGB[0]) * coeff[2][0] + static_cast<int64_t>(inRGB[1]) * coeff[2][1] + static_cast<int64_t>(inRGB[2]) * coeff[2][2];
+
+		ccR /= kPrecisionFactor;
+		ccG /= kPrecisionFactor;
+		ccB /= kPrecisionFactor;
+
+		// Clamp values to 0-255
+		ccR = std::clamp(ccR, static_cast<int64_t>(0), static_cast<int64_t>(255));
+		ccG = std::clamp(ccG, static_cast<int64_t>(0), static_cast<int64_t>(255));
+		ccB = std::clamp(ccB, static_cast<int64_t>(0), static_cast<int64_t>(255));
+
+		outRGB[0] = static_cast<uint32_t>(ccR);
+		outRGB[1] = static_cast<uint32_t>(ccG);
+		outRGB[2] = static_cast<uint32_t>(ccB);
+	} else {
+		outRGB[0] = inRGB[0];
+		outRGB[1] = inRGB[1];
+		outRGB[2] = inRGB[2];
+	}
+}
+
+static bool initializeLibrary()
+{
+	const char *lib_dir = "/usr/lib/";
+	const char *lib_name = "libevision-awb.so.1";
+	std::string lib_path = std::string(lib_dir) + lib_name;
+
+	plib_handle = dlopen(lib_path.c_str(), RTLD_LAZY);
+	if (!plib_handle) {
+		LOG(DcmippAwb, Warning) << "Cannot open library: " << dlerror();
+		LOG(DcmippAwb, Warning) << "Fall back to simple AWB algorithm processing";
+		return true;
+	}
+
+	dlerror(); // Clear any existing error
+
+	process_simple_algo = false;
+	evision_api_awb_new = (evision_api_awb_new_t)dlsym(plib_handle, "evision_api_awb_new");
+	const char *dlsym_error = dlerror();
+	if (dlsym_error) {
+		LOG(DcmippAwb, Error) << "Cannot load symbol 'evision_api_awb_new': " << dlsym_error;
+		dlclose(plib_handle);
+		return false;
+	}
+
+	evision_api_awb_delete = (evision_api_awb_delete_t)dlsym(plib_handle, "evision_api_awb_delete");
+	dlsym_error = dlerror();
+	if (dlsym_error) {
+		LOG(DcmippAwb, Error) << "Cannot load symbol 'evision_api_awb_delete': " << dlsym_error;
+		dlclose(plib_handle);
+		return false;
+	}
+
+	evision_api_awb_set_profile = (evision_api_awb_set_profile_t)dlsym(plib_handle, "evision_api_awb_set_profile");
+	dlsym_error = dlerror();
+	if (dlsym_error) {
+		LOG(DcmippAwb, Error) << "Cannot load symbol 'evision_api_awb_set_profile': " << dlsym_error;
+		dlclose(plib_handle);
+		return false;
+	}
+
+	evision_api_awb_init_profiles = (evision_api_awb_init_profiles_t)dlsym(plib_handle, "evision_api_awb_init_profiles");
+	dlsym_error = dlerror();
+	if (dlsym_error) {
+		LOG(DcmippAwb, Error) << "Cannot load symbol 'evision_api_awb_init_profiles': " << dlsym_error;
+		dlclose(plib_handle);
+		return false;
+	}
+
+	evision_api_awb_run_average = (evision_api_awb_run_average_t)dlsym(plib_handle, "evision_api_awb_run_average");
+	dlsym_error = dlerror();
+	if (dlsym_error) {
+		LOG(DcmippAwb, Error) << "Cannot load symbol 'evision_api_awb_run_average': " << dlsym_error;
+		dlclose(plib_handle);
+		return false;
+	}
+
+	return true;
+}
+
+static void log_cb(const char *const msg)
+{
+	LOG(DcmippAwb, Debug) << msg;
+}
+
+bool initializeAwbInstance()
+{
+	if (!plib_handle) {
+		LOG(DcmippAwb, Error) << "Library not loaded";
+		return false;
+	}
+
+	pIspAWBestimator = evision_api_awb_new(log_cb);
+	if (pIspAWBestimator == nullptr) {
+		LOG(DcmippAwb, Error) << "Failed to create pIspAWBestimator";
+		return false;
+	}
+
+	return true;
+}
+
+bool Awb::configureAwbAlgo()
+{
+	if (process_simple_algo) {
+		LOG(DcmippAwb, Debug) << "No algorithm reconfiguration needed";
+		return true;
+	}
+
+	evision_return_t e_ret;
+	uint32_t colorTemp, profId, profNb = 0;
+	float cfaGains[4], ccmCoeffs[3][3], ccmOffsets[3] = { 0 };
+
+	if (pIspAWBestimator == nullptr) {
+		LOG(DcmippAwb, Error) << "pIspAWBestimator not found";
+		return false;
+	}
+
+	/* Set profiles (color temperature, gains, color conv matrix) */
+	for (profId = 0; profId < EVISION_AWB_MAX_PROFILE_COUNT; profId++) {
+		colorTemp = static_cast<float>(params_.referenceColorTemp[profId]);
+		if (colorTemp == 0)
+			break;
+
+		if (profNb > 0) {
+			/* Profile decision threshold = lowest ref. temperature + 1/4 of the distance between two reference temperatures */
+			colorTempThresholds[profNb - 1] = static_cast<float>((colorTemp + 3 * params_.referenceColorTemp[profId - 1]) / 4);
+		}
+
+		/* Set cfa gains (RGGB) */
+		cfaGains[0] = static_cast<float>(params_.gainRGB[profId + 0 * kAwbNbRef]) / kPrecisionFactor;
+		cfaGains[1] = static_cast<float>(params_.gainRGB[profId + 1 * kAwbNbRef]) / kPrecisionFactor;
+		cfaGains[2] = cfaGains[1];
+		cfaGains[3] = static_cast<float>(params_.gainRGB[profId + 2 * kAwbNbRef]) / kPrecisionFactor;
+
+		/* Set CCM Coeff */
+		for (uint32_t i = 0; i < 3; i++) {
+			for (uint32_t j = 0; j < 3; j++) {
+				ccmCoeffs[i][j] = static_cast<float>(params_.cconv[profId * 9 + i * 3 + j]) / kPrecisionFactor;
+			}
+		}
+
+		/* Set profile */
+		evision_api_awb_set_profile(&awbProfiles[profId], static_cast<float>(colorTemp), cfaGains, ccmCoeffs, ccmOffsets);
+		profNb++;
+	}
+
+	if (profNb == 0) {
+		LOG(DcmippAwb, Error) << "No valid AWB profiles found";
+		return false;
+	}
+
+	/* Register profiles */
+	e_ret = evision_api_awb_init_profiles(pIspAWBestimator, static_cast<double>(params_.referenceColorTemp[0]),
+					      static_cast<double>(params_.referenceColorTemp[profNb - 1]), profNb,
+					      colorTempThresholds, awbProfiles);
+	if (e_ret != EVISION_RET_SUCCESS) {
+		LOG(DcmippAwb, Error) << "Failed to initialize AWB profiles";
+		return false;
+	}
+
+	/* Configure algo */
+	/* TODO: check if this shall be an IQ tuning parameter (like the LUT tables of AE algo) */
+	pIspAWBestimator->hyper_params.speed_p_min = 1.35;
+	pIspAWBestimator->hyper_params.speed_p_max = (profNb < 4) ? 1.8 : 2.0;
+	pIspAWBestimator->hyper_params.gm_tolerance = 1;
+	pIspAWBestimator->hyper_params.conv_criterion = 3;
+
+	return true;
+}
+
+static void deinitializeAwbInstance()
+{
+	if (pIspAWBestimator) {
+		evision_api_awb_delete(pIspAWBestimator);
+		pIspAWBestimator = nullptr;
+	}
+}
+
+static void deinitializeLibrary()
+{
+	if (plib_handle) {
+		dlclose(plib_handle);
+		plib_handle = nullptr;
+	}
+}
+#endif /* EVISION_ALGO_ENABLED */
+
+static void getStatNoGain(struct IPAIspGain ispGain, const __u32 average_RGB[3],
+			  int32_t avgBeforeGain[3])
+{
+	uint64_t R, G, B;
+
+	/* Read the current ISP gain */
+	if (ispGain.enable == 1) {
+		R = ((uint64_t)average_RGB[0] * kPrecisionFactor) / ispGain.gainR;
+		avgBeforeGain[0] = (int32_t)R;
+
+		G = ((uint64_t)average_RGB[1] * kPrecisionFactor) / ispGain.gainG;
+		avgBeforeGain[1] = (int32_t)G;
+
+		B = ((uint64_t)average_RGB[2] * kPrecisionFactor) / ispGain.gainB;
+		avgBeforeGain[2] = (int32_t)B;
+	} else {
+		avgBeforeGain[0] = (int32_t)average_RGB[0];
+		avgBeforeGain[1] = (int32_t)average_RGB[1];
+		avgBeforeGain[2] = (int32_t)average_RGB[2];
+	}
+}
+
+static double linearSrgb(double c)
+{
+	double linh;
+	if (c <= 0.04045)
+		linh = c / 12.92;
+	else
+		linh = pow((c + 0.055) / 1.055, 2.4);
+	return linh;
+}
+
+static double computeCCT(int32_t gain[3])
+{
+	/* Correlation matrix used in order to convert RBG values to XYZ space */
+	/* Illuminant = D65      RGB (R709) [sRGB or HDTV] to XYZ */
+	const double Cx[] = { 0.4124, 0.3576, 0.1805 };
+	const double Cy[] = { 0.2126, 0.7152, 0.0722 };
+	const double Cz[] = { 0.0193, 0.1192, 0.9505 };
+	int i;
+	double data[3], xyNormFactor, m_xNormCoeff, m_yNormCoeff, nCoeff, cct;
+	double X_tmp = 0, Y_tmp = 0, Z_tmp = 0;
+
+	/* Normalize and prepare RGB channels values for cct computation */
+	data[0] = linearSrgb(gain[0] / 255.0);
+	data[1] = linearSrgb(gain[1] / 255.0);
+	data[2] = linearSrgb(gain[2] / 255.0);
+
+	/* Apply correlation matrix to RGB channels to obtain (X,Y,Z) */
+	for (i = 0; i < 3; i++) {
+		X_tmp += Cx[i] * data[i];
+		Y_tmp += Cy[i] * data[i];
+		Z_tmp += Cz[i] * data[i];
+	}
+
+	/* Transform (X,Y,Z) to (x,y) */
+	xyNormFactor = X_tmp + Y_tmp + Z_tmp;
+	m_xNormCoeff = X_tmp / xyNormFactor;
+	m_yNormCoeff = Y_tmp / xyNormFactor;
+
+	/* Apply McCamy's formula to obtain CCT value */
+	nCoeff = (m_xNormCoeff - 0.3320) / (0.1858 - m_yNormCoeff);
+	cct = (449 * pow(nCoeff, 3) + 3525 * pow(nCoeff, 2) + 6823.3 * nCoeff + 5520.33);
+
+	return cct;
+}
+
+static double fixCCT(double cct)
+{
+	/* Correction = 0.0005517 CCT² – 4.597 CCT + 12208 */
+	return 0.0005517 * cct * cct - 4.597 * cct + 12208;
+}
+
+void Awb::applyProfile(int profId)
+{
+	LOG(DcmippAwb, Debug) << "Changing AWB profile to " << params_.profileName[profId]
+			      << " (" << params_.referenceColorTemp[profId] << ")";
+	internal_.colorTemp = params_.referenceColorTemp[profId];
+	internal_.profileName = params_.profileName[profId];
+
+	config_.gain.enable = 1;
+	config_.gain.gainR = params_.gainRGB[profId + 0 * kAwbNbRef];
+	config_.gain.gainG = params_.gainRGB[profId + 1 * kAwbNbRef];
+	config_.gain.gainB = params_.gainRGB[profId + 2 * kAwbNbRef];
+
+	config_.cconv.enable = 1;
+	int offset = 3 * 3 * profId;
+	std::copy(params_.cconv.begin() + offset, params_.cconv.begin() + offset + 3 * 3,
+		  &config_.cconv.coeff[0][0]);
+
+	internal_.profileDirty = false;
+	config_.pending = true;
+}
+
+int Awb::init([[maybe_unused]] IPAContext &context, const YamlObject &tuningData)
+{
+	/* Check for AWB algo config  */
+	params_.algoEnable = tuningData["AwbEnable"].get<bool>(0);
+
+	std::vector<std::string> name = tuningData["ProfileName"].getList<std::string>().value_or(std::vector<std::string>{});
+	if (name.size() == kAwbNbRef) {
+		std::copy(name.begin(), name.end(), params_.profileName.begin());
+	} else if (name.size() != 0) {
+		LOG(DcmippAwb, Error) << "Invalid ProfileName";
+		return -EINVAL;
+	}
+
+	std::vector<int32_t> data = tuningData["RefColorTemp"].getList<int32_t>().value_or(std::vector<int32_t>{});
+	if (data.size() == kAwbNbRef) {
+		if (!isColourTemperatureValid(data)) {
+			LOG(DcmippAwb, Error) << "Invalid RefColorTemp values";
+			return -EINVAL;
+		}
+		std::copy(data.begin(), data.end(), params_.referenceColorTemp.begin());
+	} else if (data.size() != 0) {
+		LOG(DcmippAwb, Error) << "Invalid RefColorTemp";
+		return -EINVAL;
+	}
+
+	std::vector<int32_t> dataR = tuningData["GainR"].getList<int32_t>().value_or(std::vector<int32_t>{});
+	std::vector<int32_t> dataG = tuningData["GainG"].getList<int32_t>().value_or(std::vector<int32_t>{});
+	std::vector<int32_t> dataB = tuningData["GainB"].getList<int32_t>().value_or(std::vector<int32_t>{});
+	if ((dataR.size() == kAwbNbRef) && (dataG.size() == kAwbNbRef) && (dataB.size() == kAwbNbRef)) {
+		std::copy(dataR.begin(), dataR.end(), params_.gainRGB.begin() + 0 * dataR.size());
+		std::copy(dataG.begin(), dataG.end(), params_.gainRGB.begin() + 1 * dataR.size());
+		std::copy(dataB.begin(), dataB.end(), params_.gainRGB.begin() + 2 * dataR.size());
+		if (!isColourGainValid(Span<int32_t>{ params_.gainRGB })) {
+			LOG(DcmippAwb, Error) << "Invalid GainR/G/B";
+			return -EINVAL;
+		}
+	} else if ((dataR.size() != 0) || (dataG.size() != 0) || (dataB.size() != 0)) {
+		LOG(DcmippAwb, Error) << "Invalid GainR/G/B";
+		return -EINVAL;
+	}
+
+	std::vector<int32_t> matrix = tuningData["Cconv"].getList<int32_t>().value_or(std::vector<int32_t>{});
+	if (matrix.size() == kAwbNbRef * 3 * 3) {
+		if (!isColourCorrectionValid(matrix)) {
+			LOG(DcmippAwb, Error) << "Invalid Cconv values";
+			return -EINVAL;
+		}
+		std::copy(matrix.begin(), matrix.end(), params_.cconv.begin());
+	} else if (matrix.size() != 0) {
+		LOG(DcmippAwb, Error) << "Invalid Cconv";
+		return -EINVAL;
+	}
+
+	/* Check for ISP Gain / ColorConv static config */
+	params_.gainStatic.gainR = tuningData["FixedGainR"].get<int32_t>(0);
+	params_.gainStatic.gainG = tuningData["FixedGainG"].get<int32_t>(0);
+	params_.gainStatic.gainB = tuningData["FixedGainB"].get<int32_t>(0);
+	if (!isColourGainValid(params_.gainStatic.gainR) || !isColourGainValid(params_.gainStatic.gainG) || !isColourGainValid(params_.gainStatic.gainB)) {
+		LOG(DcmippAwb, Error) << "Invalid FixedGainR/G/B";
+		return -EINVAL;
+	}
+	if (!params_.gainStatic.gainR && !params_.gainStatic.gainG && !params_.gainStatic.gainB) {
+		params_.gainStatic.enable = false;
+	} else {
+		params_.gainStatic.enable = tuningData["FixedGainEnable"].get<bool>(true);
+	}
+
+	matrix = tuningData["FixedCconv"].getList<int32_t>().value_or(std::vector<int32_t>{});
+	if (!matrix.size()) {
+		memset(params_.cconvStatic.coeff, 0, sizeof(params_.cconvStatic.coeff));
+		params_.cconvStatic.enable = false;
+	} else if (matrix.size() == 3 * 3) {
+		if (!isColourCorrectionValid(matrix)) {
+			LOG(DcmippAwb, Error) << "Invalid FixedCconv values";
+			return -EINVAL;
+		}
+		for (unsigned int i = 0; i < 3; i++)
+			for (unsigned int j = 0; j < 3; j++)
+				params_.cconvStatic.coeff[i][j] = matrix[i * 3 + j];
+		params_.cconvStatic.enable = tuningData["FixedCconvEnable"].get<bool>(true);
+	} else {
+		LOG(DcmippAwb, Error) << "Invalid FixedCconv";
+		return -EINVAL;
+	}
+
+#ifdef EVISION_ALGO_ENABLED
+	if (params_.algoEnable) {
+		if (!initializeLibrary()) {
+			LOG(DcmippAwb, Error) << "Initialize library failed";
+			return -EINVAL;
+		}
+
+ 		if (!process_simple_algo) {
+			if (!initializeAwbInstance()) {
+				LOG(DcmippAwb, Error) << "Cannot initialize awb instance";
+				deinitializeLibrary();
+				return -EINVAL;
+			}
+
+			if (!configureAwbAlgo()) {
+				LOG(DcmippAwb, Error) << "Cannot configure awb algorithm";
+				deinitializeAwbInstance();
+				deinitializeLibrary();
+				return -EINVAL;
+			}
+		}
+	}
+#endif /* EVISION_ALGO_ENABLED */
+
+	/* Configure exposed controls */
+	context.dcmippControls[&controls::draft::ColourGains3Enable] = ControlInfo(false, true);
+	context.dcmippControls[&controls::draft::ColourGains3] = ControlInfo(kColGainMin, kColGainMax, kColGainDef);
+	context.dcmippControls[&controls::draft::ColourCorrectionEnable] = ControlInfo(false, true);
+	context.dcmippControls[&controls::draft::ColourCorrection] = ControlInfo(kColCorrectionMin, kColCorrectionMax, kColCorrectionDef);
+	context.dcmippControls[&controls::AwbEnable] = ControlInfo(false, true);
+	context.dcmippControls[&controls::AwbMode] = ControlInfo(controls::AwbModeValues);
+	context.dcmippControls[&controls::draft::AwbProfileName] = ControlInfo(0, kProfileNameLen, kProfileNameLen);
+	context.dcmippControls[&controls::draft::AwbReferenceColorTemperature] = ControlInfo(kColTemperatureMin, kColTemperatureMax, kColTemperatureDef);
+	context.dcmippControls[&controls::draft::AwbColourGains3] = ControlInfo(kColGainMin, kColGainMax, kColGainDef);
+	context.dcmippControls[&controls::draft::AwbColourCorrection] = ControlInfo(kColCorrectionMin, kColCorrectionMax, kColCorrectionDef);
+	context.dcmippControls[&controls::draft::AwbCustomColorTemperature] = ControlInfo(kColTemperatureMin, kColTemperatureMax, kColTemperatureDef);
+
+	return 0;
+}
+
+int Awb::configure([[maybe_unused]] IPAContext &context,
+		   [[maybe_unused]] const IPACameraSensorInfo &configInfo)
+{
+	/* Set the initial ISP values in the pending config */
+	if (!params_.algoEnable) {
+		/* Apply static ISP Gain / ColorConv config */
+		config_.gain = params_.gainStatic;
+		config_.cconv = params_.cconvStatic;
+	}
+
+	config_.pending = true;
+
+	return 0;
+}
+
+void Awb::queueRequest([[maybe_unused]] IPAContext &context,
+		       [[maybe_unused]] const uint32_t frame,
+		       [[maybe_unused]] IPAFrameContext &frameContext,
+		       const ControlList &controls)
+{
+	bool awbModeAutoDisabling = false;
+
+	/* Algo ctrl: only update params_ which will be considered upon the next process() call */
+	const auto &algoEnable = controls.get(controls::AwbEnable);
+	const auto &awbMode = controls.get(controls::AwbMode);
+	const auto &profileName = controls.get(controls::draft::AwbProfileName);
+	const auto &referenceColorTemp = controls.get(controls::draft::AwbReferenceColorTemperature);
+	const auto &gainRGB = controls.get(controls::draft::AwbColourGains3);
+	const auto &cconv = controls.get(controls::draft::AwbColourCorrection);
+
+	if (algoEnable) {
+		params_.algoEnable = *algoEnable;
+		LOG(DcmippAwb, Debug) << "Updating AwbEnable to " << *algoEnable;
+	}
+
+	if (awbMode) {
+		if (*awbMode == controls::AwbAuto) {
+			params_.algoEnable = true;
+			LOG(DcmippAwb, Debug) << "Updating AwbMode / AwbEnable to "
+					      << params_.algoEnable;
+		} else if (*awbMode == controls::AwbCustom) {
+			if (params_.algoEnable)
+				awbModeAutoDisabling = true;
+			params_.algoEnable = false;
+			LOG(DcmippAwb, Debug) << "Updating AwbMode / AwbEnable to "
+					      << params_.algoEnable;
+		} else {
+			LOG(DcmippAwb, Error) << "Unsupported AwbMode: " << *awbMode;
+		}
+	}
+
+	if (profileName) {
+		/* The Controls class does not support array of string. So, split the concatenated string */
+		std::string token;
+		std::stringstream ss(*profileName);
+		for (int i = 0; i < kAwbNbRef; i++) {
+			if (!getline(ss, token, kDelimiter))
+				token = "";
+			params_.profileName[i] = token;
+		}
+		/* mark the current profile as dirty so it will be applied at next algo run */
+		internal_.profileDirty = true;
+		LOG(DcmippAwb, Debug) << "Updating AwbProfileName to " << *profileName;
+	}
+
+	if (referenceColorTemp) {
+		if (!isColourTemperatureValid(*referenceColorTemp)) {
+			LOG(DcmippAwb, Error) << "Invalid RefColorTemp values";
+			return;
+		}
+		std::copy(std::begin(*referenceColorTemp), std::end(*referenceColorTemp), params_.referenceColorTemp.begin());
+		/* mark the current profile as dirty so it will be applied at next algo run */
+		internal_.profileDirty = true;
+		LOG(DcmippAwb, Debug) << "Updating AwbRefColorTemp to " << (*referenceColorTemp)[0] << "...";
+	}
+
+	if (gainRGB) {
+		if (!isColourGainValid(*gainRGB)) {
+			LOG(DcmippAwb, Error) << "Invalid AwbColourGain values";
+			return;
+		}
+		std::copy(std::begin(*gainRGB), std::end(*gainRGB), params_.gainRGB.begin());
+		/* mark the current profile as dirty so it will be applied at next algo run */
+		internal_.profileDirty = true;
+		LOG(DcmippAwb, Debug) << "Updating AwbColourGains3 to " << (*gainRGB)[0] << "...";
+	}
+
+	if (cconv) {
+		if (!isColourCorrectionValid(*cconv)) {
+			LOG(DcmippAwb, Error) << "Invalid CConv value";
+			return;
+		}
+		std::copy(std::begin(*cconv), std::end(*cconv), params_.cconv.begin());
+		/* mark the current profile as dirty so it will be applied at next algo run */
+		internal_.profileDirty = true;
+		LOG(DcmippAwb, Debug) << "Updating AwbColourConv to " << (*cconv)[0] << "...";
+	}
+
+	if (internal_.profileDirty && !configureAwbAlgo()) {
+		LOG(DcmippAwb, Error) << "Cannot reconfigure awb algorithm";
+		return;
+	}
+
+	/* Static config: update params_ and if applicable force config_ update now */
+	const auto &customColorTemp = controls.get(controls::draft::AwbCustomColorTemperature);
+	const auto &staticGainEnable = controls.get(controls::draft::ColourGains3Enable);
+	const auto &staticGain = controls.get(controls::draft::ColourGains3);
+	const auto &staticCconvEnable = controls.get(controls::draft::ColourCorrectionEnable);
+	const auto &staticCconv = controls.get(controls::draft::ColourCorrection);
+
+	if (customColorTemp && !params_.algoEnable) {
+		/* Search for the corresponding profile and apply it */
+		int profId;
+		for (profId = 0; profId < kAwbNbRef; profId++)
+			if (params_.referenceColorTemp[profId] == *customColorTemp)
+				break;
+
+		if (profId >= kAwbNbRef) {
+			LOG(DcmippAwb, Error) << "Invalid Custom Colour Temp: " << *customColorTemp;
+			/* Revert the 'awbMode = AwbCustom' request if needed */
+			if (awbModeAutoDisabling)
+				params_.algoEnable = true;
+		} else {
+			applyProfile(profId);
+		}
+
+		internal_.customColorTemp = *customColorTemp;
+	}
+
+	if (staticGainEnable) {
+		params_.gainStatic.enable = *staticGainEnable;
+		if (!params_.algoEnable) {
+			config_.gain.enable = *staticGainEnable;
+			config_.pending = true;
+		}
+		LOG(DcmippAwb, Debug) << "Updating ColourGains3Enable to " << *staticGainEnable;
+	}
+
+	if (staticGain) {
+		if (!isColourGainValid(*staticGain)) {
+			LOG(DcmippAwb, Error) << "Invalid FixedGainR/G/B";
+			return;
+		}
+		params_.gainStatic.gainR = (*staticGain)[0];
+		params_.gainStatic.gainG = (*staticGain)[1];
+		params_.gainStatic.gainB = (*staticGain)[2];
+		if (!params_.algoEnable) {
+			config_.gain.gainR = (*staticGain)[0];
+			config_.gain.gainG = (*staticGain)[1];
+			config_.gain.gainB = (*staticGain)[2];
+			config_.pending = true;
+		}
+		LOG(DcmippAwb, Debug) << "Updating ColourGains3 to "
+				      << (*staticGain)[0] << " / "
+				      << (*staticGain)[1] << " / "
+				      << (*staticGain)[2];
+	}
+
+	if (staticCconvEnable) {
+		params_.cconvStatic.enable = *staticCconvEnable;
+		if (!params_.algoEnable) {
+			config_.cconv.enable = *staticCconvEnable;
+			config_.pending = true;
+		}
+		LOG(DcmippAwb, Debug) << "Updating ColourConvEnable to " << *staticCconvEnable;
+	}
+
+	if (staticCconv) {
+		if (!isColourCorrectionValid(*staticCconv)) {
+			LOG(DcmippAwb, Error) << "Invalid staticCconv value";
+			return;
+		}
+		for (unsigned int i = 0; i < 3; i++)
+			for (unsigned int j = 0; j < 3; j++)
+				params_.cconvStatic.coeff[i][j] = (*staticCconv)[i * 3 + j];
+		if (!params_.algoEnable) {
+			memcpy(config_.cconv.coeff, params_.cconvStatic.coeff, sizeof(config_.cconv.coeff));
+			config_.pending = true;
+		}
+		LOG(DcmippAwb, Debug) << "Updating ColourConv to " << (*staticCconv)[0] << "...";
+	}
+}
+
+void Awb::prepare(IPAContext &context,
+		  [[maybe_unused]] const uint32_t frame,
+		  [[maybe_unused]] IPAFrameContext &frameContext,
+		  stm32_dcmipp_params_cfg *params,
+		  [[maybe_unused]] ControlList &sensorControls,
+		  [[maybe_unused]] ControlList &ispControls)
+{
+	/* Copy the pending config to the isp_params. Update the IPAContext */
+	if (config_.pending) {
+		/* Configure Gain params */
+		params->module_cfg_update |= STM32_DCMIPP_ISP_EX;
+		toShiftMultiplier(config_.gain.gainR, &params->ctrls.ex_cfg.shift_r, &params->ctrls.ex_cfg.mult_r);
+		toShiftMultiplier(config_.gain.gainG, &params->ctrls.ex_cfg.shift_g, &params->ctrls.ex_cfg.mult_g);
+		toShiftMultiplier(config_.gain.gainB, &params->ctrls.ex_cfg.shift_b, &params->ctrls.ex_cfg.mult_b);
+		params->ctrls.ex_cfg.en = config_.gain.enable;
+
+		/* Configure Color Conv params */
+		params->module_cfg_update |= STM32_DCMIPP_ISP_CC;
+		params->ctrls.cc_cfg.ra = 0;
+		params->ctrls.cc_cfg.ga = 0;
+		params->ctrls.cc_cfg.ba = 0;
+		params->ctrls.cc_cfg.clamp = 0;
+		params->ctrls.cc_cfg.rr = toCConvReg(config_.cconv.coeff[0][0]);
+		params->ctrls.cc_cfg.rg = toCConvReg(config_.cconv.coeff[0][1]);
+		params->ctrls.cc_cfg.rb = toCConvReg(config_.cconv.coeff[0][2]);
+		params->ctrls.cc_cfg.gr = toCConvReg(config_.cconv.coeff[1][0]);
+		params->ctrls.cc_cfg.gg = toCConvReg(config_.cconv.coeff[1][1]);
+		params->ctrls.cc_cfg.gb = toCConvReg(config_.cconv.coeff[1][2]);
+		params->ctrls.cc_cfg.br = toCConvReg(config_.cconv.coeff[2][0]);
+		params->ctrls.cc_cfg.bg = toCConvReg(config_.cconv.coeff[2][1]);
+		params->ctrls.cc_cfg.bb = toCConvReg(config_.cconv.coeff[2][2]);
+		params->ctrls.cc_cfg.en = config_.cconv.enable;
+
+		/* Update context */
+		context.isp.gain = config_.gain;
+		context.isp.cconv = config_.cconv;
+
+		/* Start the invalid stats counter from this update. Consider only ISP, not sensor */
+		internal_.invalidStats = context.info.ispStatLatency + kIspApplyConfigLatency;
+
+		/* Clear the pending request */
+		config_.pending = false;
+	}
+}
+
+void Awb::process(IPAContext &context,
+		  [[maybe_unused]] const uint32_t frame,
+		  [[maybe_unused]] IPAFrameContext &frameContext,
+		  const stm32_dcmipp_stat_buf *stats,
+		  ControlList &metadata)
+{
+	/* Compute a new pending config from stats */
+	if (params_.algoEnable) {
+		if (process_simple_algo) {
+			/* Fall back to simple AWB algorithm if evision library is not found or used */
+			int32_t avgBeforeGain[3], fixedCCT, distance, colorTemp;
+			int i, profId;
+			double cct;
+
+			/* Check if stats can be considered as valid */
+			if (internal_.invalidStats)
+				internal_.invalidStats--;
+
+			if (!internal_.invalidStats) {
+				/* Get RGB before ISP gain */
+				getStatNoGain(context.isp.gain, stats->post.average_RGB, avgBeforeGain);
+
+				/* Get CCT from McCamy’s approximation */
+				cct = computeCCT(avgBeforeGain);
+
+				/* Fix the computed CCT to match IMX335 experimentations */
+				fixedCCT = (int32_t)fixCCT(cct);
+
+				/* Find the index of the closest profile matching this color temperature */
+				distance = INT_MAX;
+				profId = 0;
+				for (i = 0; i < kAwbNbRef; i++) {
+					if (params_.referenceColorTemp[i] == 0)
+						continue;
+
+					if (abs(params_.referenceColorTemp[i] - fixedCCT) < distance) {
+						distance = abs(params_.referenceColorTemp[i] - fixedCCT);
+						profId = i;
+					}
+				}
+
+				colorTemp = params_.referenceColorTemp[profId];
+				if (colorTemp != internal_.colorTemp || internal_.profileDirty)
+					applyProfile(profId);
+			}
+		}
+#ifdef EVISION_ALGO_ENABLED
+		else
+		{
+			int32_t colorTemp = 0;
+			uint32_t ccAvgRGB[3];
+			double meas[3];
+			uint32_t profId = 0;
+
+			/* Check if stats can be considered as valid */
+			if (internal_.invalidStats)
+				internal_.invalidStats--;
+
+			if (!internal_.invalidStats) {
+				evision_return_t e_ret;
+				/* Apply the current color conversion matrix to get stats after color conversion ISP block*/
+				applyCConv(context, stats->post.average_RGB, ccAvgRGB);
+
+				/* Invert gamma */
+				for (int i = 0; i < 3; ++i) {
+					meas[i] = applyGammaInverse(ccAvgRGB[i]);
+				}
+
+				/* Run algo to estimate gain and color conversion to apply */
+				e_ret = evision_api_awb_run_average(pIspAWBestimator, NULL, 1, meas);
+				if (e_ret == EVISION_RET_SUCCESS) {
+					if (pIspAWBestimator->out_temp != internal_.colorTemp) {
+						/* Find the index profile for this referenceColorTemp */
+						for (profId = 0; profId < EVISION_AWB_MAX_PROFILE_COUNT; profId++) {
+							if (pIspAWBestimator->out_temp == params_.referenceColorTemp[profId])
+								break;
+						}
+
+						if (profId == EVISION_AWB_MAX_PROFILE_COUNT) {
+							LOG(DcmippAwb, Error) << "Unknown AWB profile";
+							return;
+						} else {
+							/* Apply new ISP Color Conversion */
+							colorTemp = params_.referenceColorTemp[profId];
+						}
+					}
+
+					if (colorTemp || internal_.profileDirty)
+						applyProfile((int)profId);
+				} else {
+					LOG(DcmippAwb, Error) << "Unable to run evivion library";
+					return;
+				}
+			}
+		}
+#endif /* EVISION_ALGO_ENABLED */
+	}
+
+	/* Set metadata */
+	metadata.set(controls::draft::ColourGains3Enable, config_.gain.enable);
+	metadata.set(controls::draft::ColourGains3,
+		     { static_cast<int32_t>(config_.gain.gainR),
+		       static_cast<int32_t>(config_.gain.gainG),
+		       static_cast<int32_t>(config_.gain.gainB) });
+
+	metadata.set(controls::draft::ColourCorrectionEnable, config_.cconv.enable);
+	metadata.set(controls::draft::ColourCorrection,
+		     { config_.cconv.coeff[0][0], config_.cconv.coeff[0][1], config_.cconv.coeff[0][2],
+		       config_.cconv.coeff[1][0], config_.cconv.coeff[1][1], config_.cconv.coeff[1][2],
+		       config_.cconv.coeff[2][0], config_.cconv.coeff[2][1], config_.cconv.coeff[2][2] });
+
+	/* The Controls class does not support array of string. So, concatenate the strings in a single one */
+	std::string concatProfiles = "";
+	for (auto const &profile : params_.profileName) {
+		if (!concatProfiles.empty())
+			concatProfiles += kDelimiter;
+		concatProfiles += profile;
+	}
+	metadata.set(controls::draft::AwbProfileName, concatProfiles);
+
+	metadata.set(controls::AwbEnable, params_.algoEnable);
+	metadata.set(controls::AwbMode, params_.algoEnable ? controls::AwbAuto : controls::AwbCustom);
+	metadata.set(controls::draft::AwbReferenceColorTemperature, params_.referenceColorTemp);
+	metadata.set(controls::draft::AwbColourGains3, params_.gainRGB);
+	metadata.set(controls::draft::AwbColourCorrection, params_.cconv);
+
+	if (internal_.colorTemp)
+		metadata.set(controls::ColourTemperature, internal_.colorTemp);
+	if (!internal_.profileName.empty())
+		metadata.set(controls::draft::AwbCurrentProfileName, internal_.profileName);
+	if (internal_.customColorTemp && !params_.algoEnable)
+		metadata.set(controls::draft::AwbCustomColorTemperature, internal_.customColorTemp);
+}
+
+REGISTER_IPA_ALGORITHM(Awb, "Awb")
+
+} /* namespace ipa::dcmipp::algorithms */
+
+} /* namespace libcamera */
diff --git a/src/ipa/dcmipp/algorithms/awb.h b/src/ipa/dcmipp/algorithms/awb.h
new file mode 100644
index 00000000..239868c9
--- /dev/null
+++ b/src/ipa/dcmipp/algorithms/awb.h
@@ -0,0 +1,65 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024 ST Microelectronics
+ * Copyright (C) 2024 LACROIX - Impulse
+ *
+ * awb.h - STM32 DCMIPP AWB control
+ */
+
+#pragma once
+
+#include "algorithm.h"
+
+namespace libcamera {
+
+namespace ipa::dcmipp::algorithms {
+
+class Awb : public Algorithm
+{
+public:
+	Awb() = default;
+
+	int init(IPAContext &context, const YamlObject &tuningData) override;
+	int configure(IPAContext &context, const IPACameraSensorInfo &configInfo) override;
+	void queueRequest(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+			  const ControlList &controls) override;
+	void prepare(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+		     stm32_dcmipp_params_cfg *params, ControlList &sensorControls,
+		     ControlList &ispControls) override;
+	void process(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+		     const stm32_dcmipp_stat_buf *stats, ControlList &metadata) override;
+
+private:
+	static constexpr int32_t kAwbNbRef = 5;
+
+	struct algoParams {
+		bool algoEnable;
+		std::array<std::string, kAwbNbRef> profileName;
+		std::array<int32_t, kAwbNbRef> referenceColorTemp;
+		std::array<int32_t, kAwbNbRef * 3> gainRGB;
+		std::array<int32_t, kAwbNbRef * 3 * 3> cconv;
+		struct IPAIspGain gainStatic;
+		struct IPAIspColorConv cconvStatic;
+	} params_;
+
+	struct algoInternal {
+		int32_t invalidStats;
+		int32_t colorTemp;
+		std::string profileName;
+		int32_t customColorTemp;
+		bool profileDirty;
+	} internal_;
+
+	struct algoConfig {
+		bool pending;
+		struct IPAIspGain gain;
+		struct IPAIspColorConv cconv;
+	} config_;
+
+	bool configureAwbAlgo();
+	void applyProfile(int profId);
+};
+
+} /* namespace ipa::dcmipp::algorithms */
+
+} /* namespace libcamera */
diff --git a/src/ipa/dcmipp/algorithms/badpixel.cpp b/src/ipa/dcmipp/algorithms/badpixel.cpp
new file mode 100644
index 00000000..eb681c13
--- /dev/null
+++ b/src/ipa/dcmipp/algorithms/badpixel.cpp
@@ -0,0 +1,185 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024 ST Microelectronics
+ *
+ * badpixel.cpp - STM32 DCMIPP Bad Pixel Removal
+ */
+
+#include "badpixel.h"
+
+#include <libcamera/base/log.h>
+#include <libcamera/control_ids.h>
+
+namespace libcamera {
+
+namespace ipa::dcmipp::algorithms {
+
+LOG_DEFINE_CATEGORY(DcmippBadPixel)
+
+static constexpr int kStrengthMin = 0;
+static constexpr int kStrengthMax = 7;
+static constexpr int kStrengthDef = 0;
+static constexpr int kThresholdMin = 0;
+static constexpr int kThresholdMax = 4094 * 4094;
+static constexpr int kThresholdDef = 0;
+
+static bool isStrengthValid(int8_t strength)
+{
+	return (strength >= kStrengthMin && strength <= kStrengthMax) || strength == -1;
+}
+
+static bool isThresholdValid(int32_t threshold)
+{
+	return threshold >= kThresholdMin && threshold <= kThresholdMax;
+}
+
+int BadPixel::init([[maybe_unused]] IPAContext &context, const YamlObject &tuningData)
+{
+	/* Parse Tuning Data to get algo parameters */
+	int8_t strength = tuningData["Strength"].get<int8_t>(-1);
+	int32_t threshold = tuningData["Threshold"].get<int32_t>(kThresholdDef);
+	if (!isStrengthValid(strength)) {
+		LOG(DcmippBadPixel, Error) << "Invalid Strength: " << strength;
+		return -EINVAL;
+	}
+	if (!isThresholdValid(threshold)) {
+		LOG(DcmippBadPixel, Error) << "Invalid Threshold: " << threshold;
+		return -EINVAL;
+	}
+	if (strength == -1 && !threshold) {
+		internal_.threshold = 0;
+		params_.badpixel.strength = 0;
+		params_.badpixel.enable = false;
+	} else {
+		internal_.threshold = threshold;
+		internal_.countAccu = 0;
+		internal_.measureNb = 0;
+		params_.badpixel.strength = strength < 0 ? 0 : strength;
+		params_.badpixel.enable = tuningData["Enable"].get<bool>(true);
+	}
+
+	/* Configure exposed controls */
+	context.dcmippControls[&controls::draft::BadPixelRemovalEnable] = ControlInfo(false, true);
+	context.dcmippControls[&controls::draft::BadPixelRemovalStrength] = ControlInfo(kStrengthMin, kStrengthMax, kStrengthDef);
+	context.dcmippControls[&controls::draft::BadPixelRemovalThreshold] = ControlInfo(kThresholdMin, kThresholdMax, kThresholdDef);
+
+	return 0;
+}
+
+int BadPixel::configure([[maybe_unused]] IPAContext &context,
+			[[maybe_unused]] const IPACameraSensorInfo &configInfo)
+{
+	/* Set the initial ISP values in the pending config */
+	config_.badpixel = params_.badpixel;
+	config_.pending = true;
+
+	return 0;
+}
+
+void BadPixel::queueRequest([[maybe_unused]] IPAContext &context,
+			    [[maybe_unused]] const uint32_t frame,
+			    [[maybe_unused]] IPAFrameContext &frameContext,
+			    const ControlList &controls)
+{
+	/* Algo ctrl: only update internal_ which will be considered upon the next process() call */
+	const auto &threshold = controls.get(controls::draft::BadPixelRemovalThreshold);
+	if (threshold) {
+		if (!isThresholdValid(*threshold)) {
+			LOG(DcmippBadPixel, Error) << "Invalid Threshold: " << *threshold;
+			return;
+		}
+		internal_.threshold = *threshold;
+		internal_.measureNb = 0;
+		internal_.countAccu = 0;
+		LOG(DcmippBadPixel, Debug) << "Updating threshold to " << *threshold;
+	}
+
+	/* Update params_ and force config_ update now */
+	const auto &enable = controls.get(controls::draft::BadPixelRemovalEnable);
+	const auto &strength = controls.get(controls::draft::BadPixelRemovalStrength);
+
+	if (enable) {
+		params_.badpixel.enable = *enable;
+		config_.badpixel.enable = params_.badpixel.enable;
+		config_.pending = true;
+		LOG(DcmippBadPixel, Debug) << "Updating Bad Pixel status to " << *enable;
+	}
+
+	if (strength) {
+		if (!isStrengthValid(*strength)) {
+			LOG(DcmippBadPixel, Error) << "Invalid Strength: " << *strength;
+			return;
+		}
+		params_.badpixel.strength = *strength;
+		if (!internal_.threshold) {
+			config_.badpixel.strength = params_.badpixel.strength;
+			config_.pending = true;
+		}
+		LOG(DcmippBadPixel, Debug) << "Updating strength to " << *strength;
+	}
+}
+
+void BadPixel::prepare(IPAContext &context,
+		       [[maybe_unused]] const uint32_t frame,
+		       [[maybe_unused]] IPAFrameContext &frameContext,
+		       stm32_dcmipp_params_cfg *params,
+		       [[maybe_unused]] ControlList &sensorControls,
+		       [[maybe_unused]] ControlList &ispControls)
+{
+	/* Copy the pending config to the isp_params. Update the IPAContext */
+	if (config_.pending) {
+		/* Configure Bad Pixel params */
+		params->module_cfg_update |= STM32_DCMIPP_ISP_BPR;
+		params->ctrls.bpr_cfg.en = config_.badpixel.enable;
+		params->ctrls.bpr_cfg.strength = config_.badpixel.strength;
+
+		/* Update context */
+		context.isp.badpixel = config_.badpixel;
+
+		/* Clear the pending request */
+		config_.pending = false;
+	}
+}
+
+const int32_t kBadPixelMeasures = 30;
+
+void BadPixel::process(IPAContext &context,
+		       [[maybe_unused]] const uint32_t frame,
+		       [[maybe_unused]] IPAFrameContext &frameContext,
+		       [[maybe_unused]] const stm32_dcmipp_stat_buf *stats,
+		       ControlList &metadata)
+{
+	/* Adjust strength according to threshold */
+	if (params_.badpixel.enable && internal_.threshold) {
+		/* Make kBadPixelMeasures measures before computing the average */
+		internal_.countAccu += stats->bad_pixel_count;
+		if (++internal_.measureNb == kBadPixelMeasures) {
+			uint8_t strength = context.isp.badpixel.strength;
+			internal_.countAccu /= kBadPixelMeasures;
+
+			/* Increase or decrease strength */
+			if (internal_.countAccu > internal_.threshold && strength > 0)
+				strength--;
+			else if (internal_.countAccu < internal_.threshold && strength < kStrengthMax - 1)
+				strength++;
+
+			/* Update config */
+			config_.badpixel.strength = strength;
+			config_.pending = true;
+			internal_.measureNb = 0;
+			internal_.countAccu = 0;
+		}
+	}
+
+	/* Set bad pixel metadata */
+	metadata.set(controls::draft::BadPixelRemovalEnable, config_.badpixel.enable);
+	metadata.set(controls::draft::BadPixelRemovalStrength, config_.badpixel.strength);
+	metadata.set(controls::draft::BadPixelRemovalThreshold, internal_.threshold);
+	metadata.set(controls::draft::BadPixelRemovalCount, stats->bad_pixel_count);
+}
+
+REGISTER_IPA_ALGORITHM(BadPixel, "BadPixel")
+
+} /* namespace ipa::dcmipp::algorithms */
+
+} /* namespace libcamera */
diff --git a/src/ipa/dcmipp/algorithms/badpixel.h b/src/ipa/dcmipp/algorithms/badpixel.h
new file mode 100644
index 00000000..0db7645a
--- /dev/null
+++ b/src/ipa/dcmipp/algorithms/badpixel.h
@@ -0,0 +1,50 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024 ST Microelectronics
+ *
+ * badpixel.h - STM32 DCMIPP Bad Pixel Removal
+ */
+
+#pragma once
+
+#include "algorithm.h"
+
+namespace libcamera {
+
+namespace ipa::dcmipp::algorithms {
+
+class BadPixel : public Algorithm
+{
+public:
+	BadPixel() = default;
+
+	int init(IPAContext &context, const YamlObject &tuningData) override;
+	int configure(IPAContext &context, const IPACameraSensorInfo &configInfo) override;
+	void queueRequest(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+			  const ControlList &controls) override;
+	void prepare(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+		     stm32_dcmipp_params_cfg *params, ControlList &sensorControls,
+		     ControlList &ispControls) override;
+	void process(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+		     const stm32_dcmipp_stat_buf *stats, ControlList &metadata) override;
+
+private:
+	struct algoParams {
+		struct IPAIspBadpixel badpixel;
+	} params_;
+
+	struct algoInternal {
+		int32_t threshold;
+		int32_t countAccu;
+		int32_t measureNb;
+	} internal_;
+
+	struct algoConfig {
+		bool pending;
+		struct IPAIspBadpixel badpixel;
+	} config_;
+};
+
+} /* namespace ipa::dcmipp::algorithms */
+
+} /* namespace libcamera */
diff --git a/src/ipa/dcmipp/algorithms/blc.cpp b/src/ipa/dcmipp/algorithms/blc.cpp
new file mode 100644
index 00000000..9b40dd5f
--- /dev/null
+++ b/src/ipa/dcmipp/algorithms/blc.cpp
@@ -0,0 +1,145 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024 ST Microelectronics
+ *
+ * blc.cpp - STM32 DCMIPP Black Level Correction
+ */
+
+#include "blc.h"
+
+#include <libcamera/base/log.h>
+#include <libcamera/control_ids.h>
+
+namespace libcamera {
+
+namespace ipa::dcmipp::algorithms {
+
+LOG_DEFINE_CATEGORY(DcmippBlc)
+
+static constexpr int kBLMin = 0;
+static constexpr int kBLMax = 255;
+static constexpr int kBLDef = 0;
+
+static bool isValid(int32_t level)
+{
+	return level >= kBLMin && level <= kBLMax;
+}
+
+int BlackLevelCorrection::init([[maybe_unused]] IPAContext &context, const YamlObject &tuningData)
+{
+	/* Parse Tuning Data to get algo parameters */
+	std::vector<int32_t> level = tuningData["Level"].getList<int32_t>().value_or(std::vector<int32_t>{});
+	if (!level.size()) {
+		params_.blackLevel.blcR = kBLDef;
+		params_.blackLevel.blcG = kBLDef;
+		params_.blackLevel.blcB = kBLDef;
+		params_.blackLevel.enable = false;
+	} else if (level.size() == 3) {
+		for (auto const &l : level)
+			if (!isValid(l)) {
+				LOG(DcmippBlc, Error) << "Invalid black level value: " << l;
+				return -EINVAL;
+			}
+		params_.blackLevel.blcR = level[0];
+		params_.blackLevel.blcG = level[1];
+		params_.blackLevel.blcB = level[2];
+		params_.blackLevel.enable = false;
+		params_.blackLevel.enable = tuningData["Enable"].get<bool>(true);
+	} else {
+		LOG(DcmippBlc, Error) << "Invalid nubmer of black levels";
+		return -EINVAL;
+	}
+
+	/* Configure exposed controls */
+	context.dcmippControls[&controls::draft::BlackLevelCorrectionEnable] = ControlInfo(false, true);
+	context.dcmippControls[&controls::draft::BlackLevelCorrectionLevels] = ControlInfo(kBLMin, kBLMax, kBLDef);
+
+	return 0;
+}
+
+int BlackLevelCorrection::configure([[maybe_unused]] IPAContext &context,
+				    [[maybe_unused]] const IPACameraSensorInfo &configInfo)
+{
+	/* Set the initial ISP/sensor values in the pending config */
+	config_.blackLevel = params_.blackLevel;
+	config_.pending = true;
+
+	return 0;
+}
+
+void BlackLevelCorrection::queueRequest([[maybe_unused]] IPAContext &context,
+					[[maybe_unused]] const uint32_t frame,
+					[[maybe_unused]] IPAFrameContext &frameContext,
+					const ControlList &controls)
+{
+	/* Update params_ and force config_ update now */
+	const auto &enable = controls.get(controls::draft::BlackLevelCorrectionEnable);
+	const auto &level = controls.get(controls::draft::BlackLevelCorrectionLevels);
+
+	if (enable) {
+		params_.blackLevel.enable = *enable;
+		config_.blackLevel.enable = params_.blackLevel.enable;
+		config_.pending = true;
+		LOG(DcmippBlc, Debug) << "Updating black level status to " << *enable;
+	}
+
+	if (level) {
+		for (auto const &l : *level)
+			if (!isValid(l)) {
+				LOG(DcmippBlc, Error) << "Invalid black level value: " << l;
+				return;
+			}
+		params_.blackLevel.blcR = (*level)[0];
+		params_.blackLevel.blcG = (*level)[1];
+		params_.blackLevel.blcB = (*level)[2];
+		config_.blackLevel.blcR = params_.blackLevel.blcR;
+		config_.blackLevel.blcG = params_.blackLevel.blcG;
+		config_.blackLevel.blcB = params_.blackLevel.blcB;
+		config_.pending = true;
+		LOG(DcmippBlc, Debug) << "Updating black level to " << (*level)[0] << "...";
+	}
+}
+
+void BlackLevelCorrection::prepare([[maybe_unused]] IPAContext &context,
+				   [[maybe_unused]] const uint32_t frame,
+				   [[maybe_unused]] IPAFrameContext &frameContext,
+				   stm32_dcmipp_params_cfg *params,
+				   [[maybe_unused]] ControlList &sensorControls,
+				   [[maybe_unused]] ControlList &ispControls)
+{
+	/* Copy the pending config to the isp_params. Update the IPAContext */
+	if (config_.pending) {
+		/* Configure Black Level params */
+		params->module_cfg_update |= STM32_DCMIPP_ISP_BLC;
+		params->ctrls.blc_cfg.blc_r = config_.blackLevel.blcR;
+		params->ctrls.blc_cfg.blc_g = config_.blackLevel.blcG;
+		params->ctrls.blc_cfg.blc_b = config_.blackLevel.blcB;
+		params->ctrls.blc_cfg.en = config_.blackLevel.enable;
+
+		/* Update context */
+		context.isp.blackLevel = config_.blackLevel;
+
+		/* Clear the pending request */
+		config_.pending = false;
+	}
+}
+
+void BlackLevelCorrection::process([[maybe_unused]] IPAContext &context,
+				   [[maybe_unused]] const uint32_t frame,
+				   [[maybe_unused]] IPAFrameContext &frameContext,
+				   [[maybe_unused]] const stm32_dcmipp_stat_buf *stats,
+				   ControlList &metadata)
+{
+	/* Set BlackLevel metadata */
+	metadata.set(controls::draft::BlackLevelCorrectionEnable, config_.blackLevel.enable);
+	metadata.set(controls::draft::BlackLevelCorrectionLevels,
+		     { static_cast<int32_t>(config_.blackLevel.blcR),
+		       static_cast<int32_t>(config_.blackLevel.blcG),
+		       static_cast<int32_t>(config_.blackLevel.blcB) });
+}
+
+REGISTER_IPA_ALGORITHM(BlackLevelCorrection, "BlackLevelCorrection")
+
+} /* namespace ipa::dcmipp::algorithms */
+
+} /* namespace libcamera */
diff --git a/src/ipa/dcmipp/algorithms/blc.h b/src/ipa/dcmipp/algorithms/blc.h
new file mode 100644
index 00000000..968d5ce3
--- /dev/null
+++ b/src/ipa/dcmipp/algorithms/blc.h
@@ -0,0 +1,44 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024 ST Microelectronics
+ *
+ * blc.h - STM32 DCMIPP Black Level Correction
+ */
+
+#pragma once
+
+#include "algorithm.h"
+
+namespace libcamera {
+
+namespace ipa::dcmipp::algorithms {
+
+class BlackLevelCorrection : public Algorithm
+{
+public:
+	BlackLevelCorrection() = default;
+
+	int init(IPAContext &context, const YamlObject &tuningData) override;
+	int configure(IPAContext &context, const IPACameraSensorInfo &configInfo) override;
+	void queueRequest(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+			  const ControlList &controls) override;
+	void prepare(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+		     stm32_dcmipp_params_cfg *params, ControlList &sensorControls,
+		     ControlList &ispControls) override;
+	void process(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+		     const stm32_dcmipp_stat_buf *stats, ControlList &metadata) override;
+
+private:
+	struct algoParams {
+		struct IPAIspBlackLevel blackLevel;
+	} params_;
+
+	struct algoConfig {
+		bool pending;
+		struct IPAIspBlackLevel blackLevel;
+	} config_;
+};
+
+} /* namespace ipa::dcmipp::algorithms */
+
+} /* namespace libcamera */
diff --git a/src/ipa/dcmipp/algorithms/contrast.cpp b/src/ipa/dcmipp/algorithms/contrast.cpp
new file mode 100644
index 00000000..412d9888
--- /dev/null
+++ b/src/ipa/dcmipp/algorithms/contrast.cpp
@@ -0,0 +1,141 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024 ST Microelectronics
+ *
+ * contrast.cpp - STM32 DCMIPP Contrast Enhancement
+ */
+
+#include "contrast.h"
+
+#include <libcamera/base/log.h>
+#include <libcamera/control_ids.h>
+
+namespace libcamera {
+
+namespace ipa::dcmipp::algorithms {
+
+LOG_DEFINE_CATEGORY(DcmippContrast)
+
+static constexpr uint32_t kPrecisionFactor = 100;
+static constexpr uint32_t kIdle = 16;
+static constexpr int kContrastSize = 9;
+static constexpr int kFactorMin = 0;
+static constexpr int kFactorMax = 394;
+static constexpr int kFactorDef = 0;
+
+static bool isFactorValid(int32_t factor)
+{
+	return factor >= kFactorMin && factor <= kFactorMax;
+}
+
+int Contrast::init([[maybe_unused]] IPAContext &context, const YamlObject &tuningData)
+{
+	/* Parse Tuning Data to get algo parameters */
+	/* ISP Contrast */
+	std::vector<int32_t> lum = tuningData["LuminanceFactor"].getList<int32_t>().value_or(std::vector<int32_t>{});
+	if (!lum.size()) {
+		memset(params_.contrast.coeff, kFactorDef, kNbContrastFactor * sizeof(params_.contrast.coeff[0]));
+		params_.contrast.enable = false;
+	} else if (lum.size() == kNbContrastFactor) {
+		for (auto const &l : lum)
+			if (!isFactorValid(l)) {
+				LOG(DcmippContrast, Error) << "Invalid luminance factor: " << l;
+				return -EINVAL;
+			}
+		for (unsigned int i = 0; i < kNbContrastFactor; i++)
+			params_.contrast.coeff[i] = lum[i];
+		params_.contrast.enable = tuningData["Enable"].get<bool>(true);
+	} else {
+		LOG(DcmippContrast, Error) << "Invalid LuminanceFactor";
+		return -EINVAL;
+	}
+
+	/* Configure exposed controls */
+	context.dcmippControls[&controls::draft::ContrastLuminanceEnable] = ControlInfo(false, true);
+	context.dcmippControls[&controls::draft::ContrastLuminance] = ControlInfo(0, 394, 0);
+
+	return 0;
+}
+
+int Contrast::configure([[maybe_unused]] IPAContext &context,
+			[[maybe_unused]] const IPACameraSensorInfo &configInfo)
+{
+	/* Set the initial ISP values in the pending config */
+	config_.contrast = params_.contrast;
+	config_.pending = true;
+
+	return 0;
+}
+
+void Contrast::queueRequest([[maybe_unused]] IPAContext &context,
+			    [[maybe_unused]] const uint32_t frame,
+			    [[maybe_unused]] IPAFrameContext &frameContext,
+			    const ControlList &controls)
+{
+	/* Update params_ and force config_ update now */
+	const auto &enable = controls.get(controls::draft::ContrastLuminanceEnable);
+	const auto &luminance = controls.get(controls::draft::ContrastLuminance);
+
+	if (enable) {
+		params_.contrast.enable = *enable;
+		config_.contrast.enable = params_.contrast.enable;
+		config_.pending = true;
+		LOG(DcmippContrast, Debug) << "Updating contrast status to " << *enable;
+	}
+
+	if (luminance) {
+		for (auto const &l : *luminance)
+			if (!isFactorValid(l)) {
+				LOG(DcmippContrast, Error) << "Invalid luminance factor: " << l;
+				return;
+			}
+		std::copy(std::begin(*luminance), std::end(*luminance), params_.contrast.coeff);
+		memcpy(config_.contrast.coeff, params_.contrast.coeff, sizeof(config_.contrast.coeff));
+		config_.pending = true;
+		LOG(DcmippContrast, Debug) << "Updating contrast status to " << (*luminance)[0] << "...";
+	}
+}
+
+void Contrast::prepare(IPAContext &context,
+		       [[maybe_unused]] const uint32_t frame,
+		       [[maybe_unused]] IPAFrameContext &frameContext,
+		       stm32_dcmipp_params_cfg *params,
+		       [[maybe_unused]] ControlList &sensorControls,
+		       [[maybe_unused]] ControlList &ispControls)
+{
+	/* Copy the pending config to the isp_params. Update the IPAContext */
+	if (config_.pending) {
+		/* Configure Contrast params */
+		params->module_cfg_update |= STM32_DCMIPP_ISP_CE;
+		params->ctrls.ce_cfg.en = config_.contrast.enable;
+		for (unsigned int i = 0; i < kNbContrastFactor; i++)
+			/* Convert factor (Unit = 100 for "x1.0") to register format (where 16 means "x1.0") */
+			params->ctrls.ce_cfg.lum[i] = (config_.contrast.coeff[i] * kIdle) / kPrecisionFactor;
+
+		/* Update context */
+		context.isp.contrast = config_.contrast;
+
+		/* Clear the pending request */
+		config_.pending = false;
+	}
+}
+
+void Contrast::process([[maybe_unused]] IPAContext &context,
+		       [[maybe_unused]] const uint32_t frame,
+		       [[maybe_unused]] IPAFrameContext &frameContext,
+		       [[maybe_unused]] const stm32_dcmipp_stat_buf *stats,
+		       ControlList &metadata)
+{
+	/* Set contrast metadata */
+	std::array<int32_t, kContrastSize> contrast;
+
+	metadata.set(controls::draft::ContrastLuminanceEnable, config_.contrast.enable);
+	std::copy(params_.contrast.coeff, params_.contrast.coeff + kContrastSize, contrast.begin());
+	metadata.set(controls::draft::ContrastLuminance, contrast);
+}
+
+REGISTER_IPA_ALGORITHM(Contrast, "Contrast")
+
+} /* namespace ipa::dcmipp::algorithms */
+
+} /* namespace libcamera */
diff --git a/src/ipa/dcmipp/algorithms/contrast.h b/src/ipa/dcmipp/algorithms/contrast.h
new file mode 100644
index 00000000..51dc85e7
--- /dev/null
+++ b/src/ipa/dcmipp/algorithms/contrast.h
@@ -0,0 +1,44 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024 ST Microelectronics
+ *
+ * contrast.h - STM32 DCMIPP Contrast Enhancement
+ */
+
+#pragma once
+
+#include "algorithm.h"
+
+namespace libcamera {
+
+namespace ipa::dcmipp::algorithms {
+
+class Contrast : public Algorithm
+{
+public:
+	Contrast() = default;
+
+	int init(IPAContext &context, const YamlObject &tuningData) override;
+	int configure(IPAContext &context, const IPACameraSensorInfo &configInfo) override;
+	void queueRequest(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+			  const ControlList &controls) override;
+	void prepare(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+		     stm32_dcmipp_params_cfg *params, ControlList &sensorControls,
+		     ControlList &ispControls) override;
+	void process(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+		     const stm32_dcmipp_stat_buf *stats, ControlList &metadata) override;
+
+private:
+	struct algoParams {
+		struct IPAIspContrast contrast;
+	} params_;
+
+	struct algoConfig {
+		bool pending;
+		struct IPAIspContrast contrast;
+	} config_;
+};
+
+} /* namespace ipa::dcmipp::algorithms */
+
+} /* namespace libcamera */
diff --git a/src/ipa/dcmipp/algorithms/demosaicing.cpp b/src/ipa/dcmipp/algorithms/demosaicing.cpp
new file mode 100644
index 00000000..b0c7915a
--- /dev/null
+++ b/src/ipa/dcmipp/algorithms/demosaicing.cpp
@@ -0,0 +1,146 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024 ST Microelectronics
+ *
+ * demosaicing.cpp - STM32 DCMIPP Demosaicing Filter
+ */
+
+#include "demosaicing.h"
+
+#include <libcamera/base/log.h>
+#include <libcamera/control_ids.h>
+
+namespace libcamera {
+
+namespace ipa::dcmipp::algorithms {
+
+LOG_DEFINE_CATEGORY(DcmippDemosaicing)
+
+static constexpr unsigned int kNbFilters = 4;
+static constexpr int kFilterMin = 0;
+static constexpr int kFilterMax = 7;
+static constexpr int kFilterDef = 0;
+
+static bool isValid(int32_t filter)
+{
+	return filter >= kFilterMin && filter <= kFilterMax;
+}
+
+int Demosaicing::init([[maybe_unused]] IPAContext &context, const YamlObject &tuningData)
+{
+	/* Parse Tuning Data to get algo parameters */
+	params_.demosaicing.enable = tuningData["Enable"].get<bool>(true);
+	/* ISP Demosaicing Filter */
+	std::vector<int32_t> filter = tuningData["Filter"].getList<int32_t>().value_or(std::vector<int32_t>(kNbFilters, kFilterDef));
+	if (filter.size() != kNbFilters) {
+		LOG(DcmippDemosaicing, Error) << "Invalid number of filters";
+		return -EINVAL;
+	}
+	for (auto const &f : filter)
+		if (!isValid(f)) {
+			LOG(DcmippDemosaicing, Error) << "Invalid filter value: " << f;
+			return -EINVAL;
+		}
+
+	params_.demosaicing.peak = filter[0];
+	params_.demosaicing.linev = filter[1];
+	params_.demosaicing.lineh = filter[2];
+	params_.demosaicing.edge = filter[3];
+
+	/* Configure exposed controls */
+	context.dcmippControls[&controls::draft::DemosaicingEnable] = ControlInfo(false, true);
+	context.dcmippControls[&controls::draft::DemosaicingFilter] = ControlInfo(kFilterMin, kFilterMax, kFilterDef);
+
+	return 0;
+}
+
+int Demosaicing::configure([[maybe_unused]] IPAContext &context,
+			   [[maybe_unused]] const IPACameraSensorInfo &configInfo)
+{
+	/* Set the initial ISP values in the pending config */
+	config_.demosaicing = params_.demosaicing;
+	config_.pending = true;
+
+	return 0;
+}
+
+void Demosaicing::queueRequest([[maybe_unused]] IPAContext &context,
+			       [[maybe_unused]] const uint32_t frame,
+			       [[maybe_unused]] IPAFrameContext &frameContext,
+			       const ControlList &controls)
+{
+	/* Update params_ and force config_ update now */
+	const auto &enable = controls.get(controls::draft::DemosaicingEnable);
+	const auto &filter = controls.get(controls::draft::DemosaicingFilter);
+
+	if (enable) {
+		params_.demosaicing.enable = *enable;
+		config_.demosaicing.enable = params_.demosaicing.enable;
+		config_.pending = true;
+		LOG(DcmippDemosaicing, Debug) << "Updating demosaicing status to " << *enable;
+	}
+
+	if (filter) {
+		for (auto const &f : *filter)
+			if (!isValid(f)) {
+				LOG(DcmippDemosaicing, Error) << "Invalid filter value: " << f;
+				return;
+			}
+		params_.demosaicing.peak = (*filter)[0];
+		params_.demosaicing.linev = (*filter)[1];
+		params_.demosaicing.lineh = (*filter)[2];
+		params_.demosaicing.edge = (*filter)[3];
+		config_.demosaicing.peak = params_.demosaicing.peak;
+		config_.demosaicing.linev = params_.demosaicing.linev;
+		config_.demosaicing.lineh = params_.demosaicing.lineh;
+		config_.demosaicing.edge = params_.demosaicing.edge;
+		config_.pending = true;
+		LOG(DcmippDemosaicing, Debug) << "Updating demosaicing filter to " << (*filter)[0] << "...";
+	}
+}
+
+void Demosaicing::prepare(IPAContext &context,
+			  [[maybe_unused]] const uint32_t frame,
+			  [[maybe_unused]] IPAFrameContext &frameContext,
+			  stm32_dcmipp_params_cfg *params,
+			  [[maybe_unused]] ControlList &sensorControls,
+			  [[maybe_unused]] ControlList &ispControls)
+{
+	/* Copy the pending config to the isp_params. Update the IPAContext */
+	if (config_.pending) {
+		/* Configure Demosaicing filter params */
+		params->module_cfg_update |= STM32_DCMIPP_ISP_DM;
+		params->ctrls.dm_cfg.en = config_.demosaicing.enable;
+		params->ctrls.dm_cfg.edge = config_.demosaicing.edge;
+		params->ctrls.dm_cfg.lineh = config_.demosaicing.lineh;
+		params->ctrls.dm_cfg.linev = config_.demosaicing.linev;
+		params->ctrls.dm_cfg.peak = config_.demosaicing.peak;
+
+		/* Update context */
+		context.isp.demosaicing = config_.demosaicing;
+
+		/* Clear the pending request */
+		config_.pending = false;
+	}
+}
+
+void Demosaicing::process([[maybe_unused]] IPAContext &context,
+			  [[maybe_unused]] const uint32_t frame,
+			  [[maybe_unused]] IPAFrameContext &frameContext,
+			  [[maybe_unused]] const stm32_dcmipp_stat_buf *stats,
+			  ControlList &metadata)
+{
+	/* Set demosaicing metadata */
+	metadata.set(controls::draft::DemosaicingEnable, config_.demosaicing.enable);
+	metadata.set(controls::draft::DemosaicingFilter,
+		     { static_cast<int32_t>(config_.demosaicing.peak),
+		       static_cast<int32_t>(config_.demosaicing.linev),
+		       static_cast<int32_t>(config_.demosaicing.lineh),
+		       static_cast<int32_t>(config_.demosaicing.edge) });
+}
+
+REGISTER_IPA_ALGORITHM(Demosaicing, "Demosaicing")
+
+} /* namespace ipa::dcmipp::algorithms */
+
+} /* namespace libcamera */
diff --git a/src/ipa/dcmipp/algorithms/demosaicing.h b/src/ipa/dcmipp/algorithms/demosaicing.h
new file mode 100644
index 00000000..9b407485
--- /dev/null
+++ b/src/ipa/dcmipp/algorithms/demosaicing.h
@@ -0,0 +1,44 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024 ST Microelectronics
+ *
+ * demosaicing.h - STM32 DCMIPP Deomsaicing Filter
+ */
+
+#pragma once
+
+#include "algorithm.h"
+
+namespace libcamera {
+
+namespace ipa::dcmipp::algorithms {
+
+class Demosaicing : public Algorithm
+{
+public:
+	Demosaicing() = default;
+
+	int init(IPAContext &context, const YamlObject &tuningData) override;
+	int configure(IPAContext &context, const IPACameraSensorInfo &configInfo) override;
+	void queueRequest(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+			  const ControlList &controls) override;
+	void prepare(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+		     stm32_dcmipp_params_cfg *params, ControlList &sensorControls,
+		     ControlList &ispControls) override;
+	void process(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+		     const stm32_dcmipp_stat_buf *stats, ControlList &metadata) override;
+
+private:
+	struct algoParams {
+		struct IPAIspDemosaicing demosaicing;
+	} params_;
+
+	struct algoConfig {
+		bool pending;
+		struct IPAIspDemosaicing demosaicing;
+	} config_;
+};
+
+} /* namespace ipa::dcmipp::algorithms */
+
+} /* namespace libcamera */
diff --git a/src/ipa/dcmipp/algorithms/meson.build b/src/ipa/dcmipp/algorithms/meson.build
new file mode 100644
index 00000000..5f4d10a1
--- /dev/null
+++ b/src/ipa/dcmipp/algorithms/meson.build
@@ -0,0 +1,11 @@
+# SPDX-License-Identifier: CC0-1.0
+
+dcmipp_ipa_algorithms = files([
+    'statistic.cpp',
+    'badpixel.cpp',
+    'blc.cpp',
+    'demosaicing.cpp',
+    'contrast.cpp',
+    'aec.cpp',
+    'awb.cpp',
+])
diff --git a/src/ipa/dcmipp/algorithms/statistic.cpp b/src/ipa/dcmipp/algorithms/statistic.cpp
new file mode 100644
index 00000000..4fe1812d
--- /dev/null
+++ b/src/ipa/dcmipp/algorithms/statistic.cpp
@@ -0,0 +1,212 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024 ST Microelectronics
+ *
+ * statistic.cpp - STM32 DCMIPP Statistic configuration
+ */
+
+#include "statistic.h"
+
+#include <libcamera/base/log.h>
+#include <libcamera/control_ids.h>
+
+namespace libcamera {
+
+namespace ipa::dcmipp::algorithms {
+
+LOG_DEFINE_CATEGORY(DcmippStatistic)
+
+enum StatProfile {
+	ProfileFull = 0,
+	ProfileAvgUp,
+	ProfileAvgDown
+};
+
+static constexpr int kBinsSize = 12;
+static constexpr int kSizeMin = 0;
+static constexpr int kSizeMax = 4094;
+static constexpr int kSizeDef = 0;
+static constexpr int kProfileMin = ProfileFull;
+static constexpr int kProfileMax = ProfileAvgDown;
+static constexpr int kProfileDef = ProfileFull;
+
+static bool isSizeValid(int32_t size)
+{
+	return size >= kSizeMin && size <= kSizeMax;
+}
+
+static bool isProfileValid(int32_t profile)
+{
+	return profile >= kProfileMin && profile <= kProfileMax;
+}
+
+static int32_t getCycleDuration(uint32_t profile)
+{
+	int32_t duration;
+
+	switch (profile) {
+	default:
+	case ProfileFull:
+		/* 10 requests to get all stats:  (up[1] + down[1]) * (avg[1] + bins[4]) */
+		duration = (1 + 1) * (1 + 4);
+		break;
+	case ProfileAvgUp:
+	case ProfileAvgDown:
+		/* 1 single request to get AVG for up or down */
+		duration = 1;
+	}
+	return duration;
+}
+
+static int32_t luminanceFromRgb(const __u32 RGB[3])
+{
+	return (int32_t)((3 * RGB[0] + 6 * RGB[1] + RGB[2]) / 10);
+}
+
+int Statistic::init([[maybe_unused]] IPAContext &context, const YamlObject &tuningData)
+{
+	/* Parse Tuning Data to get algo parameters */
+	/* ISP Statistic config */
+	params_.statistic.profile = tuningData["Profile"].get<uint32_t>(kProfileDef);
+	if (!isProfileValid(params_.statistic.profile)) {
+		LOG(DcmippStatistic, Error) << "Invalid Profile: " << params_.statistic.profile;
+		return -EINVAL;
+	}
+
+	std::vector<int32_t> rect = tuningData["Area"].getList<int32_t>().value_or(std::vector<int32_t>(4, kSizeDef));
+	if (rect.size() != 4) {
+		LOG(DcmippStatistic, Error) << "Invalid Area";
+		return -EINVAL;
+	}
+	for (auto const &s : rect)
+		if (!isSizeValid(s)) {
+			LOG(DcmippStatistic, Error) << "Invalid stat area";
+			return -EINVAL;
+		}
+	params_.statistic.area.x0 = rect[0];
+	params_.statistic.area.y0 = rect[1];
+	params_.statistic.area.xSize = rect[2];
+	params_.statistic.area.ySize = rect[3];
+
+	/* Configure exposed controls */
+	context.dcmippControls[&controls::draft::StatisticArea] = ControlInfo(Rectangle{}, Rectangle(kSizeMax, kSizeMax, kSizeMax, kSizeMax), Rectangle{});
+	context.dcmippControls[&controls::draft::StatisticProfile] = ControlInfo(0, 2, 0);
+
+	return 0;
+}
+
+int Statistic::configure([[maybe_unused]] IPAContext &context,
+			 [[maybe_unused]] const IPACameraSensorInfo &configInfo)
+{
+	/* Set the initial ISP values in the pending config */
+	config_.statistic = params_.statistic;
+	config_.pending = true;
+
+	return 0;
+}
+
+void Statistic::queueRequest([[maybe_unused]] IPAContext &context,
+			     [[maybe_unused]] const uint32_t frame,
+			     [[maybe_unused]] IPAFrameContext &frameContext,
+			     const ControlList &controls)
+{
+	/* Update params_ and force config_ update now */
+	const auto &profile = controls.get(controls::draft::StatisticProfile);
+	const auto &area = controls.get(controls::draft::StatisticArea);
+
+	if (profile) {
+		if (!isProfileValid(*profile)) {
+			LOG(DcmippStatistic, Error) << "Invalid Profile: " << *profile;
+			return;
+		}
+		params_.statistic.profile = *profile;
+		config_.statistic.profile = params_.statistic.profile;
+		config_.pending = true;
+		LOG(DcmippStatistic, Debug) << "Updating static profile to " << *profile;
+	}
+
+	if (area) {
+		if (!isSizeValid((*area).x) || !isSizeValid((*area).y) || !isSizeValid((*area).width) || !isSizeValid((*area).height)) {
+			LOG(DcmippStatistic, Error) << "Invalid stat area";
+			return;
+		}
+		params_.statistic.area.x0 = (*area).x;
+		params_.statistic.area.y0 = (*area).y;
+		params_.statistic.area.xSize = (*area).width;
+		params_.statistic.area.ySize = (*area).height;
+		config_.statistic.area = params_.statistic.area;
+		config_.pending = true;
+		LOG(DcmippStatistic, Debug) << "Updating static area to " << *area;
+	}
+}
+
+void Statistic::prepare(IPAContext &context,
+			[[maybe_unused]] const uint32_t frame,
+			[[maybe_unused]] IPAFrameContext &frameContext,
+			[[maybe_unused]] stm32_dcmipp_params_cfg *params,
+			[[maybe_unused]] ControlList &sensorControls,
+			ControlList &ispControls)
+{
+	/* Copy the pending config to the isp controls (not isp_params). Update the IPAContext */
+	if (config_.pending) {
+		/* Configure Statistic area */
+		Rectangle area(config_.statistic.area.x0, config_.statistic.area.y0,
+			       config_.statistic.area.xSize, config_.statistic.area.ySize);
+		ispControls.set(controls::draft::StatisticArea, area);
+		ispControls.set(controls::draft::StatisticProfile, config_.statistic.profile);
+
+		/* Update context */
+		context.isp.statistic = config_.statistic;
+
+		/* Stat Latency = 1 VSYNC (shadow register) + stat gathering cycle length */
+		context.info.ispStatLatency = getCycleDuration(config_.statistic.profile) + 1;
+
+		/* Clear the pending request */
+		config_.pending = false;
+	}
+}
+
+void Statistic::process([[maybe_unused]] IPAContext &context,
+			[[maybe_unused]] const uint32_t frame,
+			[[maybe_unused]] IPAFrameContext &frameContext,
+			const stm32_dcmipp_stat_buf *stats,
+			ControlList &metadata)
+{
+	/* Set statistic metadata */
+	Rectangle area(config_.statistic.area.x0, config_.statistic.area.y0,
+		       config_.statistic.area.xSize, config_.statistic.area.ySize);
+	metadata.set(controls::draft::StatisticArea, area);
+	metadata.set(controls::draft::StatisticProfile, config_.statistic.profile);
+
+	if ((config_.statistic.profile == ProfileAvgUp) ||
+	    (config_.statistic.profile == ProfileFull)) {
+		metadata.set(controls::draft::StatisticAverageUp,
+			     { static_cast<int32_t>(stats->pre.average_RGB[0]),
+			       static_cast<int32_t>(stats->pre.average_RGB[1]),
+			       static_cast<int32_t>(stats->pre.average_RGB[2]),
+			       luminanceFromRgb(stats->pre.average_RGB) });
+	}
+	if ((config_.statistic.profile == ProfileAvgDown) ||
+	    (config_.statistic.profile == ProfileFull)) {
+		metadata.set(controls::draft::StatisticAverageDown,
+			     { static_cast<int32_t>(stats->post.average_RGB[0]),
+			       static_cast<int32_t>(stats->post.average_RGB[1]),
+			       static_cast<int32_t>(stats->post.average_RGB[2]),
+			       luminanceFromRgb(stats->post.average_RGB) });
+	}
+	if (config_.statistic.profile == ProfileFull) {
+		std::array<int32_t, kBinsSize> bins;
+
+		std::copy(stats->pre.bins, stats->pre.bins + kBinsSize, bins.begin());
+		metadata.set(controls::draft::StatisticBinsUp, bins);
+
+		std::copy(stats->post.bins, stats->post.bins + kBinsSize, bins.begin());
+		metadata.set(controls::draft::StatisticBinsDown, bins);
+	}
+}
+
+REGISTER_IPA_ALGORITHM(Statistic, "Statistic")
+
+} /* namespace ipa::dcmipp::algorithms */
+
+} /* namespace libcamera */
diff --git a/src/ipa/dcmipp/algorithms/statistic.h b/src/ipa/dcmipp/algorithms/statistic.h
new file mode 100644
index 00000000..1185b1a6
--- /dev/null
+++ b/src/ipa/dcmipp/algorithms/statistic.h
@@ -0,0 +1,44 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024 ST Microelectronics
+ *
+ * statistic.h - STM32 DCMIPP Statistic configuration
+ */
+
+#pragma once
+
+#include "algorithm.h"
+
+namespace libcamera {
+
+namespace ipa::dcmipp::algorithms {
+
+class Statistic : public Algorithm
+{
+public:
+	Statistic() = default;
+
+	int init(IPAContext &context, const YamlObject &tuningData) override;
+	int configure(IPAContext &context, const IPACameraSensorInfo &configInfo) override;
+	void queueRequest(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+			  const ControlList &controls) override;
+	void prepare(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+		     stm32_dcmipp_params_cfg *params, ControlList &sensorControls,
+		     ControlList &ispControls) override;
+	void process(IPAContext &context, const uint32_t frame, IPAFrameContext &frameContext,
+		     const stm32_dcmipp_stat_buf *stats, ControlList &metadata) override;
+
+private:
+	struct algoParams {
+		struct IPAIspStatistic statistic;
+	} params_;
+
+	struct algoConfig {
+		bool pending;
+		struct IPAIspStatistic statistic;
+	} config_;
+};
+
+} /* namespace ipa::dcmipp::algorithms */
+
+} /* namespace libcamera */
diff --git a/src/ipa/dcmipp/data/imx335.yaml b/src/ipa/dcmipp/data/imx335.yaml
new file mode 100644
index 00000000..7edc2dc4
--- /dev/null
+++ b/src/ipa/dcmipp/data/imx335.yaml
@@ -0,0 +1,54 @@
+# Copyright (c) 2024 STMicroelectronics.
+# All rights reserved.
+#
+# This software is licensed under SLA0044 terms that can be found here:
+# https://www.st.com/resource/en/license_agreement/SLA0044.txt
+#
+# imx335 configuration file for the STM32 dcmipp IPA.
+#
+# THIS FILE WAS GENERATED BY THE STM32 ISP IQTune ON 2024-10-09 12:13:15
+#
+
+%YAML 1.1
+---
+version: 1
+algorithms:
+  - Aec:
+      AnalogueGain_dB: 0.0
+      ExposureTime: 6318
+      AeEnable: true
+      ExposureValue: 0.0
+  - Awb:
+      FixedGainEnable: true
+      FixedGainR: 1.77
+      FixedGainG: 1.0
+      FixedGainB: 2.35
+      FixedCconvEnable: true
+      FixedCconv: [155134500, -69370000, 13106000, -38671000, 167689800, -33936000, 5546200, -66769999, 159944200]
+      AwbEnable: true
+      ProfileName: ["IMX335-A", "IMX335-TL84", "IMX335-D50", "IMX335-D65", "Free Slot"]
+      RefColorTemp: [2856, 4000, 5000, 6500, 0]
+      GainR: [140000000, 177000000, 220000000, 245000000, 0]
+      GainG: [100000000, 100000000, 100000000, 100000000, 0]
+      GainB: [275000000, 235000000, 180000000, 155000000, 0]
+      Cconv: [151460000, -102340000, 50892000, -85991000, 210980000, -24984000, 25000000, -261000000, 341000000, 155134500, -69370000, 13106000, -38671000, 167689800, -33936000, 5546200, -66769999, 159944200, 180080000, -64840000, -15230000, -35550000, 169920000, -34380000, 9770000, -95700000, 185940000, 180080000, -64840000, -15230000, -35550000, 169920000, -34380000, 9770000, -95700000, 185940000, 0, 0, 0, 0, 0, 0, 0, 0, 0]
+  - BadPixel:
+      Enable: false
+      Strength: 0
+      Threhsold: 0
+  - BlackLevelCorrection:
+      Enable: true
+      Level: [12, 12, 12]
+  - Contrast:
+      Enable: false
+      LuminanceFactor: [100, 100, 100, 100, 100, 100, 100, 100, 100]
+  - Demosaicing:
+      Enable: true
+      Filter: [2, 4, 4, 6]
+  - Statistic:
+      Area: [648, 486, 1296, 972]
+      Profile: 2
+# NOTE : parameters of 'statRemoval' are not handled in libcamera
+# NOTE : parameters of 'decimation' are not handled in libcamera
+# NOTE : parameter 'demosaicing.type' is not handled in libcamera
+# NOTE : parameters of 'gamma' are not handled in libcamera
diff --git a/src/ipa/dcmipp/data/meson.build b/src/ipa/dcmipp/data/meson.build
new file mode 100644
index 00000000..2a4f455c
--- /dev/null
+++ b/src/ipa/dcmipp/data/meson.build
@@ -0,0 +1,9 @@
+# SPDX-License-Identifier: CC0-1.0
+
+conf_files = files([
+    'imx335.yaml',
+])
+
+install_data(conf_files,
+             install_dir : ipa_data_dir / 'dcmipp',
+             install_tag : 'runtime')
diff --git a/src/ipa/dcmipp/dcmipp.cpp b/src/ipa/dcmipp/dcmipp.cpp
new file mode 100644
index 00000000..566bf1dd
--- /dev/null
+++ b/src/ipa/dcmipp/dcmipp.cpp
@@ -0,0 +1,537 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024 ST Microelectronics
+ *
+ * dcmipp.cpp - STM32 DCMIPP Image Processing Algorithm module
+ */
+#include <cmath>
+
+#include <linux/v4l2-controls.h>
+
+#include <libcamera/base/file.h>
+#include <libcamera/base/log.h>
+
+#include <libcamera/control_ids.h>
+
+#include <libcamera/ipa/dcmipp_ipa_interface.h>
+#include <libcamera/ipa/ipa_interface.h>
+#include <libcamera/ipa/ipa_module_info.h>
+
+#include "libcamera/internal/mapped_framebuffer.h"
+#include "libcamera/internal/yaml_parser.h"
+
+#include "algorithms/algorithm.h"
+#include "libipa/camera_sensor_helper.h"
+#include "linux/stm32-dcmipp-config.h"
+
+#include "ipa_context.h"
+#include "module.h"
+
+namespace libcamera {
+
+LOG_DEFINE_CATEGORY(IPADcmipp)
+
+namespace ipa::dcmipp {
+
+class IPADcmipp : public IPADcmippInterface, public Module
+{
+public:
+	IPADcmipp();
+
+	int init(const IPASettings &settings, unsigned int hwRevision,
+		 const IPACameraSensorInfo &sensorInfo, const ControlInfoMap &sensorControls,
+		 ControlInfoMap *ipaControls) override;
+
+	int start() override;
+	void stop() override;
+
+	int configure(const IPACameraSensorInfo &sensorInfo, const ControlInfoMap &sensorControls,
+		      uint32_t decimation, ControlInfoMap *ipaControls) override;
+
+	void mapBuffers(const std::vector<IPABuffer> &buffers) override;
+	void unmapBuffers(const std::vector<unsigned int> &ids) override;
+
+	void processStatsBuffer(uint32_t frame, uint32_t bufferId) override;
+	void fillParamsBuffer(uint32_t frame, uint32_t bufferId) override;
+	void queueRequest(uint32_t frame, const ControlList &controls) override;
+
+protected:
+	std::string logPrefix() const override;
+
+private:
+	float linearTodB(float gain);
+	float dBToLinear(float gain);
+	void convertControls(ControlList &controls, ControlList &v4l2Controls);
+	void setSensorProperties(const IPACameraSensorInfo &sensorInfo,
+				 const ControlInfoMap &sensorControls);
+	void updateControls(ControlInfoMap *ipaControls);
+	void logConfig(struct stm32_dcmipp_params_cfg *isp_params, ControlList &sensorControls,
+		       ControlList &ispControls);
+	float exposureFactor(struct stm32_dcmipp_isp_ex_cfg *exp, int comp);
+	float cconvCoeff(__u16 reg);
+
+	std::map<unsigned int, FrameBuffer> buffers_;
+	std::map<unsigned int, MappedFrameBuffer> mappedBuffers_;
+
+	ControlInfoMap sensorControls_;
+
+	std::unique_ptr<CameraSensorHelper> camHelper_;
+
+	struct IPAContext context_;
+	struct IPAFrameContext frameContext_; /* not used, kept for compatibility with module */
+};
+
+IPADcmipp::IPADcmipp()
+	: context_({})
+{
+}
+
+std::string IPADcmipp::logPrefix() const
+{
+	return "DCMIPP";
+}
+
+int IPADcmipp::init(const IPASettings &settings, unsigned int hwRevision,
+		    const IPACameraSensorInfo &sensorInfo, const ControlInfoMap &sensorControls,
+		    ControlInfoMap *ipaControls)
+{
+	LOG(IPADcmipp, Debug) << __func__;
+
+	context_ = {};
+
+	context_.info.hwRevision = hwRevision;
+	sensorControls_ = sensorControls;
+	camHelper_ = CameraSensorHelperFactoryBase::create(settings.sensorModel);
+	if (!camHelper_)
+		LOG(IPADcmipp, Warning) << "No camera sensor helper for " << settings.sensorModel;
+	context_.info.sensorStatLatency = 1;
+
+	/* Get sensor exposure/time properties */
+	setSensorProperties(sensorInfo, sensorControls);
+
+	/* Load and parse the tuning data file */
+	if (!settings.configurationFile.empty()) {
+		LOG(IPADcmipp, Debug) << "Parsing IPA settings from " << settings.configurationFile;
+		File file(settings.configurationFile);
+		if (!file.open(File::OpenModeFlag::ReadOnly)) {
+			int ret = file.error();
+			LOG(IPADcmipp, Error) << "Failed to open " << settings.configurationFile << ": "
+					      << strerror(-ret);
+			return ret;
+		}
+
+		std::unique_ptr<libcamera::YamlObject> data = YamlParser::parse(file);
+		if (!data)
+			return -EINVAL;
+		int ret = createAlgorithms(context_, (*data)["algorithms"]);
+		if (ret)
+			return ret;
+	}
+
+	/* Set controls supported by the algorithms */
+	updateControls(ipaControls);
+
+	return 0;
+}
+
+int IPADcmipp::start()
+{
+	LOG(IPADcmipp, Debug) << __func__;
+
+	/* Apply the sensors settings before capturing the first frame */
+	ControlList v4l2SensorControls(sensorControls_), sensorControls;
+	sensorControls.set(controls::draft::AnalogueGain_dB, context_.sensor.gain);
+	sensorControls.set(controls::ExposureTime, context_.sensor.exposure);
+	convertControls(sensorControls, v4l2SensorControls);
+	setSensorControls.emit(0, v4l2SensorControls);
+
+	return 0;
+}
+
+void IPADcmipp::stop()
+{
+	LOG(IPADcmipp, Debug) << __func__;
+}
+
+int IPADcmipp::configure(const IPACameraSensorInfo &sensorInfo,
+			 const ControlInfoMap &sensorControls,
+			 uint32_t decimation,
+			 ControlInfoMap *ipaControls)
+{
+	LOG(IPADcmipp, Debug) << __func__;
+
+	/* Get sensor exposure/time properties */
+	setSensorProperties(sensorInfo, sensorControls);
+
+	/* Configure algorithms */
+	for (auto const &algo : algorithms()) {
+		int ret = algo->configure(context_, sensorInfo);
+		if (ret) {
+			LOG(IPADcmipp, Error) << "Failed to configure algorithm: " << strerror(ret);
+			return ret;
+		}
+	}
+
+	context_.isp.decimationRatio = decimation;
+	context_.info.sensorBitsPerPixel = sensorInfo.bitsPerPixel;
+
+	/* Update the camera controls using the new sensor settings. */
+	updateControls(ipaControls);
+
+	return 0;
+}
+
+void IPADcmipp::mapBuffers(const std::vector<IPABuffer> &buffers)
+{
+	LOG(IPADcmipp, Debug) << __func__;
+
+	for (const IPABuffer &buffer : buffers) {
+		auto elem = buffers_.emplace(std::piecewise_construct,
+					     std::forward_as_tuple(buffer.id),
+					     std::forward_as_tuple(buffer.planes));
+		const FrameBuffer &fb = elem.first->second;
+
+		MappedFrameBuffer mappedBuffer(&fb, MappedFrameBuffer::MapFlag::ReadWrite);
+		if (!mappedBuffer.isValid())
+			LOG(IPADcmipp, Error) << "Failed to mmap buffer: " << strerror(mappedBuffer.error());
+
+		mappedBuffers_.emplace(buffer.id, std::move(mappedBuffer));
+	}
+}
+
+void IPADcmipp::unmapBuffers(const std::vector<unsigned int> &ids)
+{
+	LOG(IPADcmipp, Debug) << __func__;
+
+	for (unsigned int id : ids) {
+		const auto fb = buffers_.find(id);
+		if (fb == buffers_.end())
+			continue;
+
+		mappedBuffers_.erase(id);
+		buffers_.erase(id);
+	}
+}
+
+void IPADcmipp::queueRequest(uint32_t frame, const ControlList &controls)
+{
+	LOG(IPADcmipp, Debug) << __func__ << " frame: " << frame;
+
+	/* Send request to algorithms */
+	for (auto const &algo : algorithms())
+		algo->queueRequest(context_, frame, frameContext_, controls);
+}
+
+void IPADcmipp::processStatsBuffer(uint32_t frame, uint32_t bufferId)
+{
+	LOG(IPADcmipp, Debug) << __func__ << " frame: " << frame << " bufferId: " << bufferId;
+
+	/* Check bufferId validity */
+	auto it = buffers_.find(bufferId);
+	if (it == buffers_.end()) {
+		LOG(IPADcmipp, Error) << "Could not find stats buffer";
+		return;
+	}
+
+	/* Get buffer */
+	struct stm32_dcmipp_stat_buf *stats = reinterpret_cast<struct stm32_dcmipp_stat_buf *>(
+		mappedBuffers_.at(bufferId).planes()[0].data());
+
+	/* Ask algo to process stats */
+	LOG(IPADcmipp, Debug) << "Calling algo process";
+	ControlList metadata;
+	for (auto const &algo : algorithms())
+		algo->process(context_, frame, frameContext_, stats, metadata);
+
+	/* Add additional information */
+	metadata.set(controls::draft::IspDecimationRatio, context_.isp.decimationRatio);
+	metadata.set(controls::draft::SensorBitsPerPixel, context_.info.sensorBitsPerPixel);
+	metadata.set(controls::draft::PipelineHwRevision, context_.info.hwRevision);
+
+	/* Send metadata (controls) */
+	metadataReady.emit(frame, metadata);
+
+	/* Inform that the buffer can be freed now */
+	statsBufferProcessed.emit(bufferId);
+}
+
+void IPADcmipp::fillParamsBuffer(uint32_t frame, uint32_t bufferId)
+{
+	LOG(IPADcmipp, Debug) << __func__ << " frame: " << frame << " bufferId: " << bufferId;
+
+	/* Check bufferId validity */
+	auto it = buffers_.find(bufferId);
+	if (it == buffers_.end()) {
+		LOG(IPADcmipp, Error) << "Could not find parameter buffer";
+		return;
+	}
+
+	/* Get buffer */
+	struct stm32_dcmipp_params_cfg *isp_params = reinterpret_cast<struct stm32_dcmipp_params_cfg *>(
+		mappedBuffers_.at(bufferId).planes()[0].data());
+
+	/* Ask algo to provide new configuration */
+	ControlList ispControls, sensorControls;
+	memset(isp_params, 0, sizeof(struct stm32_dcmipp_params_cfg));
+
+	LOG(IPADcmipp, Debug) << "Calling algo prepare";
+	for (auto const &a : algorithms()) {
+		Algorithm *algo = static_cast<Algorithm *>(a.get());
+		algo->prepare(context_, frame, frameContext_, isp_params, sensorControls, ispControls);
+	}
+
+	/* Log new isp and sensor config */
+	logConfig(isp_params, sensorControls, ispControls);
+
+	/* Inform that the sensor config can be applied */
+	ControlList v4l2SensorControls(sensorControls_);
+	convertControls(sensorControls, v4l2SensorControls);
+	setSensorControls.emit(0, v4l2SensorControls);
+
+	/* Inform that the buffer can be applied for ISP HW update (buff params + optional v4l2 ctrl) */
+	if (!ispControls.empty()) {
+		ControlList v4l2IspControls;
+		convertControls(ispControls, v4l2IspControls);
+		setIspControls.emit(0, v4l2IspControls);
+	}
+	paramsBufferReady.emit(bufferId);
+}
+
+float IPADcmipp::linearTodB(float gain)
+{
+	return 20 * std::log10(gain);
+}
+
+float IPADcmipp::dBToLinear(float gain)
+{
+	return std::pow(10, gain / 20);
+}
+
+void IPADcmipp::convertControls(ControlList &controls, ControlList &v4l2Controls)
+{
+	/* Converts exposure to V4L2 control unit (number of lines) */
+	const auto &exposure = controls.get(controls::ExposureTime);
+	if (exposure)
+		v4l2Controls.set(V4L2_CID_EXPOSURE, (int32_t)(*exposure / context_.info.sensorLineDuration_us));
+
+	/* Converts gain to V4L2 control unit (eg 0.3 dB step for IMX335 sensor) */
+	const auto &gain = controls.get(controls::draft::AnalogueGain_dB);
+	if (gain && camHelper_) {
+		float gainLinear = dBToLinear(*gain);
+		v4l2Controls.set(V4L2_CID_ANALOGUE_GAIN, (int32_t)(camHelper_->gainCode(gainLinear)));
+	}
+
+	/* Converts statistic area */
+	const auto &area = controls.get(controls::draft::StatisticArea);
+	if (area) {
+		struct v4l2_ctrl_isp_stat_region region;
+
+		region.nb_regions = 1;
+		region.top[0] = area->y / context_.isp.decimationRatio;
+		region.left[0] = area->x / context_.isp.decimationRatio;
+		region.width[0] = area->width / context_.isp.decimationRatio;
+		region.height[0] = area->height / context_.isp.decimationRatio;
+
+		ControlValue c(Span<const uint8_t>{ reinterpret_cast<uint8_t *>(&region), sizeof(region) });
+		v4l2Controls.set(V4L2_CID_ISP_STAT_REGION, c);
+	}
+
+	/* Converts statistic profile */
+	const auto &profile = controls.get(controls::draft::StatisticProfile);
+	if (profile)
+		v4l2Controls.set(V4L2_CID_ISP_STAT_PROFILE, *profile);
+}
+
+void IPADcmipp::setSensorProperties(const IPACameraSensorInfo &sensorInfo,
+				    const ControlInfoMap &sensorControls)
+{
+	/* Compute sensor exposure time properties */
+	const ControlInfo &v4l2Exposure = sensorControls.find(V4L2_CID_EXPOSURE)->second;
+	double lineDuration_us = sensorInfo.minLineLength / (sensorInfo.pixelRate / 1000000.0f);
+	context_.info.sensorLineDuration_us = lineDuration_us;
+	context_.info.sensorExposureMin = v4l2Exposure.min().get<int32_t>() * lineDuration_us;
+	context_.info.sensorExposureMax = v4l2Exposure.max().get<int32_t>() * lineDuration_us;
+	context_.info.sensorExposureDef = v4l2Exposure.def().get<int32_t>() * lineDuration_us;
+
+	/* Compute sensor analogue gain properties */
+	if (camHelper_) {
+		const ControlInfo &v4l2Gain = sensorControls.find(V4L2_CID_ANALOGUE_GAIN)->second;
+		context_.info.sensorGainMin = linearTodB(camHelper_->gain(v4l2Gain.min().get<int32_t>()));
+		context_.info.sensorGainMax = linearTodB(camHelper_->gain(v4l2Gain.max().get<int32_t>()));
+		context_.info.sensorGainDef = linearTodB(camHelper_->gain(v4l2Gain.def().get<int32_t>()));
+	}
+
+	/* Compute frame duration properties */
+	const ControlInfo &v4l2HBlank = sensorControls.find(V4L2_CID_HBLANK)->second;
+	const ControlInfo &v4l2VBlank = sensorControls.find(V4L2_CID_VBLANK)->second;
+
+	uint32_t hblank = v4l2HBlank.def().get<int32_t>();
+	uint32_t lineLength = sensorInfo.outputSize.width + hblank;
+	uint32_t sizeHeight = sensorInfo.outputSize.height;
+
+	uint64_t minFrameSize = (uint64_t)(v4l2VBlank.min().get<int32_t>() + sizeHeight) * lineLength;
+	uint64_t maxFrameSize = (uint64_t)(v4l2VBlank.max().get<int32_t>() + sizeHeight) * lineLength;
+	uint64_t defFrameSize = (uint64_t)(v4l2VBlank.def().get<int32_t>() + sizeHeight) * lineLength;
+
+	context_.info.frameDurationsMin = minFrameSize / (sensorInfo.pixelRate / 1000000U);
+	context_.info.frameDurationsMax = maxFrameSize / (sensorInfo.pixelRate / 1000000U);
+	context_.info.frameDurationsDef = defFrameSize / (sensorInfo.pixelRate / 1000000U);
+}
+
+void IPADcmipp::updateControls(ControlInfoMap *ipaControls)
+{
+	ControlInfoMap::Map ctrlMap = context_.dcmippControls;
+
+	/* Add the frame duration limits */
+	ctrlMap.emplace(std::piecewise_construct,
+			std::forward_as_tuple(&controls::FrameDurationLimits),
+			std::forward_as_tuple(context_.info.frameDurationsMin,
+					      context_.info.frameDurationsMax,
+					      context_.info.frameDurationsDef));
+
+	*ipaControls = ControlInfoMap(std::move(ctrlMap), controls::controls);
+}
+
+void IPADcmipp::logConfig(struct stm32_dcmipp_params_cfg *p, ControlList &sensorControls,
+			  ControlList &ispControls)
+{
+	if (p->module_cfg_update & STM32_DCMIPP_ISP_BPR)
+		LOG(IPADcmipp, Debug) << "ISP update - BAD PIXEL: "
+				      << (p->ctrls.bpr_cfg.en ? "enabled" : "disabled") << " ("
+				      << p->ctrls.bpr_cfg.strength << ")";
+
+	if (p->module_cfg_update & STM32_DCMIPP_ISP_BLC)
+		LOG(IPADcmipp, Debug) << "ISP update - BLACK LEVEL: "
+				      << (p->ctrls.blc_cfg.en ? "enabled" : "disabled") << " ("
+				      << (int)p->ctrls.blc_cfg.blc_r << " / "
+				      << (int)p->ctrls.blc_cfg.blc_g << " / "
+				      << (int)p->ctrls.blc_cfg.blc_b << ")";
+
+	if (p->module_cfg_update & STM32_DCMIPP_ISP_EX)
+		LOG(IPADcmipp, Debug) << "ISP update - EXPOSURE: "
+				      << (p->ctrls.ex_cfg.en ? "enabled" : "disabled") << " ("
+				      << "R x" << exposureFactor(&p->ctrls.ex_cfg, 0) << " /"
+				      << "G x" << exposureFactor(&p->ctrls.ex_cfg, 1) << " /"
+				      << "B x" << exposureFactor(&p->ctrls.ex_cfg, 2) << ")";
+
+	if (p->module_cfg_update & STM32_DCMIPP_ISP_CC)
+		LOG(IPADcmipp, Debug) << "ISP update - COLOR CONVERSION: "
+				      << (p->ctrls.cc_cfg.en ? "enabled" : "disabled") << " ("
+				      << " (" << cconvCoeff(p->ctrls.cc_cfg.rr)
+				      << " , " << cconvCoeff(p->ctrls.cc_cfg.rg)
+				      << " , " << cconvCoeff(p->ctrls.cc_cfg.rb)
+				      << ") , (" << cconvCoeff(p->ctrls.cc_cfg.gr)
+				      << " , " << cconvCoeff(p->ctrls.cc_cfg.gg)
+				      << " , " << cconvCoeff(p->ctrls.cc_cfg.gb)
+				      << ") , (" << cconvCoeff(p->ctrls.cc_cfg.br)
+				      << " , " << cconvCoeff(p->ctrls.cc_cfg.bg)
+				      << " , " << cconvCoeff(p->ctrls.cc_cfg.bb) << ")";
+
+	if (p->module_cfg_update & STM32_DCMIPP_ISP_DM)
+		LOG(IPADcmipp, Debug) << "ISP update - DEMOSAICING: "
+				      << (p->ctrls.dm_cfg.en ? "enabled" : "disabled") << " ("
+				      << (int)p->ctrls.dm_cfg.edge << " / "
+				      << (int)p->ctrls.dm_cfg.lineh << " / "
+				      << (int)p->ctrls.dm_cfg.linev << " / "
+				      << (int)p->ctrls.dm_cfg.peak;
+
+	if (p->module_cfg_update & STM32_DCMIPP_ISP_CE)
+		LOG(IPADcmipp, Debug) << "ISP update - CONTRAST: "
+				      << (p->ctrls.ce_cfg.en ? "enabled" : "disabled") << " ("
+				      << (float)p->ctrls.ce_cfg.lum[0] / 16 << ", "
+				      << (float)p->ctrls.ce_cfg.lum[1] / 16 << ", "
+				      << (float)p->ctrls.ce_cfg.lum[2] / 16 << ", "
+				      << (float)p->ctrls.ce_cfg.lum[3] / 16 << ", "
+				      << (float)p->ctrls.ce_cfg.lum[4] / 16 << ", "
+				      << (float)p->ctrls.ce_cfg.lum[5] / 16 << ", "
+				      << (float)p->ctrls.ce_cfg.lum[6] / 16 << ", "
+				      << (float)p->ctrls.ce_cfg.lum[7] / 16 << ", "
+				      << (float)p->ctrls.ce_cfg.lum[8] / 16 << ")";
+
+	/* ISP control updates */
+	const auto &area = ispControls.get(controls::draft::StatisticArea);
+	if (area)
+		LOG(IPADcmipp, Debug) << "ISP update - STAT AREA: ("
+				      << area->width << " x "
+				      << area->height << ") @ ("
+				      << area->x << ", "
+				      << area->y << ")";
+
+	const auto &profile = ispControls.get(controls::draft::StatisticProfile);
+	if (profile)
+		LOG(IPADcmipp, Debug) << "ISP update - STAT PROFILE: " << *profile;
+
+	/* Sensor Updates (exposure and gain) */
+	const auto &exposure = sensorControls.get(controls::ExposureTime);
+	if (exposure)
+		LOG(IPADcmipp, Debug) << "SENSOR update - EXPOSURE: " << *exposure << " us";
+
+	const auto &gain = sensorControls.get(controls::draft::AnalogueGain_dB);
+	if (gain)
+		LOG(IPADcmipp, Debug) << "SENSOR update - GAIN: " << *gain << " dB";
+}
+
+float IPADcmipp::exposureFactor(struct stm32_dcmipp_isp_ex_cfg *exp, int comp)
+{
+	/* Convert Shift + Multiplier to Factor */
+	uint32_t shift, mult;
+
+	switch (comp) {
+	default:
+	case 0:
+		shift = exp->shift_r;
+		mult = exp->mult_r;
+		break;
+	case 1:
+		shift = exp->shift_g;
+		mult = exp->mult_g;
+		break;
+	case 2:
+		shift = exp->shift_b;
+		mult = exp->mult_b;
+		break;
+	}
+	float factor = 1 << shift;
+	factor = (factor * mult) / 128;
+	return factor;
+}
+
+float IPADcmipp::cconvCoeff(__u16 reg)
+{
+	/* Convert from register format to float format */
+	float coeff;
+
+	if (reg & 0x400) {
+		int32_t val = reg;
+		val = (val - 1) ^ 0x7FF;
+		coeff = -(float)val / 256;
+	} else {
+		coeff = (float)reg / 256;
+	}
+
+	return coeff;
+}
+
+} /* namespace ipa::dcmipp */
+
+/*
+ * External IPA module interface
+ */
+
+extern "C" {
+const struct IPAModuleInfo ipaModuleInfo = {
+	IPA_MODULE_API_VERSION,
+	0,
+	"PipelineHandlerDcmipp",
+	"dcmipp",
+};
+
+IPAInterface *ipaCreate()
+{
+	LOG(IPADcmipp, Debug) << __func__;
+
+	return new ipa::dcmipp::IPADcmipp();
+}
+}
+
+} /* namespace libcamera */
diff --git a/src/ipa/dcmipp/ipa_context.h b/src/ipa/dcmipp/ipa_context.h
new file mode 100644
index 00000000..1e85b6a9
--- /dev/null
+++ b/src/ipa/dcmipp/ipa_context.h
@@ -0,0 +1,127 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024 ST Microelectronics
+ *
+ * ipa_context.h - STM32 DCMIPP IPA Context
+ */
+
+#pragma once
+
+#include <stdint.h>
+
+namespace libcamera {
+
+namespace ipa::dcmipp {
+
+static constexpr unsigned int kNbContrastFactor = 9;
+
+/* Sensor config */
+struct IPASensor {
+	double gain; /* Analogue gain in dB */
+	int32_t exposure; /* Exposure time in microseconds */
+};
+
+/* ISP Statistic */
+struct IPAIspStatistic {
+	struct { /* Coordinates */
+		uint32_t x0;
+		uint32_t y0;
+		uint32_t xSize;
+		uint32_t ySize;
+	} area;
+	uint32_t profile; /* Reported Stats (0:Full 1:AvgUp 2:AvgDown) */
+};
+
+/* ISP Bad pixel */
+struct IPAIspBadpixel {
+	uint8_t enable; /* Enable or disable */
+	uint8_t strength; /* Strength of the bad pixel removal algorithm */
+};
+
+/* ISP Black Level */
+struct IPAIspBlackLevel {
+	uint8_t enable; /* Enable or disable */
+	uint8_t blcR; /* Level offset for the red component */
+	uint8_t blcG; /* Level offset for the green component */
+	uint8_t blcB; /* Level offset for the blue component */
+};
+
+/* ISP Demosaicing */
+struct IPAIspDemosaicing {
+	uint8_t enable; /* Enable or disable */
+	uint8_t edge; /* Edge detection strength */
+	uint8_t lineh; /* Horizontal line detection strength */
+	uint8_t linev; /* Vertical line detection strength */
+	uint8_t peak; /* Peak detection strength */
+};
+
+/* ISP Contrast */
+struct IPAIspContrast {
+	uint8_t enable; /* Enable or disable */
+	uint32_t coeff[kNbContrastFactor]; /* Luminance amplification factor. Unit = 100 for "x1.0" */
+};
+
+/* ISP Gain ('exposure') */
+struct IPAIspGain {
+	uint8_t enable; /* Enable or disable */
+	uint32_t gainR; /* Gain of the red component. Unit = 100000000 for "x1.0", 150000000 for "x1.5". Max gain is "x16" */
+	uint32_t gainG; /* Gain of the green component */
+	uint32_t gainB; /* Gain of the blue component */
+};
+
+/* ISP Color Conversion */
+struct IPAIspColorConv {
+	uint8_t enable; /* Enable or disable */
+	int32_t coeff[3][3]; /* 3x3 RGB to RGB matrix coefficients. Unit = 100000000 for "x1.0", -150000000 for "x-1.5". Range is "x-4.0" to "x4.0" */
+};
+
+/* IPA context */
+struct IPAContext {
+	/* ISP config */
+	struct IPAIsp {
+		struct IPAIspStatistic statistic;
+		struct IPAIspBadpixel badpixel;
+		struct IPAIspBlackLevel blackLevel;
+		struct IPAIspDemosaicing demosaicing;
+		struct IPAIspContrast contrast;
+		struct IPAIspGain gain;
+		struct IPAIspColorConv cconv;
+		uint32_t decimationRatio;
+	} isp;
+
+	/* Sensor config */
+	struct IPASensor sensor;
+
+	/* General information */
+	struct IPAInfo {
+		uint8_t AECEnable; /* AEC algo enable or disable */
+		uint32_t AECExposureTarget; /* AEC Exposure Target */
+		uint8_t AWBEnable; /* AWB algo enable or disable */
+		uint32_t CCT; /* Estimated Correlated Color Temperature */
+		int32_t ispStatLatency; /* Nb of Vsync to get stats after ISP update */
+		int32_t sensorStatLatency; /* Nb of Vsync to get stats after sensor update */
+		uint32_t sensorBitsPerPixel; /* Nb of bpp from the sensor */
+		uint32_t hwRevision; /* DCMIPP HW version */
+		double sensorGainMin; /* Sensor min analogue gain in dB */
+		double sensorGainMax; /* Sensor max analogue gain in dB */
+		double sensorGainDef; /* Sensor default analogue gain in dB */
+		double sensorLineDuration_us; /* Sensor line duration in microseconds */
+		int32_t sensorExposureMin; /* Sensor min exposure time in microseconds */
+		int32_t sensorExposureMax; /* Sensor max exposure time in microseconds */
+		int32_t sensorExposureDef; /* Sensor default exposure time in microseconds */
+		int64_t frameDurationsMin; /* Min frame duration in microseconds */
+		int64_t frameDurationsMax; /* Max frame duration in microseconds */
+		int64_t frameDurationsDef; /* Default frame duration in microseconds */
+	} info;
+
+	/* Supported controls */
+	ControlInfoMap::Map dcmippControls;
+};
+
+/* Frame context, not used for the time being. Declaration required to use module */
+struct IPAFrameContext {
+};
+
+} /* namespace ipa::dcmipp */
+
+} /* namespace libcamera */
diff --git a/src/ipa/dcmipp/meson.build b/src/ipa/dcmipp/meson.build
new file mode 100644
index 00000000..911372d0
--- /dev/null
+++ b/src/ipa/dcmipp/meson.build
@@ -0,0 +1,39 @@
+# SPDX-License-Identifier: CC0-1.0
+
+subdir('algorithms')
+subdir('data')
+
+ipa_name = 'ipa_dcmipp'
+
+dcmipp_ipa_sources = files([
+    'dcmipp.cpp',
+])
+
+dcmipp_ipa_sources += dcmipp_ipa_algorithms
+
+dcmipp_cpp_arguments = []
+
+if get_option('evision_algo')
+    dcmipp_cpp_arguments += ['-DEVISION_ALGO_ENABLED']
+endif
+
+mod = shared_module(ipa_name,
+                    [dcmipp_ipa_sources, libcamera_generated_ipa_headers],
+                    name_prefix : '',
+                    include_directories : [ipa_includes, libipa_includes],
+                    dependencies : libcamera_private,
+                    cpp_args : dcmipp_cpp_arguments,
+                    link_with : libipa,
+                    install : true,
+                    install_dir : ipa_install_dir)
+
+if ipa_sign_module
+    custom_target(ipa_name + '.so.sign',
+                  input : mod,
+                  output : ipa_name + '.so.sign',
+                  command : [ipa_sign, ipa_priv_key, '@INPUT@', '@OUTPUT@'],
+                  install : false,
+                  build_by_default : true)
+endif
+
+ipa_names += ipa_name
diff --git a/src/ipa/dcmipp/module.h b/src/ipa/dcmipp/module.h
new file mode 100644
index 00000000..2faecf85
--- /dev/null
+++ b/src/ipa/dcmipp/module.h
@@ -0,0 +1,27 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024 ST Microelectronics
+ *
+ * module.h - STM32 DCCMIPP IPA Module
+ */
+
+#pragma once
+
+#include <libcamera/ipa/dcmipp_ipa_interface.h>
+
+#include <libipa/module.h>
+
+#include "linux/stm32-dcmipp-config.h"
+
+#include "ipa_context.h"
+
+namespace libcamera {
+
+namespace ipa::dcmipp {
+
+using Module = ipa::Module<IPAContext, IPAFrameContext, IPACameraSensorInfo,
+			   stm32_dcmipp_params_cfg, stm32_dcmipp_stat_buf>;
+
+} /* namespace ipa::dcmipp */
+
+} /* namespace libcamera*/
diff --git a/src/ipa/libipa/camera_sensor_helper.cpp b/src/ipa/libipa/camera_sensor_helper.cpp
index ce29f423..6897939d 100644
--- a/src/ipa/libipa/camera_sensor_helper.cpp
+++ b/src/ipa/libipa/camera_sensor_helper.cpp
@@ -444,6 +444,17 @@ class CameraSensorHelperImx327 : public CameraSensorHelperImx290
 };
 REGISTER_CAMERA_SENSOR_HELPER("imx327", CameraSensorHelperImx327)
 
+class CameraSensorHelperImx335 : public CameraSensorHelper
+{
+public:
+	CameraSensorHelperImx335()
+	{
+		gainType_ = AnalogueGainExponential;
+		gainConstants_.exp = { 1.0, expGainDb(0.3) };
+	}
+};
+REGISTER_CAMERA_SENSOR_HELPER("imx335", CameraSensorHelperImx335)
+
 class CameraSensorHelperImx477 : public CameraSensorHelper
 {
 public:
diff --git a/src/ipa/libipa/camera_sensor_helper.h b/src/ipa/libipa/camera_sensor_helper.h
index 3ea1806c..1ca9371b 100644
--- a/src/ipa/libipa/camera_sensor_helper.h
+++ b/src/ipa/libipa/camera_sensor_helper.h
@@ -88,7 +88,7 @@ public:
 	}
 
 private:
-	std::unique_ptr<CameraSensorHelper> createInstance() const
+	std::unique_ptr<CameraSensorHelper> createInstance() const override
 	{
 		return std::make_unique<_Helper>();
 	}
diff --git a/src/libcamera/base/bound_method.cpp b/src/libcamera/base/bound_method.cpp
index 3ecec51c..c83d623f 100644
--- a/src/libcamera/base/bound_method.cpp
+++ b/src/libcamera/base/bound_method.cpp
@@ -7,6 +7,7 @@
 
 #include <libcamera/base/bound_method.h>
 #include <libcamera/base/message.h>
+#include <libcamera/base/object.h>
 #include <libcamera/base/semaphore.h>
 #include <libcamera/base/thread.h>
 
diff --git a/src/libcamera/base/event_notifier.cpp b/src/libcamera/base/event_notifier.cpp
index fd93c087..a519aec3 100644
--- a/src/libcamera/base/event_notifier.cpp
+++ b/src/libcamera/base/event_notifier.cpp
@@ -8,6 +8,7 @@
 #include <libcamera/base/event_notifier.h>
 
 #include <libcamera/base/event_dispatcher.h>
+#include <libcamera/base/log.h>
 #include <libcamera/base/message.h>
 #include <libcamera/base/thread.h>
 
@@ -20,6 +21,8 @@
 
 namespace libcamera {
 
+LOG_DECLARE_CATEGORY(Event)
+
 /**
  * \class EventNotifier
  * \brief Notify of activity on a file descriptor
@@ -104,6 +107,9 @@ EventNotifier::~EventNotifier()
  */
 void EventNotifier::setEnabled(bool enable)
 {
+	if (!assertThreadBound("EventNotifier can't be enabled from another thread"))
+		return;
+
 	if (enabled_ == enable)
 		return;
 
diff --git a/src/libcamera/base/object.cpp b/src/libcamera/base/object.cpp
index 92cecd22..81054b58 100644
--- a/src/libcamera/base/object.cpp
+++ b/src/libcamera/base/object.cpp
@@ -40,8 +40,9 @@ LOG_DEFINE_CATEGORY(Object)
  * Object class.
  *
  * Deleting an object from a thread other than the one the object is bound to is
- * unsafe, unless the caller ensures that the object isn't processing any
- * message concurrently.
+ * unsafe, unless the caller ensures that the object's thread is stopped and no
+ * parent or child of the object gets deleted concurrently. See
+ * Object::~Object() for more information.
  *
  * Object slots connected to signals will also run in the context of the
  * object's thread, regardless of whether the signal is emitted in the same or
@@ -84,9 +85,20 @@ Object::Object(Object *parent)
  * Object instances shall be destroyed from the thread they are bound to,
  * otherwise undefined behaviour may occur. If deletion of an Object needs to
  * be scheduled from a different thread, deleteLater() shall be used.
+ *
+ * As an exception to this rule, Object instances may be deleted from a
+ * different thread if the thread the instance is bound to is stopped through
+ * the whole duration of the object's destruction, *and* the parent and children
+ * of the object do not get deleted concurrently. The caller is responsible for
+ * fulfilling those requirements.
+ *
+ * In all cases Object instances shall be deleted before the Thread they are
+ * bound to.
  */
 Object::~Object()
 {
+	ASSERT(Thread::current() == thread_ || !thread_->isRunning());
+
 	/*
 	 * Move signals to a private list to avoid concurrent iteration and
 	 * deletion of items from Signal::disconnect().
@@ -116,8 +128,9 @@ Object::~Object()
  * event loop that the object belongs to. This ensures the object is destroyed
  * from the right context, as required by the libcamera threading model.
  *
- * If this function is called before the thread's event loop is started, the
- * object will be deleted when the event loop starts.
+ * If this function is called before the thread's event loop is started or after
+ * it has stopped, the object will be deleted when the event loop (re)starts. If
+ * this never occurs, the object will be leaked.
  *
  * Deferred deletion can be used to control the destruction context with shared
  * pointers. An object managed with shared pointers is deleted when the last
@@ -212,6 +225,35 @@ void Object::message(Message *msg)
 	}
 }
 
+/**
+ * \fn Object::assertThreadBound()
+ * \brief Check if the caller complies with thread-bound constraints
+ * \param[in] message The message to be printed on error
+ *
+ * This function verifies the calling constraints required by the \threadbound
+ * definition. It shall be called at the beginning of member functions of an
+ * Object subclass that are explicitly marked as thread-bound in their
+ * documentation.
+ *
+ * If the thread-bound constraints are not met, the function prints \a message
+ * as an error message. For debug builds, it additionally causes an assertion
+ * error.
+ *
+ * \todo Verify the thread-bound requirements for functions marked as
+ * thread-bound at the class level.
+ *
+ * \return True if the call is thread-bound compliant, false otherwise
+ */
+bool Object::assertThreadBound(const char *message)
+{
+	if (Thread::current() == thread_)
+		return true;
+
+	LOG(Object, Error) << message;
+	ASSERT(false);
+	return false;
+}
+
 /**
  * \fn R Object::invokeMethod()
  * \brief Invoke a method asynchronously on an Object instance
@@ -259,11 +301,12 @@ void Object::message(Message *msg)
  * Moving an object that has a parent is not allowed, and causes undefined
  * behaviour.
  *
- * \context This function is thread-bound.
+ * \context This function is \threadbound.
  */
 void Object::moveToThread(Thread *thread)
 {
-	ASSERT(Thread::current() == thread_);
+	if (!assertThreadBound("Object can't be moved from another thread"))
+		return;
 
 	if (thread_ == thread)
 		return;
diff --git a/src/libcamera/base/signal.cpp b/src/libcamera/base/signal.cpp
index a46386a0..f1018b37 100644
--- a/src/libcamera/base/signal.cpp
+++ b/src/libcamera/base/signal.cpp
@@ -8,6 +8,7 @@
 #include <libcamera/base/signal.h>
 
 #include <libcamera/base/mutex.h>
+#include <libcamera/base/object.h>
 
 /**
  * \file base/signal.h
@@ -74,7 +75,7 @@ SignalBase::SlotList SignalBase::slots()
  *
  * Signals and slots are a language construct aimed at communication between
  * objects through the observer pattern without the need for boilerplate code.
- * See http://doc.qt.io/qt-5/signalsandslots.html for more information.
+ * See http://doc.qt.io/qt-6/signalsandslots.html for more information.
  *
  * Signals model events that can be observed from objects unrelated to the event
  * source. Slots are functions that are called in response to a signal. Signals
diff --git a/src/libcamera/base/thread.cpp b/src/libcamera/base/thread.cpp
index b96951ac..4ac72036 100644
--- a/src/libcamera/base/thread.cpp
+++ b/src/libcamera/base/thread.cpp
@@ -18,6 +18,7 @@
 #include <libcamera/base/log.h>
 #include <libcamera/base/message.h>
 #include <libcamera/base/mutex.h>
+#include <libcamera/base/object.h>
 
 /**
  * \page thread Thread Support
@@ -370,6 +371,12 @@ void Thread::run()
 
 void Thread::finishThread()
 {
+	/*
+	 * Objects may have been scheduled for deletion right before the thread
+	 * exited. Ensure they get deleted now, before the thread stops.
+	 */
+	dispatchMessages(Message::Type::DeferredDelete);
+
 	data_->mutex_.lock();
 	data_->running_ = false;
 	data_->mutex_.unlock();
diff --git a/src/libcamera/base/timer.cpp b/src/libcamera/base/timer.cpp
index 74b060af..24dbf1e8 100644
--- a/src/libcamera/base/timer.cpp
+++ b/src/libcamera/base/timer.cpp
@@ -85,10 +85,8 @@ void Timer::start(std::chrono::milliseconds duration)
  */
 void Timer::start(std::chrono::steady_clock::time_point deadline)
 {
-	if (Thread::current() != thread()) {
-		LOG(Timer, Error) << "Timer " << this << " << can't be started from another thread";
+	if (!assertThreadBound("Timer can't be started from another thread"))
 		return;
-	}
 
 	deadline_ = deadline;
 
@@ -114,13 +112,11 @@ void Timer::start(std::chrono::steady_clock::time_point deadline)
  */
 void Timer::stop()
 {
-	if (!isRunning())
+	if (!assertThreadBound("Timer can't be stopped from another thread"))
 		return;
 
-	if (Thread::current() != thread()) {
-		LOG(Timer, Error) << "Timer " << this << " can't be stopped from another thread";
+	if (!isRunning())
 		return;
-	}
 
 	unregisterTimer();
 }
diff --git a/src/libcamera/bayer_format.cpp b/src/libcamera/bayer_format.cpp
index 3bf15fb4..20aedfa6 100644
--- a/src/libcamera/bayer_format.cpp
+++ b/src/libcamera/bayer_format.cpp
@@ -170,6 +170,10 @@ const std::map<BayerFormat, Formats, BayerFormatComparator> bayerToFormat{
 		{ formats::R10, V4L2PixelFormat(V4L2_PIX_FMT_Y10) } },
 	{ { BayerFormat::MONO, 10, BayerFormat::Packing::CSI2 },
 		{ formats::R10_CSI2P, V4L2PixelFormat(V4L2_PIX_FMT_Y10P) } },
+	{ { BayerFormat::MONO, 12, BayerFormat::Packing::None },
+		{ formats::R12, V4L2PixelFormat(V4L2_PIX_FMT_Y12) } },
+	{ { BayerFormat::MONO, 16, BayerFormat::Packing::None },
+		{ formats::R16, V4L2PixelFormat(V4L2_PIX_FMT_Y16) } },
 };
 
 const std::unordered_map<unsigned int, BayerFormat> mbusCodeToBayer{
@@ -208,6 +212,7 @@ const std::unordered_map<unsigned int, BayerFormat> mbusCodeToBayer{
 	{ MEDIA_BUS_FMT_Y8_1X8, { BayerFormat::MONO, 8, BayerFormat::Packing::None } },
 	{ MEDIA_BUS_FMT_Y10_1X10, { BayerFormat::MONO, 10, BayerFormat::Packing::None } },
 	{ MEDIA_BUS_FMT_Y12_1X12, { BayerFormat::MONO, 12, BayerFormat::Packing::None } },
+	{ MEDIA_BUS_FMT_Y16_1X16, { BayerFormat::MONO, 16, BayerFormat::Packing::None } },
 };
 
 } /* namespace */
diff --git a/src/libcamera/camera_sensor_properties.cpp b/src/libcamera/camera_sensor_properties.cpp
index 6e28b09e..7fb90d60 100644
--- a/src/libcamera/camera_sensor_properties.cpp
+++ b/src/libcamera/camera_sensor_properties.cpp
@@ -111,6 +111,10 @@ const CameraSensorProperties *CameraSensorProperties::get(const std::string &sen
 			.unitCellSize = { 2900, 2900 },
 			.testPatternModes = {},
 		} },
+		{ "imx335", {
+			.unitCellSize = { 2000, 2000 },
+			.testPatternModes = {},
+		} },
 		{ "imx477", {
 			.unitCellSize = { 1550, 1550 },
 			.testPatternModes = {},
diff --git a/src/libcamera/control_ids_draft.yaml b/src/libcamera/control_ids_draft.yaml
index 9bef5bf1..728c2573 100644
--- a/src/libcamera/control_ids_draft.yaml
+++ b/src/libcamera/control_ids_draft.yaml
@@ -227,4 +227,221 @@ controls:
             value. All of the custom test patterns will be static (that is the
             raw image must not vary from frame to frame).
 
+  - AnalogueGain_dB:
+      type: float
+      description: |
+        Analogue gain value applied in the sensor device expressed in decibel.
+        The value of the control specifies the gain multiplier applied to all
+        colour channels. This value cannot be lower than 0.0.
+
+        Setting this value means that it is now fixed and the AE algorithm may
+        not change it. Setting it back to a negative value returns it to the
+        control of the AE algorithm.
+
+  - AeExposureTarget:
+      type: int32_t
+      description: |
+        Exposure target for the AE algorithm to use.
+
+  - ColourGains3Enable:
+      type: bool
+      description: |
+        ColourGains3 feature enable status.
+
+  - ColourGains3:
+      type: int32_t
+      description: |
+        Gain values for the 3 colour channels, Red, Green and Blue in that
+        order.
+        Unit = 100000000 for "x1.0", 150000000 for "x1.5".
+      size: [3]
+
+  - ColourCorrectionEnable:
+      type: bool
+      description: |
+        ColourCorrection feature enable status.
+
+  - ColourCorrection:
+      type: int32_t
+      description: |
+        The 3x3 matrix that converts camera RGB to sRGB within the
+        imaging pipeline. This should describe the matrix that is used
+        after pixels have been white-balanced, but before any gamma
+        transformation. The 3x3 matrix is stored in conventional reading
+        order in an array of 9 values.
+        Unit = 100000000 for "x1.0", 150000000 for "x1.5".
+      size: [3,3]
+
+  - AwbProfileName:
+      type: string
+      description: |
+        Array of AWB profile name (one entry per profile) used by the AWB
+        algorithm.
+      size: [5]
+
+  - AwbCurrentProfileName:
+      type: string
+      description: Report the current profile name, for this frame. The
+        AwbCurrentProfileName control can only be returned in metadata.
+
+  - AwbReferenceColorTemperature:
+      type: int32_t
+      description: |
+        Array of reference color tempeartures (one entry per profile) used by
+        the AWB algorithm.
+      size: [5]
+
+  - AwbColourGains3:
+      type: int32_t
+      description: |
+        Array of ColourGains3 (one entry per profile) used by the AWB algorithm.
+      size: [5,3]
+
+  - AwbColourCorrection:
+      type: int32_t
+      description: |
+        Array of ColourCorrection (one entry per profile) used by the AWB
+        algorithm.
+      size: [5,3,3]
+
+  - AwbCustomColorTemperature:
+      type: int32_t
+      description: |
+        Color Temperature specifying a custom Awb mode. Must be a value of
+        AwbReferenceColorTemperature[].
+        Applicable when AwbMode is set to AwbCustom.
+
+  - BadPixelRemovalEnable:
+      type: bool
+      description: |
+        BadPixelRemoval feature enable status.
+
+  - BadPixelRemovalStrength:
+      type: int32_t
+      description: |
+        Strength of the detection and correction artifacts generated by a bad
+        pixel on the sensor array.
+        If BadPixelRemovalThreshold is set to a positive value, then this
+        setting is under control of the BadPixelRemoval algorithm.
+
+  - BadPixelRemovalThreshold:
+      type: int32_t
+      description: |
+        If set to a positive value, the BadPixelRemoval algorithm adjusts the
+        strength of detection so the amount of expected bad pixel corrected is
+        as close as possible to that threshold.
+
+  - BadPixelRemovalCount:
+      type: int32_t
+      description: |
+        Report of the amount of bad components corrected.
+
+  - BlackLevelCorrectionEnable:
+      type: bool
+      description: |
+        BlackLevelCorrection feature enable status.
+
+  - BlackLevelCorrectionLevels:
+      type: int32_t
+      description: |
+        Black levels correction of the Red, Green and Blue colour channels, in
+        that order.
+      size: [3]
+
+  - DemosaicingEnable:
+      type: bool
+      description: |
+        Demosaicing feature enable status.
+
+  - DemosaicingFilter:
+      type: int32_t
+      description: |
+        Demosaicing filter parameters (strength of the detection) to adapt to
+        specific shapes in this order: Peak, Vertical line, Horizontal line,
+        Edge
+      size: [4]
+
+  - ContrastLuminanceEnable:
+      type: bool
+      description: |
+        ContrastLuminance feature enable status.
+
+  - ContrastLuminance:
+      type: int32_t
+      description: |
+        Luminance amplification factor table for preset luminance segments.
+        Entry 0 is for pixel with luminance of 0, entry 1 is for pixel with
+        luminance of 32, ..., entry 8 is for pixel with luminance of 256.
+        Unit = 100 for "x1.0", 150 for "x1.5".
+      size: [9]
+
+  - IspDecimationRatio:
+      type: int32_t
+      description: |
+        ISP decimation ratio. This control can only be returned in metadata.
+
+  - StatisticArea:
+      type: Rectangle
+      description: |
+        Area defining where the statistics are extracted within the frame.
+        If not defined, the statistics are extracted within the whole frame.
+
+  - StatisticProfile:
+      type: int32_t
+      description: |
+        Defines which statistics are reported.
+      enum:
+        - name: Full
+          value: 0
+          description: |
+            Bins and Average on Up and Down location are reported. The ISP needs
+            several VSYNC cycles to report such statistics.
+        - name: AverageUp
+          value: 1
+          description: Only Average on Up location are reported (fast report).
+        - name: AverageDown
+          value: 2
+          description: Only Average on Down location are reported (fast report).
+
+  - StatisticAverageUp:
+      type: int32_t
+      description: |
+        Reported average value (from 0 to 255) measured at the up part of the
+        ISP pipeline. Red, Green, Blue colour channels and Luminance in that
+        order.
+      size: [4]
+
+  - StatisticAverageDown:
+      type: int32_t
+      description: |
+        Reported average value (from 0 to 255) measured at the down part of the
+        ISP pipeline. Red, Green, Blue colour channels and Luminance in that
+        order.
+      size: [4]
+
+  - StatisticBinsUp:
+      type: int32_t
+      description: |
+        Reported bins (number of pixels in one of the 12 ranges of luminance)
+        measured at the up part of the ISP pipeline.
+      size: [12]
+
+  - StatisticBinsDown:
+      type: int32_t
+      description: |
+        Reported bins (number of pixels in one of the 12 ranges of luminance)
+        measured at the up part of the ISP pipeline.
+      size: [12]
+
+  - SensorBitsPerPixel:
+      type: int32_t
+      description: |
+        Number of bits per pixel of the sensor.
+        This control can only be returned in metadata.
+
+  - PipelineHwRevision:
+      type: int32_t
+      description: |
+        IPA hardware revision identifier.
+
 ...
diff --git a/src/libcamera/formats.c b/src/libcamera/formats.c
deleted file mode 100644
index e69de29b..00000000
diff --git a/src/libcamera/formats.cpp b/src/libcamera/formats.cpp
index 447e6238..8a606a7c 100644
--- a/src/libcamera/formats.cpp
+++ b/src/libcamera/formats.cpp
@@ -497,6 +497,16 @@ const std::map<PixelFormat, PixelFormatInfo> pixelFormatInfo{
 		.pixelsPerGroup = 1,
 		.planes = {{ { 2, 1 }, { 0, 0 }, { 0, 0 } }},
 	} },
+	{ formats::R10_CSI2P, {
+		.name = "R10_CSI2P",
+		.format = formats::R10_CSI2P,
+		.v4l2Formats = { V4L2PixelFormat(V4L2_PIX_FMT_Y10P), },
+		.bitsPerPixel = 10,
+		.colourEncoding = PixelFormatInfo::ColourEncodingYUV,
+		.packed = true,
+		.pixelsPerGroup = 4,
+		.planes = {{ { 5, 1 }, { 0, 0 }, { 0, 0 } }},
+	} },
 	{ formats::R12, {
 		.name = "R12",
 		.format = formats::R12,
@@ -507,15 +517,15 @@ const std::map<PixelFormat, PixelFormatInfo> pixelFormatInfo{
 		.pixelsPerGroup = 1,
 		.planes = {{ { 2, 1 }, { 0, 0 }, { 0, 0 } }},
 	} },
-	{ formats::R10_CSI2P, {
-		.name = "R10_CSI2P",
-		.format = formats::R10_CSI2P,
-		.v4l2Formats = { V4L2PixelFormat(V4L2_PIX_FMT_Y10P), },
-		.bitsPerPixel = 10,
+	{ formats::R16, {
+		.name = "R16",
+		.format = formats::R16,
+		.v4l2Formats = { V4L2PixelFormat(V4L2_PIX_FMT_Y16), },
+		.bitsPerPixel = 16,
 		.colourEncoding = PixelFormatInfo::ColourEncodingYUV,
-		.packed = true,
-		.pixelsPerGroup = 4,
-		.planes = {{ { 5, 1 }, { 0, 0 }, { 0, 0 } }},
+		.packed = false,
+		.pixelsPerGroup = 1,
+		.planes = {{ { 2, 1 }, { 0, 0 }, { 0, 0 } }},
 	} },
 
 	/* Bayer formats. */
diff --git a/src/libcamera/formats.yaml b/src/libcamera/formats.yaml
index 539ac0b3..d8a37992 100644
--- a/src/libcamera/formats.yaml
+++ b/src/libcamera/formats.yaml
@@ -11,6 +11,8 @@ formats:
       fourcc: DRM_FORMAT_R10
   - R12:
       fourcc: DRM_FORMAT_R12
+  - R16:
+      fourcc: DRM_FORMAT_R16
 
   - RGB565:
       fourcc: DRM_FORMAT_RGB565
diff --git a/src/libcamera/pipeline/dcmipp/dcmipp.cpp b/src/libcamera/pipeline/dcmipp/dcmipp.cpp
new file mode 100644
index 00000000..48b660a8
--- /dev/null
+++ b/src/libcamera/pipeline/dcmipp/dcmipp.cpp
@@ -0,0 +1,1277 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024, ST Microelectronics
+ *
+ * dcmipp.cpp - Pipeline handler for the stm32 DCMIPP device
+ * Originally based on the vimc pipeline handler
+ */
+
+#include <algorithm>
+#include <iomanip>
+#include <map>
+#include <math.h>
+#include <tuple>
+
+#include <linux/media-bus-format.h>
+#include <linux/version.h>
+
+#include <libcamera/base/log.h>
+#include <libcamera/base/utils.h>
+
+#include <libcamera/camera.h>
+#include <libcamera/control_ids.h>
+#include <libcamera/controls.h>
+#include <libcamera/formats.h>
+#include <libcamera/request.h>
+#include <libcamera/stream.h>
+
+#include <libcamera/ipa/dcmipp_ipa_interface.h>
+#include <libcamera/ipa/dcmipp_ipa_proxy.h>
+#include <libcamera/ipa/ipa_interface.h>
+#include <libcamera/ipa/ipa_module_info.h>
+
+#include "libcamera/internal/camera.h"
+#include "libcamera/internal/camera_sensor.h"
+#include "libcamera/internal/device_enumerator.h"
+#include "libcamera/internal/framebuffer.h"
+#include "libcamera/internal/ipa_manager.h"
+#include "libcamera/internal/media_device.h"
+#include "libcamera/internal/pipeline_handler.h"
+#include "libcamera/internal/v4l2_subdevice.h"
+#include "libcamera/internal/v4l2_videodevice.h"
+
+#include "linux/stm32-dcmipp-config.h"
+#include "dcmipp.h"
+
+namespace libcamera {
+
+LOG_DEFINE_CATEGORY(DCMIPP)
+
+class PipelineHandlerDcmipp;
+class DcmippCameraData;
+
+struct DcmippFrameInfo {
+	unsigned int frame;
+	Request *request;
+
+	FrameBuffer *dumpPathBuffer;
+	FrameBuffer *mainPathBuffer;
+	FrameBuffer *auxPathBuffer;
+
+	FrameBuffer *statsBuffer;
+
+	bool metadataProcessed;
+};
+
+class DcmippFrames
+{
+public:
+	DcmippFrames(PipelineHandler *pipe);
+
+	DcmippFrameInfo *create(const DcmippCameraData *data, Request *request);
+	int destroy(unsigned int frame);
+	void clear();
+
+	DcmippFrameInfo *find(unsigned int frame);
+	DcmippFrameInfo *find(FrameBuffer *buffer);
+
+private:
+	PipelineHandlerDcmipp *pipe_;
+	std::map<unsigned int, DcmippFrameInfo *> frameInfo_;
+};
+
+class DcmippCameraData : public Camera::Private
+{
+public:
+	DcmippCameraData(PipelineHandler *pipe, DcmippDumpPath *dumpPath,
+			 DcmippMainPath *mainPath, DcmippAuxPath *auxPath)
+		: Camera::Private(pipe), dumpPath_(dumpPath),
+		  mainPath_(mainPath), auxPath_(auxPath), frameInfo_(pipe)
+	{
+	}
+
+	PipelineHandlerDcmipp *pipe();
+
+	void paramsFilled(unsigned int id);
+	void statsFreed(unsigned int id);
+	void metadataReady(unsigned int frame, const ControlList &metadata);
+	void setSensorControls(unsigned int id, const ControlList &sensorControls);
+	void setIspControls(unsigned int id, const ControlList &ispControls);
+
+	std::unique_ptr<CameraSensor> sensor_;
+	std::unique_ptr<V4L2Subdevice> input_;
+	Stream Dumpstream_;
+	Stream Mainstream_;
+	Stream Auxstream_;
+
+	DcmippDumpPath *dumpPath_;
+	DcmippMainPath *mainPath_;
+	DcmippAuxPath *auxPath_;
+
+	std::vector<IPABuffer> ipaBuffers_;
+	std::unique_ptr<ipa::dcmipp::IPAProxyDcmipp> ipa_;
+	DcmippFrames frameInfo_;
+
+	std::queue<Request *> requests_;
+};
+
+class DcmippCameraConfiguration : public CameraConfiguration
+{
+public:
+	DcmippCameraConfiguration(DcmippCameraData *data);
+
+	Status validate() override;
+
+	const V4L2SubdeviceFormat &sensorFormat() { return sensorFormat_; }
+
+	/*
+	 * Indicate if gamma correction should be enabled on the corresponding
+	 * stream
+	 */
+	bool gamma_correction[3];
+
+private:
+	bool fitsAllPaths(const StreamConfiguration &cfg);
+
+	DcmippCameraData *data_;
+	V4L2SubdeviceFormat sensorFormat_;
+};
+
+class PipelineHandlerDcmipp : public PipelineHandler
+{
+public:
+	PipelineHandlerDcmipp(CameraManager *manager);
+
+	std::unique_ptr<CameraConfiguration> generateConfiguration(Camera *camera,
+								   Span<const StreamRole> roles) override;
+	int configure(Camera *camera, CameraConfiguration *config) override;
+
+	int exportFrameBuffers(Camera *camera, Stream *stream,
+			       std::vector<std::unique_ptr<FrameBuffer>> *buffers) override;
+
+	int start(Camera *camera, const ControlList *controls) override;
+	void stopDevice(Camera *camera) override;
+
+	int queueRequestDevice(Camera *camera, Request *request) override;
+
+	bool match(DeviceEnumerator *enumerator) override;
+
+private:
+	int init();
+
+	DcmippCameraData *cameraData(Camera *camera)
+	{
+		return static_cast<DcmippCameraData *>(camera->_d());
+	}
+
+	friend DcmippCameraData;
+	friend DcmippCameraConfiguration;
+
+	int allocateBuffers(Camera *camera);
+	int freeBuffers(Camera *camera);
+
+	void bufferReady(FrameBuffer *buffer);
+	void statsReady(FrameBuffer *buffer);
+	void paramsReady(FrameBuffer *buffer);
+
+	DcmippDumpPath dumpPath_;
+	DcmippMainPath mainPath_;
+	DcmippAuxPath auxPath_;
+
+	MediaDevice *media_;
+	std::unique_ptr<V4L2Subdevice> bridge_;
+	std::unique_ptr<V4L2Subdevice> input_;
+
+	std::unique_ptr<V4L2VideoDevice> params_;
+	std::unique_ptr<V4L2VideoDevice> stats_;
+
+	std::unique_ptr<DcmippCameraData> data_;
+
+	std::vector<std::unique_ptr<FrameBuffer>> isp_params_;
+	std::queue<FrameBuffer *> available_isp_params_;
+	std::vector<std::unique_ptr<FrameBuffer>> isp_stats_;
+	std::queue<FrameBuffer *> available_isp_stats_;
+
+	void tryCompleteRequest(DcmippFrameInfo *info);
+
+	Camera *activeCamera_;
+};
+
+namespace {
+
+static const std::map<PixelFormat, uint32_t> rawFormatToMediaBus{
+	{ formats::SBGGR8, MEDIA_BUS_FMT_SBGGR8_1X8 },
+	{ formats::SGBRG8, MEDIA_BUS_FMT_SGBRG8_1X8 },
+	{ formats::SGRBG8, MEDIA_BUS_FMT_SGRBG8_1X8 },
+	{ formats::SRGGB8, MEDIA_BUS_FMT_SRGGB8_1X8 },
+	{ formats::SBGGR10, MEDIA_BUS_FMT_SBGGR10_1X10 },
+	{ formats::SGBRG10, MEDIA_BUS_FMT_SGBRG10_1X10 },
+	{ formats::SGRBG10, MEDIA_BUS_FMT_SGRBG10_1X10 },
+	{ formats::SRGGB10, MEDIA_BUS_FMT_SRGGB10_1X10 },
+	{ formats::SBGGR12, MEDIA_BUS_FMT_SBGGR12_1X12 },
+	{ formats::SGBRG12, MEDIA_BUS_FMT_SGBRG12_1X12 },
+	{ formats::SGRBG12, MEDIA_BUS_FMT_SGRBG12_1X12 },
+	{ formats::SRGGB12, MEDIA_BUS_FMT_SRGGB12_1X12 },
+	{ formats::SBGGR14, MEDIA_BUS_FMT_SBGGR14_1X14 },
+	{ formats::SGBRG14, MEDIA_BUS_FMT_SGBRG14_1X14 },
+	{ formats::SGRBG14, MEDIA_BUS_FMT_SGRBG14_1X14 },
+	{ formats::SRGGB14, MEDIA_BUS_FMT_SRGGB14_1X14 },
+};
+
+} /* namespace */
+
+DcmippFrames::DcmippFrames(PipelineHandler *pipe)
+	: pipe_(static_cast<PipelineHandlerDcmipp *>(pipe))
+{
+}
+
+DcmippFrameInfo *DcmippFrames::create(const DcmippCameraData *data, Request *request)
+{
+	FrameBuffer *dumpPathBuffer = nullptr;
+	FrameBuffer *mainPathBuffer = nullptr;
+	FrameBuffer *auxPathBuffer = nullptr;
+
+	if (data->dumpPath_->isEnabled()) {
+		dumpPathBuffer = request->findBuffer(&data->Dumpstream_);
+		if (!dumpPathBuffer) {
+			LOG(DCMIPP, Error) << "Attempt to queue request with invalid stream";
+			return nullptr;
+		}
+	}
+
+	if (data->mainPath_->isEnabled()) {
+		mainPathBuffer = request->findBuffer(&data->Mainstream_);
+		if (!mainPathBuffer) {
+			LOG(DCMIPP, Error) << "Attempt to queue request with invalid stream";
+			return nullptr;
+		}
+	}
+
+	if (data->auxPath_->isEnabled()) {
+		auxPathBuffer = request->findBuffer(&data->Auxstream_);
+		if (!auxPathBuffer) {
+			LOG(DCMIPP, Error) << "Attempt to queue request with invalid stream";
+			return nullptr;
+		}
+	}
+
+	DcmippFrameInfo *info = new DcmippFrameInfo;
+
+	info->frame = request->sequence();
+	info->request = request;
+	info->dumpPathBuffer = dumpPathBuffer;
+	info->mainPathBuffer = mainPathBuffer;
+	info->auxPathBuffer = auxPathBuffer;
+
+	info->statsBuffer = nullptr;
+	info->metadataProcessed = false;
+
+	frameInfo_[info->frame] = info;
+
+	return info;
+}
+
+int DcmippFrames::destroy(unsigned int frame)
+{
+	DcmippFrameInfo *info = find(frame);
+	if (!info)
+		return -ENOENT;
+
+	frameInfo_.erase(info->frame);
+
+	delete info;
+
+	return 0;
+}
+
+void DcmippFrames::clear()
+{
+	for (const auto &entry : frameInfo_) {
+		DcmippFrameInfo *info = entry.second;
+
+		delete info;
+	}
+
+	frameInfo_.clear();
+}
+
+DcmippFrameInfo *DcmippFrames::find(unsigned int frame)
+{
+	auto itInfo = frameInfo_.find(frame);
+
+	if (itInfo != frameInfo_.end())
+		return itInfo->second;
+
+	LOG(DCMIPP, Error) << "Frame #" << frame << " unknown in frameInfo list";
+
+	return nullptr;
+}
+
+DcmippFrameInfo *DcmippFrames::find(FrameBuffer *buffer)
+{
+	for (auto &itInfo : frameInfo_) {
+		DcmippFrameInfo *info = itInfo.second;
+
+		if (info->dumpPathBuffer == buffer ||
+		    info->mainPathBuffer == buffer ||
+		    info->auxPathBuffer == buffer ||
+		    info->statsBuffer == buffer)
+			return info;
+	}
+
+	LOG(DCMIPP, Error) << "FrameBuffer " << buffer << " unknown in frameInfo list";
+
+	return nullptr;
+}
+
+DcmippCameraConfiguration::DcmippCameraConfiguration(DcmippCameraData *data)
+	: CameraConfiguration(), data_(data)
+{
+}
+
+bool DcmippCameraConfiguration::fitsAllPaths(const StreamConfiguration &cfg)
+{
+	const CameraSensor *sensor = data_->sensor_.get();
+	StreamConfiguration config;
+	unsigned int isp_decimation_ratio = 0;
+
+	/*
+	 * We only check for non-RAW configuration using Main / Aux pipes since anyway
+	 * we dedicate the Dump pipe for RAW
+	 */
+	if (PixelFormatInfo::info(cfg.pixelFormat).colourEncoding == PixelFormatInfo::ColourEncodingRAW)
+		return false;
+
+	config = cfg;
+	if (data_->mainPath_->validate(sensor, &config, &isp_decimation_ratio) != Valid)
+		return false;
+
+	config = cfg;
+	if (data_->auxPath_->validate(sensor, &config, &isp_decimation_ratio) != Valid)
+		return false;
+
+	return true;
+}
+
+CameraConfiguration::Status DcmippCameraConfiguration::validate()
+{
+	const CameraSensor *sensor = data_->sensor_.get();
+	PipelineHandlerDcmipp *pipe =
+		static_cast<PipelineHandlerDcmipp *>(data_->pipe());
+	unsigned int isp_decimation_ratio = 0;
+	V4L2SubdeviceFormat sensorFormat;
+	Status status = Valid;
+
+	/*
+	 * List of RAW formats supported by the input subdevice
+	 * sorted from the best quality to the lowest quality so
+	 * that the pipeline handler will pick up the best quality
+	 * possible by both sensor & dcmipp
+	 */
+	const std::vector<unsigned int> mbusRAWInputCodes = {
+		MEDIA_BUS_FMT_SRGGB14_1X14,
+		MEDIA_BUS_FMT_SGRBG14_1X14,
+		MEDIA_BUS_FMT_SGBRG14_1X14,
+		MEDIA_BUS_FMT_SBGGR14_1X14,
+		MEDIA_BUS_FMT_SRGGB12_1X12,
+		MEDIA_BUS_FMT_SGRBG12_1X12,
+		MEDIA_BUS_FMT_SGBRG12_1X12,
+		MEDIA_BUS_FMT_SBGGR12_1X12,
+		MEDIA_BUS_FMT_SRGGB10_1X10,
+		MEDIA_BUS_FMT_SGRBG10_1X10,
+		MEDIA_BUS_FMT_SGBRG10_1X10,
+		MEDIA_BUS_FMT_SBGGR10_1X10,
+		MEDIA_BUS_FMT_SRGGB8_1X8,
+		MEDIA_BUS_FMT_SGRBG8_1X8,
+		MEDIA_BUS_FMT_SGBRG8_1X8,
+		MEDIA_BUS_FMT_SBGGR8_1X8,
+	};
+
+	LOG(DCMIPP, Debug) << "validate";
+
+	if (config_.empty())
+		return Invalid;
+
+	/* Cap the number of entries to the available streams. */
+	if (config_.size() > 3) {
+		config_.resize(3);
+		status = Adjusted;
+	}
+
+	/*
+	 * Reorder the list of streams based on compatibility with pipes.  Evaluate first
+	 * streams that cannot work on all pipes.  Create an order list, and push at the
+	 * back of the list pipes that can run on both main & aux pipes
+	 */
+	std::vector<unsigned int> order;
+	order.reserve(config_.size());
+	for (unsigned int index = 0; index < config_.size(); index++) {
+		if (fitsAllPaths(config_[index]))
+			order.emplace(order.end(), index);
+		else
+			order.emplace(order.begin(), index);
+	}
+
+	/* Pick a pipe and validate each configuration */
+	bool dumpAllocated = false, mainAllocated = false, auxAllocated = false;
+	for (unsigned int index : order) {
+		StreamConfiguration &cfg = config_[index];
+		DcmippPath *path;
+		Stream *stream;
+
+		if (PixelFormatInfo::info(cfg.pixelFormat).colourEncoding == PixelFormatInfo::ColourEncodingRAW) {
+			if (dumpAllocated) {
+				LOG(DCMIPP, Error) << "Cannot perform RAW capture since Dump pipe already allocated";
+				return Invalid;
+			}
+			LOG(DCMIPP, Debug) << "Select Dump pipe for config: pixelformat: " << cfg.pixelFormat << " size: " << cfg.size;
+			path = &pipe->dumpPath_;
+			stream = &data_->Dumpstream_;
+			dumpAllocated = true;
+		} else {
+			if (!mainAllocated) {
+				LOG(DCMIPP, Debug) << "Select Main pipe for config: pixelformat: " << cfg.pixelFormat << " size: " << cfg.size;
+				path = &pipe->mainPath_;
+				stream = &data_->Mainstream_;
+				mainAllocated = true;
+			} else if (!auxAllocated) {
+				LOG(DCMIPP, Debug) << "Select Aux pipe for config: pixelformat: " << cfg.pixelFormat << " size: " << cfg.size;
+				path = &pipe->auxPath_;
+				stream = &data_->Auxstream_;
+				auxAllocated = true;
+			} else {
+				LOG(DCMIPP, Error) << "No more pipe available";
+				return Invalid;
+			}
+		}
+
+		StreamConfiguration tryCfg = cfg;
+		if (path->validate(sensor, &tryCfg, &isp_decimation_ratio) != Valid)
+			return Invalid;
+
+		cfg = std::move(tryCfg);
+		cfg.setStream(stream);
+
+		/* If we have validate a RAW format, this should be the sensor format */
+		if (PixelFormatInfo::info(cfg.pixelFormat).colourEncoding == PixelFormatInfo::ColourEncodingRAW) {
+			/* Check that the format is supported */
+			if (rawFormatToMediaBus.find(cfg.pixelFormat) == rawFormatToMediaBus.end()) {
+				LOG(DCMIPP, Debug) << "Format " << cfg.pixelFormat << " not supported";
+				return Invalid;
+			}
+
+			sensorFormat.mbus_code = rawFormatToMediaBus.find(cfg.pixelFormat)->second;
+			sensorFormat.size = sensor->resolution();
+		}
+	}
+
+	/* If we haven't got yet a sensorFormat, then pick the best one for us */
+	if (sensorFormat.size.isNull()) {
+		sensorFormat = sensor->getFormat(mbusRAWInputCodes, sensor->resolution());
+		if (sensorFormat.size.isNull()) {
+			LOG(DCMIPP, Debug) << __func__ << "Failed to get compatible RAW format";
+			return Invalid;
+		}
+	}
+
+	LOG(DCMIPP, Debug) << __func__ << " sensor MBUS format is " << sensorFormat.mbus_code << "/" << sensorFormat.size;
+	sensorFormat_ = sensorFormat;
+
+	return status;
+}
+
+PipelineHandlerDcmipp::PipelineHandlerDcmipp(CameraManager *manager)
+	: PipelineHandler(manager), media_(nullptr), activeCamera_(nullptr)
+{
+}
+
+std::unique_ptr<CameraConfiguration>
+PipelineHandlerDcmipp::generateConfiguration(Camera *camera,
+					     Span<const StreamRole> roles)
+{
+	DcmippCameraData *data = cameraData(camera);
+	std::unique_ptr<CameraConfiguration> config =
+		std::make_unique<DcmippCameraConfiguration>(data);
+	DcmippCameraConfiguration *dcmipp_config =
+		static_cast<DcmippCameraConfiguration *>(config.get());
+	bool dumpAllocated = false, mainAllocated = false, auxAllocated = false;
+	int i = 0;
+
+	LOG(DCMIPP, Debug) << "generateConfiguration";
+
+	/* It is allowed to not indicate a role, in which case we return a empty config */
+	if (roles.empty())
+		return config;
+
+	/* DCMIPP can handle a maximum of 3 streams */
+	if (roles.size() > 3) {
+		LOG(DCMIPP, Error) << "More streams requested than supported";
+		return nullptr;
+	}
+
+	/*
+	 * We can allocate pipes depending on the role since preferred configuration for
+	 * each role define the pipe to be used due to their HW capabilities
+	 *
+	 * StillCapture: targetting best image, with JPEG output via SW encoder behind hence
+	 * 		 YUV420 Planar format.  That is MEDIA_BUS_FMT_UYVY8_1_5X8 in DCMIPP
+	 * 		 driver and V4L2_PIX_FMT_YUV420.
+	 * 		 This is exclusively done via the Main pipe.
+	 * Viewfinder: targetting a display, hence limited size of the image to fit into the
+	 * 	       display and xRGB32 output (for the time being we use RGB888 instead.
+	 * 	       Hence MEDIA_BUS_FMT_RGB888_1X24 and V4L2_PIX_FMT_RGB24.
+	 * 	       This can be done by both Main & Aux pipe however we use Aux pipe here.
+	 * VideoRecording: targetting a video encoder with a maximum resolution of HD.
+	 * 		   Hence MEDIA_BUS_FMT_YUYV8_1_5X8 and V4L2_PIX_FMT_NV12.
+	 * 		   This is exclusively done via the Main pipe.
+	 * Raw: targetting RawBayer extraction of the image from a sensor. Format depends on
+	 *      the format of the sensor. This is only done by the Dump pipe.
+	 */
+	for (const StreamRole role : roles) {
+		DcmippPath *path;
+		Size maxSize;
+		PixelFormat pixelFormat;
+
+		dcmipp_config->gamma_correction[i] = false;
+
+		switch (role) {
+		case StreamRole::StillCapture:
+			maxSize = data->sensor_->resolution();
+			pixelFormat = formats::YUV420;
+			if (mainAllocated) {
+				LOG(DCMIPP, Error) << "Main pipe already allocated, ABORT";
+				return nullptr;
+			}
+			path = data->mainPath_;
+			mainAllocated = true;
+			break;
+		case StreamRole::Viewfinder:
+			maxSize = { 1024, 600 };
+			pixelFormat = formats::RGB888;
+			dcmipp_config->gamma_correction[i] = true;
+			if (auxAllocated) {
+				LOG(DCMIPP, Error) << "Aux pipe already allocated, ABORT";
+				return nullptr;
+			}
+			path = data->auxPath_;
+			auxAllocated = true;
+			break;
+		case StreamRole::VideoRecording:
+			maxSize = { 1920, 1080 };
+			pixelFormat = formats::NV12;
+			if (mainAllocated) {
+				LOG(DCMIPP, Error) << "Main pipe already allocated, ABORT";
+				return nullptr;
+			}
+			path = data->mainPath_;
+			mainAllocated = true;
+			break;
+		case StreamRole::Raw:
+			maxSize = data->sensor_->resolution();
+			/*
+			 * In case of Raw role, the pixelFormat is actually given by the
+			 * dcmipp_path generateConfiguration since it depends on sensor format
+			 */
+			pixelFormat = formats::SBGGR8;
+			if (dumpAllocated) {
+				LOG(DCMIPP, Error) << "Dump pipe already allocated, ABORT";
+				return nullptr;
+			}
+			path = data->dumpPath_;
+			dumpAllocated = true;
+			break;
+		default:
+			LOG(DCMIPP, Error) << "Requested stream role not supported: " << roles[0];
+			return nullptr;
+		}
+
+		/*
+		 * role is given here mainly for the ViewFinder role case since we need to figure
+		 * out a way to indicate that we need to enable the GammaCorrection
+		 */
+		StreamConfiguration cfg =
+			path->generateConfiguration(data->sensor_.get(), maxSize, pixelFormat);
+		if (!cfg.pixelFormat.isValid())
+			return nullptr;
+
+		config->addConfiguration(cfg);
+		i++;
+	}
+
+	config->validate();
+
+	return config;
+}
+
+int PipelineHandlerDcmipp::configure(Camera *camera, CameraConfiguration *c)
+{
+	DcmippCameraConfiguration *config =
+		static_cast<DcmippCameraConfiguration *>(c);
+	DcmippCameraData *data = cameraData(camera);
+	int ret, i = 0;
+
+	LOG(DCMIPP, Debug) << "configure";
+
+	/* Disable all paths */
+	dumpPath_.setEnabled(false);
+	mainPath_.setEnabled(false);
+	auxPath_.setEnabled(false);
+
+	/* Get the sensor configuration and apply it */
+	V4L2SubdeviceFormat subformat = config->sensorFormat();
+	ret = data->sensor_->setFormat(&subformat);
+	if (ret)
+		return ret;
+
+	/* Same configuration on both side of the bridge */
+	if (bridge_) {
+		ret = bridge_->setFormat(0, &subformat);
+		if (ret)
+			return ret;
+		ret = bridge_->setFormat(1, &subformat);
+		if (ret)
+			return ret;
+	}
+
+	/* Initialize links after input depending on the config */
+	for (const StreamConfiguration &cfg : *config) {
+		if (cfg.stream() == &data->Dumpstream_)
+			ret = dumpPath_.setEnabled(true);
+		else if (cfg.stream() == &data->Mainstream_)
+			ret = mainPath_.setEnabled(true);
+		else if (cfg.stream() == &data->Auxstream_)
+			ret = auxPath_.setEnabled(true);
+	}
+
+	/* Same configuration on both side of the input subdev */
+	ret = input_->setFormat(0, &subformat);
+	if (ret)
+		return ret;
+
+	/* Configuration of each path */
+	for (const StreamConfiguration &cfg : *config) {
+		bool gamma_correction = config->gamma_correction[i];
+		if (cfg.stream() == &data->Dumpstream_)
+			ret = dumpPath_.configure(cfg, subformat, gamma_correction);
+		else if (cfg.stream() == &data->Mainstream_)
+			ret = mainPath_.configure(cfg, subformat, gamma_correction);
+		else if (cfg.stream() == &data->Auxstream_)
+			ret = auxPath_.configure(cfg, subformat, gamma_correction);
+		if (ret) {
+			LOG(DCMIPP, Error) << "Failed to configure path";
+			return ret;
+		}
+	}
+
+	/* Configure the IPA if we have one and use Main or Aux paths */
+	if (data->ipa_ && (data->mainPath_->isEnabled() || data->auxPath_->isEnabled())) {
+		/* Configure the param & stat video devices */
+		V4L2DeviceFormat paramFormat;
+		paramFormat.fourcc = V4L2PixelFormat(V4L2_META_FMT_ST_DCMIPP_ISP_PARAMS);
+		ret = params_->setFormat(&paramFormat);
+		if (ret)
+			return ret;
+
+		V4L2DeviceFormat statFormat;
+		statFormat.fourcc = V4L2PixelFormat(V4L2_META_FMT_ST_DCMIPP_ISP_STAT);
+		ret = stats_->setFormat(&statFormat);
+		if (ret)
+			return ret;
+
+		/* Disable the stat region by default */
+		struct v4l2_ctrl_isp_stat_region region;
+
+		region.nb_regions = 0;
+
+		ControlValue ctrl(Span<const uint8_t>{ reinterpret_cast<uint8_t *>(&region), sizeof(region) });
+		ControlList statAreaControl;
+		statAreaControl.set(V4L2_CID_ISP_STAT_REGION, ctrl);
+		ret = stats_->setControls(&statAreaControl);
+		if (ret) {
+			LOG(DCMIPP, Error) << "Failed to set control of ISP Stat Area";
+			return ret;
+		}
+
+		/*
+		 * Inform IPA of sensor controls. IPA will update
+		 * data->controlInfo_ which specifies the list of controls supported by the camera.
+		 */
+		IPACameraSensorInfo sensorInfo;
+		data->sensor_->sensorInfo(&sensorInfo);
+
+		ret = data->ipa_->configure(sensorInfo, data->sensor_->controls(),
+					    data->mainPath_->ispDecimationRatio(),
+					    &data->controlInfo_);
+		if (ret) {
+			LOG(DCMIPP, Error) << "Failed to configure IPA";
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+int PipelineHandlerDcmipp::exportFrameBuffers([[maybe_unused]] Camera *camera, Stream *stream,
+					      std::vector<std::unique_ptr<FrameBuffer>> *buffers)
+{
+	DcmippCameraData *data = cameraData(camera);
+	unsigned int count = stream->configuration().bufferCount;
+
+	if (stream == &data->Dumpstream_)
+		return dumpPath_.exportBuffers(count, buffers);
+	else if (stream == &data->Mainstream_)
+		return mainPath_.exportBuffers(count, buffers);
+	else if (stream == &data->Auxstream_)
+		return auxPath_.exportBuffers(count, buffers);
+
+	return -EINVAL;
+}
+
+int PipelineHandlerDcmipp::allocateBuffers(Camera *camera)
+{
+	DcmippCameraData *data = cameraData(camera);
+	unsigned int ipaBufferId = 0;
+	int ret;
+
+	ret = params_->allocateBuffers(DCMIPP_V4L2_STATS_PARAMS_BUFFER_NB, &isp_params_);
+	if (ret < 0)
+		return ret;
+
+	ret = stats_->allocateBuffers(DCMIPP_V4L2_STATS_PARAMS_BUFFER_NB, &isp_stats_);
+	if (ret < 0)
+		return ret;
+
+	for (std::unique_ptr<FrameBuffer> &buffer : isp_stats_) {
+		buffer->setCookie(ipaBufferId++);
+		data->ipaBuffers_.emplace_back(buffer->cookie(), buffer->planes());
+		available_isp_stats_.push(buffer.get());
+	}
+
+	for (std::unique_ptr<FrameBuffer> &buffer : isp_params_) {
+		buffer->setCookie(ipaBufferId++);
+		buffer->_d()->metadata().planes()[0].bytesused = sizeof(struct stm32_dcmipp_params_cfg);
+		data->ipaBuffers_.emplace_back(buffer->cookie(), buffer->planes());
+		available_isp_params_.push(buffer.get());
+	}
+
+	data->ipa_->mapBuffers(data->ipaBuffers_);
+
+	return 0;
+}
+
+int PipelineHandlerDcmipp::freeBuffers(Camera *camera)
+{
+	DcmippCameraData *data = cameraData(camera);
+
+	while (!available_isp_stats_.empty())
+		available_isp_stats_.pop();
+
+	while (!available_isp_params_.empty())
+		available_isp_params_.pop();
+
+	std::vector<unsigned int> ids;
+	for (IPABuffer &ipabuf : data->ipaBuffers_)
+		ids.push_back(ipabuf.id);
+
+	data->ipa_->unmapBuffers(ids);
+	data->ipaBuffers_.clear();
+
+	params_->releaseBuffers();
+	stats_->releaseBuffers();
+
+	return 0;
+}
+
+int PipelineHandlerDcmipp::start(Camera *camera, [[maybe_unused]] const ControlList *controls)
+{
+	DcmippCameraData *data = cameraData(camera);
+	int ret;
+
+	LOG(DCMIPP, Debug) << "start";
+
+	activeCamera_ = camera;
+
+	if (data->dumpPath_->isEnabled()) {
+		ret = data->dumpPath_->start();
+		if (ret < 0) {
+			LOG(DCMIPP, Error) << "Cannot start bytecapture";
+			return ret;
+		}
+	}
+
+	/* Nothing else to do if there is neither main or aux paths */
+	if (!data->mainPath_->isEnabled() && !data->auxPath_->isEnabled())
+		return 0;
+
+	ret = allocateBuffers(camera);
+	if (ret < 0) {
+		freeBuffers(camera);
+		if (data->dumpPath_->isEnabled())
+			data->dumpPath_->stop();
+		LOG(DCMIPP, Error) << "Cannot allocate stats & params buffers for IPA";
+		return ret;
+	}
+
+	ret = data->ipa_->start();
+	if (ret) {
+		LOG(DCMIPP, Error) << "Cannot start IPA";
+		freeBuffers(camera);
+		if (data->dumpPath_->isEnabled())
+			data->dumpPath_->stop();
+		return ret;
+	}
+
+	if (data->mainPath_->isEnabled()) {
+		ret = data->mainPath_->start();
+		if (ret < 0) {
+			LOG(DCMIPP, Error) << "Cannot start pixelcapture";
+			data->ipa_->stop();
+			freeBuffers(camera);
+			if (data->dumpPath_->isEnabled())
+				data->dumpPath_->stop();
+			return ret;
+		}
+	}
+
+	if (data->auxPath_->isEnabled()) {
+		ret = data->auxPath_->start();
+		if (ret < 0) {
+			LOG(DCMIPP, Error) << "Cannot start pixelcapture";
+			if (data->mainPath_->isEnabled())
+				data->mainPath_->stop();
+			data->ipa_->stop();
+			freeBuffers(camera);
+			if (data->dumpPath_->isEnabled())
+				data->dumpPath_->stop();
+			return ret;
+		}
+	}
+
+	ret = stats_->streamOn();
+	if (ret < 0) {
+		LOG(DCMIPP, Error) << "Cannot start stat buffers";
+		mainPath_.stop();
+		data->ipa_->stop();
+		freeBuffers(camera);
+		if (data->dumpPath_->isEnabled())
+			data->dumpPath_->stop();
+		return ret;
+	}
+
+	ret = params_->streamOn();
+	if (ret < 0) {
+		LOG(DCMIPP, Error) << "Cannot start params buffers";
+		stats_->streamOff();
+		mainPath_.stop();
+		data->ipa_->stop();
+		freeBuffers(camera);
+		if (data->dumpPath_->isEnabled())
+			data->dumpPath_->stop();
+		return ret;
+	}
+
+	return 0;
+}
+
+void PipelineHandlerDcmipp::stopDevice(Camera *camera)
+{
+	DcmippCameraData *data = cameraData(camera);
+
+	LOG(DCMIPP, Debug) << "stop";
+
+	if (data->mainPath_->isEnabled() || data->mainPath_->isEnabled()) {
+		params_->streamOff();
+		stats_->streamOff();
+		if (data->auxPath_->isEnabled())
+			data->auxPath_->stop();
+		if (data->mainPath_->isEnabled())
+			data->mainPath_->stop();
+		data->ipa_->stop();
+		freeBuffers(camera);
+	}
+	if (data->dumpPath_->isEnabled())
+		data->dumpPath_->stop();
+
+	data->frameInfo_.clear();
+
+	activeCamera_ = nullptr;
+}
+
+int PipelineHandlerDcmipp::queueRequestDevice(Camera *camera, Request *request)
+{
+	DcmippCameraData *data = cameraData(camera);
+	FrameBuffer *paramBuffer;
+	int ret;
+
+	LOG(DCMIPP, Debug) << "Function: " << __func__ << " sequence: " << request->sequence();
+
+	DcmippFrameInfo *info = data->frameInfo_.create(data, request);
+	if (!info)
+		return -ENOENT;
+
+	/*
+	 * DCMIPP driver does not output statistics frames from the very beginning.
+	 * This depends on the profile being selected via the STAT_PROFILE control,
+	 * however in order to keep the pipeline handler code simpler, set the longest
+	 * delay here, which leads to libcamera not trying to get statistics from the
+	 * DCMIPP driver during the first requests
+	 */
+	if (!available_isp_stats_.empty() && request->sequence() > DCMIPP_STATS_FRAME_DELAY) {
+		info->statsBuffer = available_isp_stats_.front();
+		available_isp_stats_.pop();
+	}
+
+	if (info->dumpPathBuffer) {
+		ret = data->dumpPath_->queueBuffer(info->dumpPathBuffer);
+		if (ret < 0) {
+			LOG(DCMIPP, Error) << "Can not queue dumpPath buffer";
+			return ret;
+		}
+	}
+
+	/* Nothing else to do if there is neither main or aux paths */
+	if (!info->mainPathBuffer && !info->auxPathBuffer)
+		return 0;
+
+	/* Inform IPA of control update */
+	data->ipa_->queueRequest(request->sequence(), request->controls());
+
+	/* Sends the params buffer to the IPA for filling */
+	if (available_isp_params_.empty()) {
+		LOG(DCMIPP, Error) << "ISP parameters buffer underrun";
+	} else {
+		paramBuffer = available_isp_params_.front();
+		available_isp_params_.pop();
+		data->ipa_->fillParamsBuffer(request->sequence(), paramBuffer->cookie());
+	}
+
+	/* Queue pipeline buffers */
+	if (info->mainPathBuffer) {
+		ret = data->mainPath_->queueBuffer(info->mainPathBuffer);
+		if (ret < 0) {
+			LOG(DCMIPP, Error) << "Can not queue mainPath buffer";
+			return ret;
+		}
+	}
+
+	if (info->auxPathBuffer) {
+		ret = data->auxPath_->queueBuffer(info->auxPathBuffer);
+		if (ret < 0) {
+			LOG(DCMIPP, Error) << "Can not queue auxPath buffer";
+			return ret;
+		}
+	}
+
+	if (info->statsBuffer) {
+		ret = stats_->queueBuffer(info->statsBuffer);
+		if (ret < 0) {
+			LOG(DCMIPP, Error) << "Can not queue ISP stats buffer";
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+bool PipelineHandlerDcmipp::match(DeviceEnumerator *enumerator)
+{
+	LOG(DCMIPP, Debug) << "match";
+
+	DeviceMatch dm("dcmipp");
+
+	dm.add("dcmipp_input");
+	dm.add("dcmipp_main_isp");
+	dm.add("dcmipp_main_postproc");
+	dm.add("dcmipp_main_capture");
+
+	media_ = acquireMediaDevice(enumerator, dm);
+	if (!media_)
+		return false;
+
+	data_ = std::make_unique<DcmippCameraData>(this, &dumpPath_,
+						   &mainPath_, &auxPath_);
+
+	/* Locate and open all subdevices and video nodes */
+	if (init())
+		return false;
+
+	data_->ipa_ = IPAManager::createIPA<ipa::dcmipp::IPAProxyDcmipp>(this, 0, 0);
+	if (!data_->ipa_) {
+		LOG(DCMIPP, Error) << "no matching IPA found";
+		return false;
+	}
+
+	/* Connect the two event callback from IPA */
+	data_->ipa_->paramsBufferReady.connect(data_.get(), &DcmippCameraData::paramsFilled);
+	data_->ipa_->statsBufferProcessed.connect(data_.get(), &DcmippCameraData::statsFreed);
+	data_->ipa_->metadataReady.connect(data_.get(), &DcmippCameraData::metadataReady);
+	data_->ipa_->setSensorControls.connect(data_.get(), &DcmippCameraData::setSensorControls);
+	data_->ipa_->setIspControls.connect(data_.get(), &DcmippCameraData::setIspControls);
+
+	/*
+	 * Initialize IPA. IPA is reponsible for setting data_->controlInfo_ which
+	 * specifies the list of controls supported by the camera.
+	 */
+	IPACameraSensorInfo sensorInfo;
+	if (data_->sensor_->sensorInfo(&sensorInfo)) {
+		LOG(DCMIPP, Error) << "Camera sensor information not available";
+		return false;
+	}
+
+	/* Tuning file made from sensor name or from environment variable */
+	std::string ipaTuningFile;
+	char const *configFromEnv = utils::secure_getenv("LIBCAMERA_DCMIPP_TUNING_FILE");
+	if (configFromEnv && *configFromEnv != '\0') {
+		ipaTuningFile = std::string(configFromEnv);
+	} else {
+		ipaTuningFile = data_->ipa_->configurationFile(data_->sensor_->model() + ".yaml");
+	}
+
+	if (data_->ipa_->init(IPASettings{ ipaTuningFile, data_->sensor_->model() },
+			      media_->hwRevision(), sensorInfo, data_->sensor_->controls(),
+			      &data_->controlInfo_) < 0) {
+		LOG(DCMIPP, Error) << "IPA initialization failure";
+		return false;
+	}
+
+	/* Create and register the camera. */
+	std::set<Stream *> streams{ &data_->Dumpstream_, &data_->Mainstream_, &data_->Auxstream_ };
+	const std::string &id = data_->sensor_->id();
+	std::shared_ptr<Camera> camera =
+		Camera::create(std::move(data_), id, streams);
+	registerCamera(std::move(camera));
+
+	return true;
+}
+
+int PipelineHandlerDcmipp::init()
+{
+	const MediaPad *sinkPad;
+	const MediaPad *remotePad;
+
+	LOG(DCMIPP, Debug) << "init";
+
+	input_ = V4L2Subdevice::fromEntityName(media_, "dcmipp_input");
+	if (input_->open())
+		return -ENODEV;
+
+	/* Locate and open the optional CSI-2 receiver */
+	sinkPad = input_->entity()->getPadByIndex(0);
+	if (!sinkPad || sinkPad->links().empty())
+		return false;
+
+	remotePad = sinkPad->links().at(0)->source();
+	if (remotePad->entity()->function() == MEDIA_ENT_F_VID_IF_BRIDGE) {
+		bridge_ = std::make_unique<V4L2Subdevice>(remotePad->entity());
+		if (bridge_->open())
+			return false;
+
+		sinkPad = bridge_->entity()->getPadByIndex(0);
+		if (!sinkPad || sinkPad->links().empty())
+			return false;
+
+		remotePad = sinkPad->links().at(0)->source();
+	}
+
+	/* Open the sensor subdev */
+	data_->sensor_ = std::make_unique<CameraSensor>(remotePad->entity());
+	if (data_->sensor_->init())
+		return -ENODEV;
+
+	data_->input_ = V4L2Subdevice::fromEntityName(media_, "dcmipp_input");
+	if (data_->input_->open() < 0)
+		return -ENODEV;
+
+	/* Initialize all path */
+	if (!dumpPath_.init(media_))
+		return -ENODEV;
+	dumpPath_.bufferReady().connect(this, &PipelineHandlerDcmipp::bufferReady);
+
+	if (!mainPath_.init(media_))
+		return -ENODEV;
+	mainPath_.bufferReady().connect(this, &PipelineHandlerDcmipp::bufferReady);
+
+	if (!auxPath_.init(media_))
+		return -ENODEV;
+	auxPath_.bufferReady().connect(this, &PipelineHandlerDcmipp::bufferReady);
+
+	/* Initialize ISP video devices */
+	params_ = V4L2VideoDevice::fromEntityName(media_, "dcmipp_main_isp_params_output");
+	if (params_->open())
+		return -ENODEV;
+	params_->bufferReady.connect(this, &PipelineHandlerDcmipp::paramsReady);
+
+	stats_ = V4L2VideoDevice::fromEntityName(media_, "dcmipp_main_isp_stat_capture");
+	if (stats_->open())
+		return -ENODEV;
+	stats_->bufferReady.connect(this, &PipelineHandlerDcmipp::statsReady);
+
+	/* Initialize the camera properties. */
+	data_->properties_ = data_->sensor_->properties();
+
+	return 0;
+}
+
+PipelineHandlerDcmipp *DcmippCameraData::pipe()
+{
+	return static_cast<PipelineHandlerDcmipp *>(Camera::Private::pipe());
+}
+
+void PipelineHandlerDcmipp::tryCompleteRequest(DcmippFrameInfo *info)
+{
+	DcmippCameraData *data = cameraData(activeCamera_);
+	Request *request = info->request;
+
+	LOG(DCMIPP, Debug) << "Function: " << __func__;
+
+	if (request->hasPendingBuffers())
+		return;
+
+	if (info->statsBuffer && !info->metadataProcessed)
+		return;
+
+	data->frameInfo_.destroy(info->frame);
+
+	completeRequest(request);
+}
+
+void PipelineHandlerDcmipp::bufferReady(FrameBuffer *buffer)
+{
+	ASSERT(activeCamera_);
+	DcmippCameraData *data = cameraData(activeCamera_);
+	Request *request = buffer->request();
+
+	LOG(DCMIPP, Debug) << "Function: " << __func__;
+
+	DcmippFrameInfo *info = data->frameInfo_.find(buffer);
+	if (!info)
+		return;
+
+	/* If the buffer is cancelled force a complete of the whole request. */
+	if (buffer->metadata().status == FrameMetadata::FrameCancelled) {
+		for (auto &it : request->buffers()) {
+			FrameBuffer *b = it.second;
+			b->_d()->cancel();
+			completeBuffer(request, b);
+		}
+
+		info->metadataProcessed = true;
+		tryCompleteRequest(info);
+
+		return;
+	}
+
+	/* Record the sensor's timestamp in the request metadata. */
+	request->metadata().set(controls::SensorTimestamp,
+				buffer->metadata().timestamp);
+
+	completeBuffer(request, buffer);
+	tryCompleteRequest(info);
+}
+
+void PipelineHandlerDcmipp::statsReady(FrameBuffer *buffer)
+{
+	ASSERT(activeCamera_);
+	DcmippCameraData *data = cameraData(activeCamera_);
+
+	DcmippFrameInfo *info = data->frameInfo_.find(buffer);
+	if (!info) {
+		LOG(DCMIPP, Error) << "Stats buffer not found";
+		return;
+	}
+
+	LOG(DCMIPP, Debug) << "Function: " << __func__;
+
+	/* Sends the stats buffer to the IPA for analysis */
+	data->ipa_->processStatsBuffer(info->frame, buffer->cookie());
+}
+
+void PipelineHandlerDcmipp::paramsReady(FrameBuffer *buffer)
+{
+	LOG(DCMIPP, Debug) << "Function: " << __func__;
+
+	/* Push this buffer into the available buffer list */
+	available_isp_params_.push(buffer);
+}
+
+void DcmippCameraData::paramsFilled(unsigned int id)
+{
+	PipelineHandlerDcmipp *pipe =
+		static_cast<PipelineHandlerDcmipp *>(Camera::Private::pipe());
+
+	LOG(DCMIPP, Debug) << "Function: " << __func__ << " buffer cookie: " << id;
+
+	/* Search the buffer and queue it back */
+	for (std::unique_ptr<FrameBuffer> &buffer : pipe->isp_params_) {
+		if (buffer.get()->cookie() == id) {
+			if (pipe->params_->queueBuffer(buffer.get()) < 0)
+				LOG(DCMIPP, Error) << "Could not queue back stats buffer";
+			return;
+		}
+	}
+
+	LOG(DCMIPP, Error) << "Could not find params buffer";
+}
+
+void DcmippCameraData::statsFreed(unsigned int id)
+{
+	PipelineHandlerDcmipp *pipe =
+		static_cast<PipelineHandlerDcmipp *>(Camera::Private::pipe());
+
+	LOG(DCMIPP, Debug) << "Function: " << __func__ << " buffer cookie: " << id;
+
+	/* Search the buffer and queue it back */
+	for (std::unique_ptr<FrameBuffer> &buffer : pipe->isp_stats_) {
+		if (buffer.get()->cookie() == id) {
+			pipe->available_isp_stats_.push(buffer.get());
+			return;
+		}
+	}
+
+	LOG(DCMIPP, Error) << "Could not find stats buffer";
+}
+
+void DcmippCameraData::metadataReady(unsigned int frame, const ControlList &metadata)
+{
+	LOG(DCMIPP, Debug) << "Function: " << __func__ << " frame: " << frame;
+
+	DcmippFrameInfo *info = frameInfo_.find(frame);
+	if (!info)
+		return;
+
+	info->request->metadata().merge(metadata);
+	info->metadataProcessed = true;
+
+	pipe()->tryCompleteRequest(info);
+}
+
+void DcmippCameraData::setSensorControls([[maybe_unused]] unsigned int id,
+					 const ControlList &sensorControls)
+{
+	LOG(DCMIPP, Debug) << "Function: " << __func__;
+
+	ControlList ctrls = sensorControls;
+
+	int ret = sensor_->setControls(&ctrls);
+	if (ret)
+		LOG(DCMIPP, Error) << "Failed to set sensor controls: " << ret;
+}
+
+void DcmippCameraData::setIspControls([[maybe_unused]] unsigned int id,
+				      const ControlList &ispControls)
+{
+	PipelineHandlerDcmipp *pipe =
+		static_cast<PipelineHandlerDcmipp *>(Camera::Private::pipe());
+
+	LOG(DCMIPP, Debug) << "Function: " << __func__;
+
+	ControlList ctrls = ispControls;
+
+	int ret = pipe->stats_->setControls(&ctrls);
+	if (ret)
+		LOG(DCMIPP, Error) << "Failed to set ISP controls: " << ret;
+}
+
+REGISTER_PIPELINE_HANDLER(PipelineHandlerDcmipp)
+
+} /* namespace libcamera */
diff --git a/src/libcamera/pipeline/dcmipp/dcmipp.h b/src/libcamera/pipeline/dcmipp/dcmipp.h
new file mode 100644
index 00000000..6059c70c
--- /dev/null
+++ b/src/libcamera/pipeline/dcmipp/dcmipp.h
@@ -0,0 +1,131 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024, ST Microelectronics
+ *
+ * dcmipp.h - STM32 DCMIPP common definitions
+ */
+
+#pragma once
+
+#include <memory>
+#include <set>
+#include <vector>
+
+#include <libcamera/base/signal.h>
+#include <libcamera/base/span.h>
+
+#include <libcamera/camera.h>
+#include <libcamera/geometry.h>
+#include <libcamera/pixel_format.h>
+
+#include "libcamera/internal/media_object.h"
+#include "libcamera/internal/v4l2_videodevice.h"
+
+namespace libcamera {
+
+class CameraSensor;
+class MediaDevice;
+class V4L2Subdevice;
+struct StreamConfiguration;
+struct V4L2SubdeviceFormat;
+
+class DcmippPath
+{
+public:
+	DcmippPath(const char *name);
+	DcmippPath(const char *name, const Span<const PixelFormat> &formats);
+
+	bool init(MediaDevice *media);
+
+	int setEnabled(bool enable);
+	bool isEnabled() const { return enabled_; }
+
+	StreamConfiguration generateConfiguration(const CameraSensor *sensor,
+						  const Size &maxSize,
+						  PixelFormat rolePixelFormat);
+	CameraConfiguration::Status validate(const CameraSensor *sensor,
+					     StreamConfiguration *cfg,
+					     unsigned int *isp_decimation_ratio);
+
+	int configure(const StreamConfiguration &config,
+		      const V4L2SubdeviceFormat &inputFormat,
+		      bool gamma_correction);
+
+	int exportBuffers(unsigned int bufferCount,
+			  std::vector<std::unique_ptr<FrameBuffer>> *buffers)
+	{
+		return video_->exportBuffers(bufferCount, buffers);
+	}
+
+	int start();
+	void stop();
+
+	int queueBuffer(FrameBuffer *buffer) { return video_->queueBuffer(buffer); }
+	Signal<FrameBuffer *> &bufferReady() { return video_->bufferReady; }
+
+	unsigned int ispDecimationRatio() const { return isp_decimation_ratio_; }
+
+private:
+	void populateFormats();
+
+	static constexpr unsigned int DCMIPP_BUFFER_COUNT = 4;
+
+	const char *name_;
+	bool enabled_;
+	bool running_;
+
+	const Span<const PixelFormat> pathFormats_;
+
+	std::unique_ptr<V4L2Subdevice> input_;
+	std::unique_ptr<V4L2Subdevice> isp_;
+	std::unique_ptr<V4L2Subdevice> postproc_;
+	std::unique_ptr<V4L2VideoDevice> video_;
+
+	unsigned int input_source_pad_;
+
+	MediaLink *link_;
+
+	unsigned int isp_decimation_ratio_;
+};
+
+class DcmippDumpPath : public DcmippPath
+{
+public:
+	DcmippDumpPath();
+};
+
+class DcmippMainPath : public DcmippPath
+{
+public:
+	DcmippMainPath();
+};
+
+class DcmippAuxPath : public DcmippPath
+{
+public:
+	DcmippAuxPath();
+};
+
+} /* namespace libcamera */
+
+#define DCMIPP_V4L2_BUFFER_NB 4
+/* We need one more buffer for stats / params than frame buffers */
+#define DCMIPP_V4L2_STATS_PARAMS_BUFFER_NB (DCMIPP_V4L2_BUFFER_NB + 1)
+
+#define DCMIPP_RAW_MAX_WIDTH 2688
+
+/*
+ * DCMIPP driver does not output statistics frames from the very beginning.
+ * This depends on the profile being selected via the STAT_PROFILE control,
+ * however in order to keep the pipeline handler code simpler, set the longest
+ * delay here, which leads to libcamera not trying to get statistics from the
+ * DCMIPP driver during the first requests
+ */
+#define DCMIPP_STATS_FRAME_DELAY 10
+
+/*
+ * DCMIPP driver doesn't export (yet) the postproc Gamma control CID macro
+ * hence define it here instead
+ * \todo - to be removed once the V4L2_CID is exported by the kernel
+ */
+#define DCMIPP_V4L2_CID_POSTPROC_GAMMA (V4L2_CID_USER_BASE | 0x1001)
diff --git a/src/libcamera/pipeline/dcmipp/dcmipp_path.cpp b/src/libcamera/pipeline/dcmipp/dcmipp_path.cpp
new file mode 100644
index 00000000..c58ccf50
--- /dev/null
+++ b/src/libcamera/pipeline/dcmipp/dcmipp_path.cpp
@@ -0,0 +1,513 @@
+/* SPDX-License-Identifier: LGPL-2.1-or-later */
+/*
+ * Copyright (C) 2024, ST Microelectronics
+ *
+ * dcmipp_path.cpp - STM32 DCMIPP path helper
+ * Based on rkisp1_path.cpp
+ */
+
+#include "dcmipp.h"
+
+#include <linux/media-bus-format.h>
+
+#include <libcamera/formats.h>
+#include <libcamera/stream.h>
+
+#include "libcamera/internal/camera_sensor.h"
+#include "libcamera/internal/media_device.h"
+#include "libcamera/internal/v4l2_subdevice.h"
+#include "libcamera/internal/v4l2_videodevice.h"
+
+namespace libcamera {
+
+LOG_DECLARE_CATEGORY(DCMIPP)
+
+namespace {
+
+constexpr std::array<PixelFormat, 27> pixelformats_dump{
+	formats::RGB565,
+	formats::YUYV,
+	formats::YVYU,
+	formats::UYVY,
+	formats::VYUY,
+	formats::R8,
+	formats::SBGGR8,
+	formats::SGBRG8,
+	formats::SGRBG8,
+	formats::SRGGB8,
+	formats::SBGGR10,
+	formats::SGBRG10,
+	formats::SGRBG10,
+	formats::SRGGB10,
+	formats::SBGGR12,
+	formats::SGBRG12,
+	formats::SGRBG12,
+	formats::SRGGB12,
+	formats::SBGGR14,
+	formats::SGBRG14,
+	formats::SGRBG14,
+	formats::SRGGB14,
+	formats::SBGGR16,
+	formats::SGBRG16,
+	formats::SGRBG16,
+	formats::SRGGB16,
+	formats::MJPEG,
+};
+
+constexpr std::array<PixelFormat, 14> pixelformats_main{
+	formats::RGB565,
+	formats::YUYV,
+	formats::YVYU,
+	formats::UYVY,
+	formats::VYUY,
+	formats::R8,
+	formats::RGB888,
+	formats::BGR888,
+	formats::NV12,
+	formats::NV21,
+	formats::NV16,
+	formats::NV61,
+	formats::YUV420,
+	formats::YVU420,
+};
+
+/*
+ * Since we only concentrate on RAW input and AUX doesn't have
+ * RGB to YUV conversion, AUX will only output RGB formats
+ * until we also add support for non-raw sensors.
+ */
+constexpr std::array<PixelFormat, 3> pixelformats_aux{
+	formats::RGB565,
+	formats::RGB888,
+	formats::BGR888,
+};
+
+const std::map<PixelFormat, uint32_t> formatToMediaBus = {
+	{ formats::RGB565, MEDIA_BUS_FMT_RGB565_2X8_LE },
+	{ formats::YUYV, MEDIA_BUS_FMT_YUYV8_2X8 },
+	{ formats::YVYU, MEDIA_BUS_FMT_YVYU8_2X8 },
+	{ formats::UYVY, MEDIA_BUS_FMT_UYVY8_2X8 },
+	{ formats::VYUY, MEDIA_BUS_FMT_VYUY8_2X8 },
+	{ formats::R8, MEDIA_BUS_FMT_Y8_1X8 },
+	{ formats::RGB888, MEDIA_BUS_FMT_RGB888_1X24 },
+	{ formats::BGR888, MEDIA_BUS_FMT_BGR888_1X24 },
+	{ formats::ARGB8888, MEDIA_BUS_FMT_ARGB8888_1X32 },
+	{ formats::AVUY8888, MEDIA_BUS_FMT_ARGB8888_1X32 },
+	{ formats::NV12, MEDIA_BUS_FMT_YUYV8_1_5X8 },
+	{ formats::NV21, MEDIA_BUS_FMT_YVYU8_1_5X8 },
+	{ formats::NV16, MEDIA_BUS_FMT_YUYV8_1X16 },
+	{ formats::NV61, MEDIA_BUS_FMT_YVYU8_1X16 },
+	{ formats::YUV420, MEDIA_BUS_FMT_UYVY8_1_5X8 },
+	{ formats::YVU420, MEDIA_BUS_FMT_VYUY8_1_5X8 },
+	{ formats::SBGGR8, MEDIA_BUS_FMT_SBGGR8_1X8 },
+	{ formats::SGBRG8, MEDIA_BUS_FMT_SGBRG8_1X8 },
+	{ formats::SGRBG8, MEDIA_BUS_FMT_SGRBG8_1X8 },
+	{ formats::SRGGB8, MEDIA_BUS_FMT_SRGGB8_1X8 },
+	{ formats::SBGGR10, MEDIA_BUS_FMT_SBGGR10_1X10 },
+	{ formats::SGBRG10, MEDIA_BUS_FMT_SGBRG10_1X10 },
+	{ formats::SGRBG10, MEDIA_BUS_FMT_SGRBG10_1X10 },
+	{ formats::SRGGB10, MEDIA_BUS_FMT_SRGGB10_1X10 },
+	{ formats::SBGGR12, MEDIA_BUS_FMT_SBGGR12_1X12 },
+	{ formats::SGBRG12, MEDIA_BUS_FMT_SGBRG12_1X12 },
+	{ formats::SGRBG12, MEDIA_BUS_FMT_SGRBG12_1X12 },
+	{ formats::SRGGB12, MEDIA_BUS_FMT_SRGGB12_1X12 },
+	{ formats::SBGGR14, MEDIA_BUS_FMT_SBGGR14_1X14 },
+	{ formats::SGBRG14, MEDIA_BUS_FMT_SGBRG14_1X14 },
+	{ formats::SGRBG14, MEDIA_BUS_FMT_SGRBG14_1X14 },
+	{ formats::SRGGB14, MEDIA_BUS_FMT_SRGGB14_1X14 },
+	{ formats::SBGGR16, MEDIA_BUS_FMT_SBGGR16_1X16 },
+	{ formats::SGBRG16, MEDIA_BUS_FMT_SGBRG16_1X16 },
+	{ formats::SGRBG16, MEDIA_BUS_FMT_SGRBG16_1X16 },
+	{ formats::SRGGB16, MEDIA_BUS_FMT_SRGGB16_1X16 },
+	{ formats::MJPEG, MEDIA_BUS_FMT_JPEG_1X8 },
+};
+
+} /* namespace */
+
+DcmippPath::DcmippPath(const char *name)
+	: name_(name), enabled_(false), running_(false), input_source_pad_(1), link_(nullptr), isp_decimation_ratio_(1)
+{
+}
+
+DcmippPath::DcmippPath(const char *name, const Span<const PixelFormat> &formats)
+	: name_(name), enabled_(false), running_(false), pathFormats_(formats), input_source_pad_(1), link_(nullptr), isp_decimation_ratio_(1)
+{
+}
+
+int DcmippPath::setEnabled(bool enable)
+{
+	enabled_ = enable;
+
+	if (link_->flags() & MEDIA_LNK_FL_IMMUTABLE)
+		return 0;
+
+	return link_->setEnabled(enable);
+}
+
+bool DcmippPath::init(MediaDevice *media)
+{
+	std::string postproc = std::string("dcmipp_") + name_ + "_postproc";
+	std::string video = std::string("dcmipp_") + name_ + "_capture";
+
+	LOG(DCMIPP, Debug) << "DcmippPath::init " << name_;
+
+	input_ = V4L2Subdevice::fromEntityName(media, "dcmipp_input");
+	if (input_->open() < 0)
+		return false;
+
+	postproc_ = V4L2Subdevice::fromEntityName(media, postproc);
+	if (postproc_->open() < 0)
+		return false;
+
+	video_ = V4L2VideoDevice::fromEntityName(media, video);
+	if (video_->open() < 0)
+		return false;
+
+	if (name_ == std::string("dump")) {
+		link_ = media->link("dcmipp_input", 1, "dcmipp_dump_postproc", 0);
+		if (!link_)
+			return false;
+		input_source_pad_ = 1;
+	} else if (name_ == std::string("main")) {
+		isp_ = V4L2Subdevice::fromEntityName(media, "dcmipp_main_isp");
+		if (isp_->open() < 0)
+			return false;
+		link_ = media->link("dcmipp_input", 2, "dcmipp_main_isp", 0);
+		if (!link_)
+			return false;
+		input_source_pad_ = 2;
+	} else if (name_ == std::string("aux")) {
+		link_ = media->link("dcmipp_main_isp", 1, "dcmipp_aux_postproc", 0);
+		if (!link_)
+			return false;
+		input_source_pad_ = 3;
+	}
+
+	return true;
+}
+
+/*
+ * This function is in charge of
+ * - list up all configuration that could be achieved by a path, taking into
+ *   consideration sensor format, decimate of the ISP block, decimate / downsize
+ *   of the postproc block and color conversion of the main pipe then available
+ *   formats of the pixel cap video device
+ * - set a default configuration depending on the role, that matches the above
+ *   constraint as well
+ * - as far as the Dump pipe is concerned, this is a matter of checking the
+ *   sensor pipe & and bytecap available formats
+ * - we should not care about role at the path level, the decision being done
+ *   at upper level
+ */
+StreamConfiguration
+DcmippPath::generateConfiguration(const CameraSensor *sensor, const Size &maxSize,
+				  PixelFormat rolePixelFormat)
+{
+	const std::vector<unsigned int> &mbusCodes = sensor->mbusCodes();
+	Size resolution = sensor->resolution();
+	Size minSize;
+
+	LOG(DCMIPP, Debug) << "DcmippPath::generateConfiguration " << name_;
+
+	/*
+	 * For Main & Aux pipe postproc can perform decimate-downsize hence 8 * 8 reduction
+	 *
+	 * ISP decimation can also perform a maximum of 8 reduction.  It is also mandatory
+	 * to ensure that RAW frame size does not exceed 2688 width prior demosaicing.
+	 */
+	if (name_ != std::string("dump")) {
+		/* Ensure to not exceed maximum width for demosaicing */
+		while (resolution.width > DCMIPP_RAW_MAX_WIDTH)
+			resolution /= 2;
+
+		minSize = sensor->resolution() / (8 * 8 * 8);
+		minSize.expandTo({ 16, minSize.height });
+	}
+
+	std::map<PixelFormat, std::vector<SizeRange>> formats;
+
+	for (const auto &format : pathFormats_) {
+		const PixelFormatInfo &info = PixelFormatInfo::info(format);
+
+		if (name_ != std::string("dump")) {
+			/* Handling of Pixel pipes (Main / Aux) */
+			std::vector<SizeRange> sizesRange{
+				SizeRange{ minSize, resolution }
+			};
+			formats[format] = std::move(sizesRange);
+			continue;
+		} else if (name_ == std::string("dump") &&
+			   info.colourEncoding == PixelFormatInfo::ColourEncodingRAW) {
+			/* Handling of Byte pipe (Dump) exclusively for RAW formats */
+			uint32_t mbusCode = formatToMediaBus.at(format);
+			if (std::find(mbusCodes.begin(), mbusCodes.end(), mbusCode) ==
+			    mbusCodes.end())
+				/* Skip formats not supported by sensor. */
+				continue;
+			else
+				rolePixelFormat = format;
+
+			/*
+			 * \todo DUMP pipe is also able to perform byte based reduction
+			 * by skipping lines or bytes
+			 * */
+			formats[format] = { resolution, resolution };
+		}
+	}
+
+	StreamConfiguration cfg(formats);
+	cfg.size = maxSize;
+	cfg.pixelFormat = rolePixelFormat;
+	cfg.bufferCount = DCMIPP_V4L2_BUFFER_NB;
+
+	return cfg;
+}
+
+CameraConfiguration::Status DcmippPath::validate(const CameraSensor *sensor,
+						 StreamConfiguration *cfg,
+						 unsigned int *isp_decimation_ratio)
+{
+	bool format_found = false;
+
+	LOG(DCMIPP, Debug) << "DcmippPath::validate " << name_;
+
+	/* Check that configured size can be achieved */
+	Size post_isp_resolution = sensor->resolution();
+
+	/*
+	 * For Main & Aux pipe postproc can perform decimate-downsize hence 8 * 8 reduction
+	 *
+	 * ISP decimation can also perform a maximum of 8 reduction.  It is also mandatory
+	 * to ensure that RAW frame size does not exceed 2688 width prior demosaicing.
+	 */
+	if (name_ != std::string("dump")) {
+		if (!*isp_decimation_ratio) {
+			*isp_decimation_ratio = 1;
+			/* Ensure to not exceed maximum width for demosaicing */
+			while (post_isp_resolution.width > DCMIPP_RAW_MAX_WIDTH ||
+			       post_isp_resolution.width / cfg->size.width > (8 * 8) ||
+			       post_isp_resolution.height / cfg->size.height > (8 * 8)) {
+				*isp_decimation_ratio *= 2;
+				if (*isp_decimation_ratio > 8) {
+					LOG(DCMIPP, Error) << "Necessary decimation factor too big.";
+					return CameraConfiguration::Invalid;
+				}
+				post_isp_resolution /= 2;
+			}
+		} else {
+			post_isp_resolution /= *isp_decimation_ratio;
+			if (post_isp_resolution.width / cfg->size.width > (8 * 8) ||
+			    post_isp_resolution.height / cfg->size.height > (8 * 8)) {
+				LOG(DCMIPP, Error) << "ISP output frame too big to reach final requested size";
+				return CameraConfiguration::Invalid;
+			}
+		}
+	}
+
+	for (const auto &format : pathFormats_) {
+		if (format == cfg->pixelFormat) {
+			format_found = true;
+			break;
+		}
+	}
+
+	if (!format_found)
+		return CameraConfiguration::Invalid;
+
+	V4L2DeviceFormat format;
+	format.fourcc = video_->toV4L2PixelFormat(cfg->pixelFormat);
+	format.size = cfg->size;
+
+	int ret = video_->tryFormat(&format);
+	if (ret)
+		return CameraConfiguration::Invalid;
+
+	cfg->stride = format.planes[0].bpl;
+	cfg->frameSize = format.planes[0].size;
+
+	if (name_ == std::string("main"))
+		isp_decimation_ratio_ = *isp_decimation_ratio;
+
+	return CameraConfiguration::Valid;
+}
+
+int DcmippPath::configure(const StreamConfiguration &config,
+			  const V4L2SubdeviceFormat &inputFormat,
+			  bool gamma_correction)
+{
+	int ret;
+	V4L2SubdeviceFormat subformat = inputFormat;
+
+	LOG(DCMIPP, Debug) << "DcmippPath::configure " << name_;
+
+	ret = input_->setFormat(input_source_pad_, &subformat);
+	if (ret < 0)
+		return ret;
+
+	if (name_ == std::string("dump")) {
+		/* Configuration of the postproc block */
+		ret = postproc_->setFormat(0, &subformat);
+		if (ret)
+			return ret;
+		ret = postproc_->setFormat(1, &subformat);
+		if (ret)
+			return ret;
+		LOG(DCMIPP, Debug)
+			<< "Configured pipe " << name_ << " with format " << subformat;
+	} else if (name_ == std::string("main")) {
+		/* Configuration of the ISP block */
+		ret = isp_->setFormat(0, &subformat);
+		if (ret)
+			return ret;
+
+		subformat.mbus_code = MEDIA_BUS_FMT_RGB888_1X24;
+		subformat.size /= isp_decimation_ratio_;
+		Rectangle compose_isp{ 0, 0, subformat.size };
+		ret = isp_->setSelection(0, V4L2_SEL_TGT_COMPOSE, &compose_isp);
+		if (ret)
+			return ret;
+
+		LOG(DCMIPP, Debug)
+			<< "Configured pipe " << name_ << " with ISP output format "
+			<< subformat;
+
+		/* Configuration of the postproc block */
+		ret = postproc_->setFormat(0, &subformat);
+		if (ret)
+			return ret;
+
+		/* This should not happen since config.pixelFormat has already been validated */
+		if (formatToMediaBus.find(config.pixelFormat) == formatToMediaBus.end())
+			return -EINVAL;
+
+		subformat.mbus_code = formatToMediaBus.find(config.pixelFormat)->second;
+		ret = postproc_->setFormat(1, &subformat);
+		if (ret)
+			return ret;
+
+		Rectangle compose{ 0, 0, config.size };
+		ret = postproc_->setSelection(0, V4L2_SEL_TGT_COMPOSE, &compose);
+		if (ret)
+			return ret;
+
+		/* Gamma correction configuration */
+		ControlList ctrls;
+		ctrls.set(DCMIPP_V4L2_CID_POSTPROC_GAMMA, (int32_t)(gamma_correction));
+		ret = postproc_->setControls(&ctrls);
+		if (ret)
+			return ret;
+
+		LOG(DCMIPP, Debug)
+			<< "Configured pipe " << name_ << " with format input format "
+			<< inputFormat << " and output format " << subformat;
+	} else if (name_ == std::string("aux")) {
+		subformat.mbus_code = MEDIA_BUS_FMT_RGB888_1X24;
+
+		/* Configuration of the postproc block */
+		ret = postproc_->setFormat(0, &subformat);
+		if (ret)
+			return ret;
+		Rectangle compose{ 0, 0, config.size };
+		ret = postproc_->setSelection(0, V4L2_SEL_TGT_COMPOSE, &compose);
+		if (ret)
+			return ret;
+
+		/* This should not happen since config.pixelFormat has already been validated */
+		if (formatToMediaBus.find(config.pixelFormat) == formatToMediaBus.end())
+			return -EINVAL;
+
+		subformat.mbus_code = formatToMediaBus.find(config.pixelFormat)->second;
+		ret = postproc_->setFormat(1, &subformat);
+		if (ret)
+			return ret;
+
+		/* Gamma correction configuration */
+		ControlList ctrls;
+		ctrls.set(DCMIPP_V4L2_CID_POSTPROC_GAMMA, (int32_t)(gamma_correction));
+		ret = postproc_->setControls(&ctrls);
+		if (ret)
+			return ret;
+
+		LOG(DCMIPP, Debug)
+			<< "Configured pipe " << name_ << " with output format "
+			<< subformat;
+	}
+
+	const PixelFormatInfo &info = PixelFormatInfo::info(config.pixelFormat);
+	V4L2DeviceFormat outputFormat;
+	outputFormat.fourcc = video_->toV4L2PixelFormat(config.pixelFormat);
+	outputFormat.size = config.size;
+	outputFormat.planesCount = info.numPlanes();
+
+	ret = video_->setFormat(&outputFormat);
+	if (ret)
+		return ret;
+
+	if (outputFormat.size != config.size ||
+	    outputFormat.fourcc != video_->toV4L2PixelFormat(config.pixelFormat)) {
+		LOG(DCMIPP, Error)
+			<< "Unable to configure capture in " << config.toString() << " got instead: " << outputFormat;
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+int DcmippPath::start()
+{
+	int ret;
+
+	LOG(DCMIPP, Debug) << "DcmippPath::start " << name_;
+
+	if (running_)
+		return -EBUSY;
+
+	ret = video_->importBuffers(DCMIPP_V4L2_BUFFER_NB);
+	if (ret)
+		return ret;
+
+	ret = video_->streamOn();
+	if (ret) {
+		LOG(DCMIPP, Error)
+			<< "Failed to start " << name_ << " path";
+
+		video_->releaseBuffers();
+		return ret;
+	}
+
+	running_ = true;
+
+	return 0;
+}
+
+void DcmippPath::stop()
+{
+	LOG(DCMIPP, Debug) << "DcmippPath::stop " << name_;
+
+	if (!running_)
+		return;
+
+	if (video_->streamOff())
+		LOG(DCMIPP, Warning) << "Failed to stop " << name_ << " path";
+
+	video_->releaseBuffers();
+
+	running_ = false;
+}
+
+DcmippDumpPath::DcmippDumpPath()
+	: DcmippPath("dump", pixelformats_dump)
+{
+}
+
+DcmippMainPath::DcmippMainPath()
+	: DcmippPath("main", pixelformats_main)
+{
+}
+
+DcmippAuxPath::DcmippAuxPath()
+	: DcmippPath("aux", pixelformats_aux)
+{
+}
+
+} /* namespace libcamera */
diff --git a/src/libcamera/pipeline/dcmipp/meson.build b/src/libcamera/pipeline/dcmipp/meson.build
new file mode 100644
index 00000000..4f1555d9
--- /dev/null
+++ b/src/libcamera/pipeline/dcmipp/meson.build
@@ -0,0 +1,5 @@
+# SPDX-License-Identifier: CC0-1.0
+
+libcamera_sources += files([
+    'dcmipp.cpp', 'dcmipp_path.cpp'
+])
diff --git a/src/libcamera/pipeline/rpi/vc4/vc4.cpp b/src/libcamera/pipeline/rpi/vc4/vc4.cpp
index 26102ea7..a52f0e7a 100644
--- a/src/libcamera/pipeline/rpi/vc4/vc4.cpp
+++ b/src/libcamera/pipeline/rpi/vc4/vc4.cpp
@@ -945,6 +945,7 @@ void Vc4CameraData::tryRunPipeline()
 	params.requestControls = request->controls();
 	params.ipaContext = request->sequence();
 	params.delayContext = bayerFrame.delayContext;
+	params.buffers.embedded = 0;
 
 	if (embeddedBuffer) {
 		unsigned int embeddedId = unicam_[Unicam::Embedded].getBufferId(embeddedBuffer);
diff --git a/src/libcamera/v4l2_device.cpp b/src/libcamera/v4l2_device.cpp
index 24d208ef..f51e0ca4 100644
--- a/src/libcamera/v4l2_device.cpp
+++ b/src/libcamera/v4l2_device.cpp
@@ -334,7 +334,13 @@ int V4L2Device::setControls(ControlList *ctrls)
 
 		default:
 			/* \todo To be changed to support strings. */
-			v4l2Ctrl.value = value.get<int32_t>();
+			if (value.isArray()) {
+				Span<uint8_t> data = value.data();
+				v4l2Ctrl.p_u32 = reinterpret_cast<uint32_t *>(data.data());
+				v4l2Ctrl.size = data.size();
+			} else {
+				v4l2Ctrl.value = value.get<int32_t>();
+			}
 			break;
 		}
 	}
@@ -553,9 +559,13 @@ std::optional<ControlInfo> V4L2Device::v4l2ControlInfo(const v4l2_query_ext_ctrl
 		return v4l2MenuControlInfo(ctrl);
 
 	default:
-		return ControlInfo(static_cast<int32_t>(ctrl.minimum),
-				   static_cast<int32_t>(ctrl.maximum),
-				   static_cast<int32_t>(ctrl.default_value));
+		if (ctrl.type >= V4L2_CTRL_COMPOUND_TYPES)
+			/* ControlInfo "None" for such control */
+			return ControlInfo();
+		else
+			return ControlInfo(static_cast<int32_t>(ctrl.minimum),
+					   static_cast<int32_t>(ctrl.maximum),
+					   static_cast<int32_t>(ctrl.default_value));
 	}
 }
 
@@ -627,6 +637,8 @@ void V4L2Device::listControls()
 			break;
 		/* \todo Support other control types. */
 		default:
+			if (ctrl.type >= V4L2_CTRL_COMPOUND_TYPES)
+				break;
 			LOG(V4L2, Debug)
 				<< "Control " << utils::hex(ctrl.id)
 				<< " has unsupported type " << ctrl.type;
diff --git a/src/libcamera/v4l2_pixelformat.cpp b/src/libcamera/v4l2_pixelformat.cpp
index 5551c62e..731dc10f 100644
--- a/src/libcamera/v4l2_pixelformat.cpp
+++ b/src/libcamera/v4l2_pixelformat.cpp
@@ -135,6 +135,8 @@ const std::map<V4L2PixelFormat, V4L2PixelFormat::Info> vpf2pf{
 		{ formats::R10_CSI2P, "10-bit Greyscale Packed" } },
 	{ V4L2PixelFormat(V4L2_PIX_FMT_Y12),
 		{ formats::R12, "12-bit Greyscale" } },
+	{ V4L2PixelFormat(V4L2_PIX_FMT_Y16),
+		{ formats::R16, "16-bit Greyscale" } },
 
 	/* Bayer formats. */
 	{ V4L2PixelFormat(V4L2_PIX_FMT_SBGGR8),
diff --git a/src/libcamera/v4l2_subdevice.cpp b/src/libcamera/v4l2_subdevice.cpp
index 15e8206a..6d0785b7 100644
--- a/src/libcamera/v4l2_subdevice.cpp
+++ b/src/libcamera/v4l2_subdevice.cpp
@@ -57,6 +57,7 @@ struct V4L2SubdeviceFormatInfo {
  * bus codes
  */
 const std::map<uint32_t, V4L2SubdeviceFormatInfo> formatInfoMap = {
+	/* This table is sorted to match the order in linux/media-bus-format.h */
 	{ MEDIA_BUS_FMT_RGB444_2X8_PADHI_BE, { 16, "RGB444_2X8_PADHI_BE", PixelFormatInfo::ColourEncodingRGB } },
 	{ MEDIA_BUS_FMT_RGB444_2X8_PADHI_LE, { 16, "RGB444_2X8_PADHI_LE", PixelFormatInfo::ColourEncodingRGB } },
 	{ MEDIA_BUS_FMT_RGB555_2X8_PADHI_BE, { 16, "RGB555_2X8_PADHI_BE", PixelFormatInfo::ColourEncodingRGB } },
@@ -88,6 +89,7 @@ const std::map<uint32_t, V4L2SubdeviceFormatInfo> formatInfoMap = {
 	{ MEDIA_BUS_FMT_YUYV10_2X10, { 20, "YUYV10_2X10", PixelFormatInfo::ColourEncodingYUV } },
 	{ MEDIA_BUS_FMT_YVYU10_2X10, { 20, "YVYU10_2X10", PixelFormatInfo::ColourEncodingYUV } },
 	{ MEDIA_BUS_FMT_Y12_1X12, { 12, "Y12_1X12", PixelFormatInfo::ColourEncodingYUV } },
+	{ MEDIA_BUS_FMT_Y16_1X16, { 16, "Y16_1X16", PixelFormatInfo::ColourEncodingYUV } },
 	{ MEDIA_BUS_FMT_UYVY8_1X16, { 16, "UYVY8_1X16", PixelFormatInfo::ColourEncodingYUV } },
 	{ MEDIA_BUS_FMT_VYUY8_1X16, { 16, "VYUY8_1X16", PixelFormatInfo::ColourEncodingYUV } },
 	{ MEDIA_BUS_FMT_YUYV8_1X16, { 16, "YUYV8_1X16", PixelFormatInfo::ColourEncodingYUV } },
@@ -359,6 +361,21 @@ int V4L2Subdevice::open()
 		return ret;
 	}
 
+	/* If the subdev supports streams, enable the streams API. */
+	if (caps_.hasStreams()) {
+		struct v4l2_subdev_client_capability clientCaps{};
+		clientCaps.capabilities = V4L2_SUBDEV_CLIENT_CAP_STREAMS;
+
+		ret = ioctl(VIDIOC_SUBDEV_S_CLIENT_CAP, &clientCaps);
+		if (ret < 0) {
+			ret = -errno;
+			LOG(V4L2, Error)
+				<< "Unable to set client capabilities: "
+				<< strerror(-ret);
+			return ret;
+		}
+	}
+
 	return 0;
 }
 
diff --git a/test/event-thread.cpp b/test/event-thread.cpp
index ef8a52c3..d6e5d27a 100644
--- a/test/event-thread.cpp
+++ b/test/event-thread.cpp
@@ -11,6 +11,7 @@
 #include <unistd.h>
 
 #include <libcamera/base/event_notifier.h>
+#include <libcamera/base/object.h>
 #include <libcamera/base/thread.h>
 #include <libcamera/base/timer.h>
 
@@ -84,10 +85,17 @@ private:
 class EventThreadTest : public Test
 {
 protected:
+	int init()
+	{
+		thread_.start();
+
+		handler_ = new EventHandler();
+
+		return TestPass;
+	}
+
 	int run()
 	{
-		Thread thread;
-		thread.start();
 
 		/*
 		 * Fire the event notifier and then move the notifier to a
@@ -97,23 +105,33 @@ protected:
 		 * different thread will correctly process already pending
 		 * events in the new thread.
 		 */
-		EventHandler handler;
-		handler.notify();
-		handler.moveToThread(&thread);
+		handler_->notify();
+		handler_->moveToThread(&thread_);
 
 		this_thread::sleep_for(chrono::milliseconds(100));
 
-		/* Must stop thread before destroying the handler. */
-		thread.exit(0);
-		thread.wait();
-
-		if (!handler.notified()) {
+		if (!handler_->notified()) {
 			cout << "Thread event handling test failed" << endl;
 			return TestFail;
 		}
 
 		return TestPass;
 	}
+
+	void cleanup()
+	{
+		/*
+		 * Object class instances must be destroyed from the thread
+		 * they live in.
+		 */
+		handler_->deleteLater();
+		thread_.exit(0);
+		thread_.wait();
+	}
+
+private:
+	EventHandler *handler_;
+	Thread thread_;
 };
 
 TEST_REGISTER(EventThreadTest)
diff --git a/test/gstreamer/gstreamer_test.cpp b/test/gstreamer/gstreamer_test.cpp
index 091f7bf7..e8119b85 100644
--- a/test/gstreamer/gstreamer_test.cpp
+++ b/test/gstreamer/gstreamer_test.cpp
@@ -51,23 +51,6 @@ GstreamerTest::GstreamerTest(unsigned int numStreams)
 		return;
 	}
 
-	/*
-	 * Remove the system libcamera plugin, if any, and add the plugin from
-	 * the build directory.
-	 */
-	GstRegistry *registry = gst_registry_get();
-	g_autoptr(GstPlugin) plugin = gst_registry_lookup(registry, "libgstlibcamera.so");
-	if (plugin)
-		gst_registry_remove_plugin(registry, plugin);
-
-	std::string path = libcamera::utils::libcameraBuildPath() + "src/gstreamer";
-	if (!gst_registry_scan_path(registry, path.c_str())) {
-		g_printerr("Failed to add plugin to registry\n");
-
-		status_ = TestFail;
-		return;
-	}
-
 	/*
 	 * Atleast one camera should be available with numStreams streams,
 	 * otherwise skip the test entirely.
diff --git a/test/gstreamer/meson.build b/test/gstreamer/meson.build
index a5c003b6..f3ba5a23 100644
--- a/test/gstreamer/meson.build
+++ b/test/gstreamer/meson.build
@@ -17,5 +17,5 @@ foreach test : gstreamer_tests
                      link_with : test_libraries,
                      include_directories : test_includes_internal)
 
-    test(test['name'], exe, suite : 'gstreamer', is_parallel : false)
+    test(test['name'], exe, suite : 'gstreamer', is_parallel : false, env : gst_env)
 endforeach
diff --git a/test/ipa/ipa_interface_test.cpp b/test/ipa/ipa_interface_test.cpp
index 051ef96e..56f3cd6d 100644
--- a/test/ipa/ipa_interface_test.cpp
+++ b/test/ipa/ipa_interface_test.cpp
@@ -16,6 +16,7 @@
 
 #include <libcamera/base/event_dispatcher.h>
 #include <libcamera/base/event_notifier.h>
+#include <libcamera/base/object.h>
 #include <libcamera/base/thread.h>
 #include <libcamera/base/timer.h>
 
diff --git a/test/meson.build b/test/meson.build
index 189e1428..8b6057d4 100644
--- a/test/meson.build
+++ b/test/meson.build
@@ -69,6 +69,7 @@ internal_tests = [
     {'name': 'signal-threads', 'sources': ['signal-threads.cpp']},
     {'name': 'threads', 'sources': 'threads.cpp', 'dependencies': [libthreads]},
     {'name': 'timer', 'sources': ['timer.cpp']},
+    {'name': 'timer-fail', 'sources': ['timer-fail.cpp'], 'should_fail': true},
     {'name': 'timer-thread', 'sources': ['timer-thread.cpp']},
     {'name': 'unique-fd', 'sources': ['unique-fd.cpp']},
     {'name': 'utils', 'sources': ['utils.cpp']},
@@ -91,7 +92,7 @@ foreach test : public_tests
                      link_with : test_libraries,
                      include_directories : test_includes_public)
 
-    test(test['name'], exe)
+    test(test['name'], exe, should_fail : test.get('should_fail', false))
 endforeach
 
 foreach test : internal_tests
@@ -105,7 +106,7 @@ foreach test : internal_tests
                      link_with : test_libraries,
                      include_directories : test_includes_internal)
 
-    test(test['name'], exe)
+    test(test['name'], exe, should_fail : test.get('should_fail', false))
 endforeach
 
 foreach test : internal_non_parallel_tests
@@ -119,5 +120,7 @@ foreach test : internal_non_parallel_tests
                      link_with : test_libraries,
                      include_directories : test_includes_internal)
 
-    test(test['name'], exe, is_parallel : false)
+    test(test['name'], exe,
+         is_parallel : false,
+         should_fail : test.get('should_fail', false))
 endforeach
diff --git a/test/message.cpp b/test/message.cpp
index d148a13d..2f9f281c 100644
--- a/test/message.cpp
+++ b/test/message.cpp
@@ -11,6 +11,7 @@
 #include <thread>
 
 #include <libcamera/base/message.h>
+#include <libcamera/base/object.h>
 #include <libcamera/base/thread.h>
 
 #include "test.h"
@@ -92,25 +93,6 @@ private:
 	bool success_;
 };
 
-class SlowMessageReceiver : public Object
-{
-protected:
-	void message(Message *msg)
-	{
-		if (msg->type() != Message::None) {
-			Object::message(msg);
-			return;
-		}
-
-		/*
-		 * Don't access any member of the object here (including the
-		 * vtable) as the object will be deleted by the main thread
-		 * while we're sleeping.
-		 */
-		this_thread::sleep_for(chrono::milliseconds(100));
-	}
-};
-
 class MessageTest : public Test
 {
 protected:
@@ -127,16 +109,19 @@ protected:
 			return TestFail;
 		}
 
-		MessageReceiver receiver;
-		receiver.moveToThread(&thread_);
+		MessageReceiver *receiver = new MessageReceiver();
+		receiver->moveToThread(&thread_);
 
 		thread_.start();
 
-		receiver.postMessage(std::make_unique<Message>(Message::None));
+		receiver->postMessage(std::make_unique<Message>(Message::None));
 
 		this_thread::sleep_for(chrono::milliseconds(100));
 
-		switch (receiver.status()) {
+		MessageReceiver::Status status = receiver->status();
+		receiver->deleteLater();
+
+		switch (status) {
 		case MessageReceiver::NoMessage:
 			cout << "No message received" << endl;
 			return TestFail;
@@ -147,29 +132,13 @@ protected:
 			break;
 		}
 
-		/*
-		 * Test for races between message delivery and object deletion.
-		 * Failures result in assertion errors, there is no need for
-		 * explicit checks.
-		 */
-		SlowMessageReceiver *slowReceiver = new SlowMessageReceiver();
-		slowReceiver->moveToThread(&thread_);
-		slowReceiver->postMessage(std::make_unique<Message>(Message::None));
-
-		this_thread::sleep_for(chrono::milliseconds(10));
-
-		delete slowReceiver;
-
-		this_thread::sleep_for(chrono::milliseconds(100));
-
 		/*
 		 * Test recursive calls to Thread::dispatchMessages(). Messages
 		 * should be delivered correctly, without crashes or memory
 		 * leaks. Two messages need to be posted to ensure we don't only
 		 * test the simple case of a queue containing a single message.
 		 */
-		std::unique_ptr<RecursiveMessageReceiver> recursiveReceiver =
-			std::make_unique<RecursiveMessageReceiver>();
+		RecursiveMessageReceiver *recursiveReceiver = new RecursiveMessageReceiver();
 		recursiveReceiver->moveToThread(&thread_);
 
 		recursiveReceiver->postMessage(std::make_unique<Message>(Message::None));
@@ -177,7 +146,10 @@ protected:
 
 		this_thread::sleep_for(chrono::milliseconds(10));
 
-		if (!recursiveReceiver->success()) {
+		bool success = recursiveReceiver->success();
+		recursiveReceiver->deleteLater();
+
+		if (!success) {
 			cout << "Recursive message delivery failed" << endl;
 			return TestFail;
 		}
diff --git a/test/object-delete.cpp b/test/object-delete.cpp
index eabefe93..80b7dc41 100644
--- a/test/object-delete.cpp
+++ b/test/object-delete.cpp
@@ -33,10 +33,10 @@ public:
 	unsigned int *deleteCount_;
 };
 
-class NewThread : public Thread
+class DeleterThread : public Thread
 {
 public:
-	NewThread(Object *obj)
+	DeleterThread(Object *obj)
 		: object_(obj)
 	{
 	}
@@ -63,9 +63,9 @@ protected:
 		unsigned int count = 0;
 		TestObject *obj = new TestObject(&count);
 
-		NewThread thread(obj);
-		thread.start();
-		thread.wait();
+		DeleterThread delThread(obj);
+		delThread.start();
+		delThread.wait();
 
 		Thread::current()->dispatchMessages(Message::Type::DeferredDelete);
 
@@ -89,6 +89,26 @@ protected:
 			return TestFail;
 		}
 
+		/*
+		 * Test that deleteLater() works properly when called just
+		 * before the object's thread exits.
+		 */
+		Thread boundThread;
+		boundThread.start();
+
+		count = 0;
+		obj = new TestObject(&count);
+		obj->moveToThread(&boundThread);
+
+		obj->deleteLater();
+		boundThread.exit();
+		boundThread.wait();
+
+		if (count != 1) {
+			cout << "Object deletion right before thread exit failed (" << count << ")" << endl;
+			return TestFail;
+		}
+
 		return TestPass;
 	}
 };
diff --git a/test/signal-threads.cpp b/test/signal-threads.cpp
index d5e2eb66..8c212b6f 100644
--- a/test/signal-threads.cpp
+++ b/test/signal-threads.cpp
@@ -10,6 +10,7 @@
 #include <thread>
 
 #include <libcamera/base/message.h>
+#include <libcamera/base/object.h>
 #include <libcamera/base/thread.h>
 #include <libcamera/base/utils.h>
 
@@ -58,15 +59,20 @@ private:
 class SignalThreadsTest : public Test
 {
 protected:
-	int run()
+	int init()
 	{
-		SignalReceiver receiver;
-		signal_.connect(&receiver, &SignalReceiver::slot);
+		receiver_ = new SignalReceiver();
+		signal_.connect(receiver_, &SignalReceiver::slot);
+
+		return TestPass;
+	}
 
+	int run()
+	{
 		/* Test that a signal is received in the main thread. */
 		signal_.emit(0);
 
-		switch (receiver.status()) {
+		switch (receiver_->status()) {
 		case SignalReceiver::NoSignal:
 			cout << "No signal received for direct connection" << endl;
 			return TestFail;
@@ -82,8 +88,8 @@ protected:
 		 * Move the object to a thread and verify that the signal is
 		 * correctly delivered, with the correct data.
 		 */
-		receiver.reset();
-		receiver.moveToThread(&thread_);
+		receiver_->reset();
+		receiver_->moveToThread(&thread_);
 
 		thread_.start();
 
@@ -91,7 +97,7 @@ protected:
 
 		this_thread::sleep_for(chrono::milliseconds(100));
 
-		switch (receiver.status()) {
+		switch (receiver_->status()) {
 		case SignalReceiver::NoSignal:
 			cout << "No signal received for message connection" << endl;
 			return TestFail;
@@ -103,7 +109,7 @@ protected:
 			break;
 		}
 
-		if (receiver.value() != 42) {
+		if (receiver_->value() != 42) {
 			cout << "Signal received with incorrect value" << endl;
 			return TestFail;
 		}
@@ -113,11 +119,13 @@ protected:
 
 	void cleanup()
 	{
+		receiver_->deleteLater();
 		thread_.exit(0);
 		thread_.wait();
 	}
 
 private:
+	SignalReceiver *receiver_;
 	Thread thread_;
 
 	Signal<int> signal_;
diff --git a/test/timer-fail.cpp b/test/timer-fail.cpp
new file mode 100644
index 00000000..82854b89
--- /dev/null
+++ b/test/timer-fail.cpp
@@ -0,0 +1,109 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
+/*
+ * Copyright (C) 2024, Ideas on Board Oy
+ *
+ * timer-fail.cpp - Threaded timer failure test
+ */
+
+#include <chrono>
+#include <iostream>
+
+#include <libcamera/base/event_dispatcher.h>
+#include <libcamera/base/object.h>
+#include <libcamera/base/thread.h>
+#include <libcamera/base/timer.h>
+
+#include "test.h"
+
+using namespace libcamera;
+using namespace std;
+using namespace std::chrono_literals;
+
+class TimeoutHandler : public Object
+{
+public:
+	TimeoutHandler()
+		: timer_(this), timeout_(false)
+	{
+		timer_.timeout.connect(this, &TimeoutHandler::timeoutHandler);
+	}
+
+	void start()
+	{
+		timer_.start(100ms);
+	}
+
+	bool timeout() const
+	{
+		return timeout_;
+	}
+
+private:
+	void timeoutHandler()
+	{
+		timeout_ = true;
+	}
+
+	Timer timer_;
+	bool timeout_;
+};
+
+class TimerFailTest : public Test
+{
+protected:
+	int init()
+	{
+		thread_.start();
+
+		timeout_ = new TimeoutHandler();
+		timeout_->moveToThread(&thread_);
+
+		return TestPass;
+	}
+
+	int run()
+	{
+		/*
+		 * Test that the forbidden operation of starting the timer from
+		 * another thread results in a failure. We need to interrupt the
+		 * event dispatcher to make sure we don't succeed simply because
+		 * the event dispatcher hasn't noticed the timer restart.
+		 */
+		timeout_->start();
+		thread_.eventDispatcher()->interrupt();
+
+		this_thread::sleep_for(chrono::milliseconds(200));
+
+		/*
+		 * The wrong start() call should result in an assertion in debug
+		 * builds, and a timeout in release builds. The test is
+		 * therefore marked in meson.build as expected to fail. We need
+		 * to return TestPass in the unexpected (usually known as
+		 * "fail") case, and TestFail otherwise.
+		 */
+		if (timeout_->timeout()) {
+			cout << "Timer start from wrong thread succeeded unexpectedly"
+			     << endl;
+			return TestPass;
+		}
+
+		return TestFail;
+	}
+
+	void cleanup()
+	{
+		/*
+		 * Object class instances must be destroyed from the thread
+		 * they live in.
+		 */
+		timeout_->deleteLater();
+		thread_.exit(0);
+		thread_.wait();
+	}
+
+private:
+	TimeoutHandler *timeout_;
+	Thread thread_;
+};
+
+TEST_REGISTER(TimerFailTest)
diff --git a/test/timer-thread.cpp b/test/timer-thread.cpp
index 61821753..8675e248 100644
--- a/test/timer-thread.cpp
+++ b/test/timer-thread.cpp
@@ -9,6 +9,7 @@
 #include <iostream>
 
 #include <libcamera/base/event_dispatcher.h>
+#include <libcamera/base/object.h>
 #include <libcamera/base/thread.h>
 #include <libcamera/base/timer.h>
 
@@ -28,12 +29,6 @@ public:
 		timer_.start(100ms);
 	}
 
-	void restart()
-	{
-		timeout_ = false;
-		timer_.start(100ms);
-	}
-
 	bool timeout() const
 	{
 		return timeout_;
@@ -55,7 +50,9 @@ protected:
 	int init()
 	{
 		thread_.start();
-		timeout_.moveToThread(&thread_);
+
+		timeout_ = new TimeoutHandler();
+		timeout_->moveToThread(&thread_);
 
 		return TestPass;
 	}
@@ -68,39 +65,27 @@ protected:
 		 */
 		this_thread::sleep_for(chrono::milliseconds(200));
 
-		if (!timeout_.timeout()) {
+		if (!timeout_->timeout()) {
 			cout << "Timer expiration test failed" << endl;
 			return TestFail;
 		}
 
-		/*
-		 * Test that starting the timer from another thread fails. We
-		 * need to interrupt the event dispatcher to make sure we don't
-		 * succeed simply because the event dispatcher hasn't noticed
-		 * the timer restart.
-		 */
-		timeout_.restart();
-		thread_.eventDispatcher()->interrupt();
-
-		this_thread::sleep_for(chrono::milliseconds(200));
-
-		if (timeout_.timeout()) {
-			cout << "Timer restart test failed" << endl;
-			return TestFail;
-		}
-
 		return TestPass;
 	}
 
 	void cleanup()
 	{
-		/* Must stop thread before destroying timeout. */
+		/*
+		 * Object class instances must be destroyed from the thread
+		 * they live in.
+		 */
+		timeout_->deleteLater();
 		thread_.exit(0);
 		thread_.wait();
 	}
 
 private:
-	TimeoutHandler timeout_;
+	TimeoutHandler *timeout_;
 	Thread thread_;
 };
 
diff --git a/utils/ipc/extract-docs.py b/utils/ipc/extract-docs.py
index 8f7fff9f..c2050c99 100755
--- a/utils/ipc/extract-docs.py
+++ b/utils/ipc/extract-docs.py
@@ -10,9 +10,9 @@ import argparse
 import re
 import sys
 
-regex_block_start = re.compile('^\/\*\*$')
-regex_block_end = re.compile('^ \*\/$')
-regex_spdx = re.compile('^\/\* SPDX-License-Identifier: .* \*\/$')
+regex_block_start = re.compile(r'^/\*\*$')
+regex_block_end = re.compile(r'^ \*/$')
+regex_spdx = re.compile(r'^/\* SPDX-License-Identifier: .* \*/$')
 
 
 def main(argv):
diff --git a/utils/ipc/generators/libcamera_templates/module_ipa_proxy.h.tmpl b/utils/ipc/generators/libcamera_templates/module_ipa_proxy.h.tmpl
index ed270f5c..6e823598 100644
--- a/utils/ipc/generators/libcamera_templates/module_ipa_proxy.h.tmpl
+++ b/utils/ipc/generators/libcamera_templates/module_ipa_proxy.h.tmpl
@@ -18,6 +18,7 @@
 #include <libcamera/ipa/ipa_interface.h>
 #include <libcamera/ipa/{{module_name}}_ipa_interface.h>
 
+#include <libcamera/base/object.h>
 #include <libcamera/base/thread.h>
 
 #include "libcamera/internal/control_serializer.h"
-- 
2.25.1

